{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limshaocong/SysBERT/blob/main/t4_finetuning_seqlabel_er.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preliminaries**"
      ],
      "metadata": {
        "id": "b0LYLPA78zuf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOsHUjgdIrIW"
      },
      "outputs": [],
      "source": [
        "! pip install --user datasets transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG-L9BEI8uie",
        "outputId": "1e263b4b-0667-46c2-a649-db151e105a50"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-f163c6e8-eefd-40a1-6ed3-581fcb9b32b7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! huggingface-cli login\n",
        "# # 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"
      ],
      "metadata": {
        "id": "WPpnEQBc8vx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPRbBNbIrIl"
      },
      "source": [
        "# **Import & Pre-process Data**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_type_dict = {\n",
        "    'bert-base-cased' : 'bert-base-cased',\n",
        "    'roberta-base' : 'roberta-base',\n",
        "    'allenai/scibert_scivocab_cased' : 'allenai/scibert_scivocab_cased',\n",
        "    'limsc/reqbert-tapt-epoch29' : 'bert-base-cased', # preferred\n",
        "    'limsc/reqbert-tapt-epoch30' : 'bert-base-cased',\n",
        "    'limsc/reqroberta-tapt-epoch20' : 'roberta-base',\n",
        "    'limsc/reqroberta-tapt-epoch33' : 'roberta-base',\n",
        "    'limsc/reqroberta-tapt-epoch43' : 'roberta-base', # preferred\n",
        "    'limsc/reqroberta-tapt-epoch50' : 'roberta-base',\n",
        "    'limsc/reqscibert-tapt-epoch10' : 'allenai/scibert_scivocab_cased', # preferred\n",
        "    'limsc/reqscibert-tapt-epoch20' : 'allenai/scibert_scivocab_cased', # preferred\n",
        "    'limsc/reqscibert-tapt-epoch31' : 'allenai/scibert_scivocab_cased',\n",
        "    'limsc/reqscibert-tapt-epoch49' : 'allenai/scibert_scivocab_cased',\n",
        "}\n",
        "\n",
        "model_name_dict = {\n",
        "    'bert-base-cased' : 'bert',\n",
        "    'roberta-base' : 'roberta',\n",
        "    'allenai/scibert_scivocab_cased' : 'scibert',\n",
        "    'limsc/reqbert-tapt-epoch29' : 'reqbert-e29',\n",
        "    'limsc/reqbert-tapt-epoch30' : 'reqbert-e30',\n",
        "    'limsc/reqroberta-tapt-epoch20' : 'reqroberta-e20',\n",
        "    'limsc/reqroberta-tapt-epoch33' : 'reqroberta-e33',\n",
        "    'limsc/reqroberta-tapt-epoch43' : 'reqroberta-e43',\n",
        "    'limsc/reqroberta-tapt-epoch50' : 'reqroberta-e50',\n",
        "    'limsc/reqscibert-tapt-epoch10' : 'reqscibert-e10',\n",
        "    'limsc/reqscibert-tapt-epoch20' : 'reqscibert-e20',\n",
        "    'limsc/reqscibert-tapt-epoch31' : 'reqscibert-e31',\n",
        "    'limsc/reqscibert-tapt-epoch49' : 'reqscibert-e49',\n",
        "}\n",
        "\n",
        "task_name_dict = {\n",
        "    'limsc/fr-nfr-classification' : 'frnfr',\n",
        "    'limsc/nfr-subclass-classification' : 'subclass',\n",
        "    'limsc/concept-recognition' : 'cr',\n",
        "    'limsc/concept-recognition-not-iob' : 'cr',\n",
        "    'limsc/requirements-entity-recognition' : 'er'\n",
        "}"
      ],
      "metadata": {
        "id": "HNVQoJ1CKvSb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IreSlFmlIrIm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556,
          "referenced_widgets": [
            "82cc9bfa8fad47ed96ba9c8859a88965",
            "9419781c2cbf4d4bb66fbe16147f28f3",
            "b152fcaf325242e2a86d5e2755fa51e2",
            "dfaea0da0e9e4255933b6c47f16660c5",
            "068d53547f034a76998280c879bdfe59",
            "c085bbda6a4e4c2da7f63070724e49bd",
            "bff0a723d43442d4b3907fd84910f3d7",
            "5a625a4182d343379cf24be0d85e7c0b",
            "bc9ae3683f8b4ff885f37e6d9e47ca6a",
            "6abb7fb9336f49ca8a9fe4658ff66ed7",
            "95fd69407c854c93acbc95613a81ab9b",
            "54c36d4a81b7404c9472b4e366d65e31",
            "fcb609f8fc30466abfb7fab22b87c6d1",
            "42c726ef1bd64695bb714ffacf0ba9d2",
            "f54988f13a7744b2b034233afcc40dbb",
            "593384d294a944e6a8fc024f89353b44",
            "60e8a005f3854139b322e387e6acda4f",
            "9035232f37f94d45ad15360051a52d60",
            "29aa9b1d36f94867a127b08d17150ce7",
            "5c39bf19d21e42c197044c4852f1f3eb",
            "0af9244b60544a48a441229a9ae03e6d",
            "bfa7628750db4553b607a330e4e995cf",
            "9b4921e11c674d719efde3c718bfb456",
            "4abb482d62984706ba599dc78756cfe9",
            "4083ddf15b494cc7815f90cb1423177f",
            "3b80fd67bb3b46e5b30121398522abc8",
            "8992e627cfed418eb8e5e4ac2c72ee34",
            "b6033066ea154a249c7cfad2f17bf209",
            "80427df9bae145f29105e4a2139488cd",
            "7f1aef68fd80468ab76809f724eb7f2d",
            "67e87843d5164200b674a02322e2d6ed",
            "f59295ba8f004dd4ae395d3cde1c5bd6",
            "29138784dba34525ba852491fac88eed",
            "b956b38083354b61a08f231dadc09284",
            "711c119b5aad4707b13bd296b04975a8",
            "86f8718b4f00454a84727c8cfe2d30e5",
            "d89df68bcf704c8b8b497f282441f51f",
            "a4ff3eaf24cd4b14b8b4fb92a91623e6",
            "bfdb50d59c944d2c94d4c741160ac4c9",
            "e1adf26a451f475c927147cf2fec3b1d",
            "3bc8d9af2424413ebb53328f2ee708e5",
            "b9b4676e00244976adfcca07c5fede12",
            "de90292d7838487d92f225daad6e53c0",
            "3c857b5f8de04e2e8248487b3a738a99",
            "7821c78eb9ee44459ba6e83391ad8e26",
            "cac7fc241a0042baa9a9f0b4b62d0591",
            "3ce40f80f996418082ce89b944447e4d",
            "8ec8734e23a44a8fbe2611ecd633df60",
            "15a8aa2b2f014224bf18f52eb2b51ab9",
            "571d7be8013e460890d0114e8973d2f2",
            "292ba2cd6c4a4faaa9e82ce3420b5954",
            "a2822701b8164139a5d6688ef3e8eca8",
            "70269273e0e3407ba27d9209c5f9a2d4",
            "7a9458faa22e469a84939bf2231f0358",
            "2b0569662c3342d780bc8dd952de7c72",
            "f9c5249d478e427490a45c06824ce2ac",
            "573f801ecb5843c4a326412f69850d5a",
            "ee7d7c2737784d0690b57b68e36140c0",
            "d6974ca000334cb6813d5d5566658e83",
            "a61c03ed50cc41edb078bb04a63a5f41",
            "12d357c2605f4902b8ff1692b7bb6334",
            "bacc5b12bed743598c7b6b808b6f4a46",
            "4a1f594e464541d8b231e5b11556480b",
            "e07dac7e7e044b62ba004d0bb51933ca",
            "2dca1ffb8d604753b730b70671dbbc9d",
            "88352dd9096c4a0aba767c7e5926d349",
            "268137a361a84bed871655d015965bc4",
            "1c93a923d1414a17a6f39585ad47abf1",
            "18d223fb16384bb1a7e8e81d9d09596b",
            "768b66af3d724a01b3bd0ae20855ca0c",
            "4b511a67e10e482f8cd1f725b1035a20",
            "e8a002b3ea61465a92aa5e9ff1b00510",
            "fc8b3013e0a246e9a623b917855e3d68",
            "b9825745777640a087c48e29fbecda6c",
            "f78472ddd4f344c9a3e92c0cdf02ee6d",
            "84df2f3fbf1c41df901e823fca5acaf3",
            "2b1766ea99c2492d9503d76348d88944"
          ]
        },
        "outputId": "abc63b05-2654-43de-90b2-6fd89ce9ab07"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.22k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82cc9bfa8fad47ed96ba9c8859a88965"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration limsc--requirements-entity-recognition-bed4bc851291dde3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset None/None (download: 71.01 KiB, generated: 361.94 KiB, post-processed: Unknown size, total: 432.95 KiB) to /root/.cache/huggingface/datasets/limsc___parquet/limsc--requirements-entity-recognition-bed4bc851291dde3/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54c36d4a81b7404c9472b4e366d65e31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b4921e11c674d719efde3c718bfb456"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/13.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b956b38083354b61a08f231dadc09284"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/45.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7821c78eb9ee44459ba6e83391ad8e26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9c5249d478e427490a45c06824ce2ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/limsc___parquet/limsc--requirements-entity-recognition-bed4bc851291dde3/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "268137a361a84bed871655d015965bc4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'ner_tags'],\n",
              "        num_rows: 139\n",
              "    })\n",
              "    val: Dataset({\n",
              "        features: ['id', 'tokens', 'ner_tags'],\n",
              "        num_rows: 138\n",
              "    })\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'ner_tags'],\n",
              "        num_rows: 646\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds_name = 'limsc/requirements-entity-recognition'\n",
        "ds = load_dataset(ds_name)\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Vn4qqTzmWqDN",
        "outputId": "78d6e757-59d8-4753-9758-4b0c64a18999",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'B-ACT',\n",
              " 'B-ATTR',\n",
              " 'B-RELOP',\n",
              " 'B-QUANT',\n",
              " 'B-ENT',\n",
              " 'I-ACT',\n",
              " 'I-ATTR',\n",
              " 'I-RELOP',\n",
              " 'I-QUANT',\n",
              " 'I-ENT']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "label_list = ds['train'].features['ner_tags'].feature.names\n",
        "label_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = 'bert-base-cased'"
      ],
      "metadata": {
        "id": "h81se9qE9F8X"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eXNLu_-nIrJI",
        "outputId": "50c3a8ff-b429-4ce4-af91-4c58adae4e50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "b2790ea0e8e44595b1ec464190f870c6",
            "37377297ee124996ae2a6a7f806c5f6b",
            "6d0e240bd86242ec999b5b24be65e327",
            "975a7d3304d14b46bcd70ab40b508c34",
            "b001a2634ea84beb92aa1f775722d078",
            "7c11b3012c38487aa9cde85771fdf990",
            "cb6dc15b4f48489db8d762fb289c227b",
            "3b283ff1b3e141b9bbef0684f76a9cc6",
            "070603705dbd469781e41db2dbe4b30d",
            "4b41346e45fd46988d01496aaf1094c7",
            "f03fc16a9f9c475194317bf24d691b49",
            "592dd02a9b2f4503b3914213788f6127",
            "41e423ea043f48cfa6fb8640ac1d354c",
            "5d2f02e19ed04aaead92b5d7cdb7f3eb",
            "075a85d179cd4cc49c1e62aadd945ceb",
            "3e6aaa470c2d4bc0833ed7df8e4ac014",
            "ec3436e069b0426ab02b0ab4032e25a3",
            "152631c1d1964265a61cee294c463e83",
            "8136a23ec440412fa408e0b489c005bc",
            "5a41b5229d2d4f579b7d9d5f9b16283f",
            "f66495718fc14fe893b85cdf2f5843bd",
            "b66d4d5e08cf4f0b8f5c4beeb8188305",
            "f84b8df2c5be44eeb8df8d41cb83a3ab",
            "f358f59111364dd08fb337ceb513ea8f",
            "400f32d1ae434b468dc641a2fa727a32",
            "c2459eb72bc440bf878ab4b388c9f7e9",
            "cb1d85933639435c9924594c2fcd52a6",
            "438334d4e75c4a7ab36c04c8ed19fd05",
            "f2493b1b95354e439863a214f297886d",
            "fa8f58659e374147b4060edf4b14c300",
            "fd7cedc4077a4ad0828761da50de014b",
            "6b9caebee0f34371ab6b2e25401267e7",
            "7baeb38af2034ee9a192de15678f6343",
            "e11298a46b78472d92d7d809636a7eb7",
            "147c4a926d6a469a8b00d28c1346bb9c",
            "6b0b1971c44a4877b7eebbdd4717a022",
            "2484a4efc15647d9814c4076ac1e1e85",
            "254e00baa33d4b569ed50ea74ab2a1e2",
            "4d9cde0d5c3d44448b3d6a8419f3b100",
            "133dbdc61eb2485cad82b41e7d4d95f5",
            "ac8ca3cb7fa546479bed2b6403397bca",
            "0e550ab888104f8dab34530b1047131f",
            "f2a065c0ac1f45d192c215c0a0a143a5",
            "5a8e582d416a4491a470de1c6969ce1f"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2790ea0e8e44595b1ec464190f870c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "592dd02a9b2f4503b3914213788f6127"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f84b8df2c5be44eeb8df8d41cb83a3ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e11298a46b78472d92d7d809636a7eb7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "prefix_space = True if model_type_dict[model_checkpoint] == 'roberta-base' else False\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_type_dict[model_checkpoint],\n",
        "    use_fast = True,\n",
        "    add_prefix_space = prefix_space\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wGZn8Er5WqDQ"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(examples, label_all_tokens = False):\n",
        "\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples['tokens'],\n",
        "        truncation = True,\n",
        "        is_split_into_words = True\n",
        "    )\n",
        "    labels = []\n",
        "    \n",
        "    for i, label in enumerate(examples['ner_tags']):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        \n",
        "        for word_idx in word_ids:           \n",
        "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
        "            # ignored in the loss function.\n",
        "\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            \n",
        "            # We set the label for the first token of each word.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            \n",
        "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "            # the label_all_tokens flag.\n",
        "            else:\n",
        "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "            \n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs['labels'] = labels\n",
        "    \n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DDtsaJeVIrJT",
        "outputId": "426139b0-9780-4e5c-acd0-772d12674bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "1630f539d9374cc8b78dd8c07eb418ae",
            "4c6009a8ce8b4a0c9b3f32b2b9ff88e0",
            "8c359f11483148369d56703c5eff5b8c",
            "0f3937feac454eba89d0dde5983146a3",
            "f9aad68aded84d798160590997c46c3b",
            "eda4a547521941038a5f4e1ade748ab1",
            "a24fb4e4daf8451a9dc97d0ba8741608",
            "452dce863b5148b5808e4052dbf4a0c8",
            "5e2250271c91483eb3f511abe3cea2df",
            "5e7e7e90426f4b5994819edc9d2c248e",
            "014a170364cf48f6886fcccabf73c358",
            "079f0ea210124860ab016a59e02d22ef",
            "a4ab89d9dc8e4697a3007247b3622f25",
            "1b05832bdf4d40b28d694f0bbf3ff634",
            "11ae77fdc0724916b7f4251f60770a85",
            "f290507437cb4fcfae2567337d40d009",
            "00baa101c1c64ad19f8927e0a69996a3",
            "65ea27c558f4488ea2a8eeabf59195d8",
            "9c5f331f3f1b4949acdb97034e17674d",
            "a1336f2e26b4489b89da9879502ee28f",
            "fc06b3ccb8e14ae39a961b457aff9f1d",
            "7f78c23001d04949b505cfa3c9eb7deb",
            "1c7eae84f7b14610973c0abc98003865",
            "69f06a6ac1d14702a2b02922ec142a1d",
            "36483c915c7743c99da29e46482a3454",
            "2d92f1449151444a821d195fd208864c",
            "0c74200b146a4bc8b121778736cddd07",
            "6d58b699882c49c5ae6e69a1317b2081",
            "cfa47de663df4400a3151520142e61a1",
            "1c9815e2f80a48dd9234b0e7a0e26cad",
            "4525e8fac7004c8c8ece905e7de687bf",
            "237361e8c2434560ba5d059b683869aa",
            "e9aef0224f2644a58734abd99c962c60"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1630f539d9374cc8b78dd8c07eb418ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "079f0ea210124860ab016a59e02d22ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c7eae84f7b14610973c0abc98003865"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenized_ds = ds.map(tokenize_and_align_labels, batched = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Fine-tuning (Single Loop)**"
      ],
      "metadata": {
        "id": "wKmQPYsTQqyv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "caHE49prWqDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd53eb8b-f507-4720-ff96-458ce5e7dcac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:707: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  tensor = as_tensor(value)\n"
          ]
        }
      ],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(\n",
        "    tokenizer = tokenizer,\n",
        "    padding = True,\n",
        "    return_tensors = 'tf'\n",
        ")\n",
        "\n",
        "def batching(tokenized_ds, batch_size):\n",
        "\n",
        "    batched_train_ds = tokenized_ds['train'].to_tf_dataset(\n",
        "        columns = ['attention_mask', 'input_ids', 'labels'],\n",
        "        shuffle = True,\n",
        "        batch_size = batch_size,\n",
        "        collate_fn = data_collator,\n",
        "    )\n",
        "\n",
        "    batched_val_ds = tokenized_ds['val'].to_tf_dataset(\n",
        "        columns = ['attention_mask', 'input_ids', 'labels'],\n",
        "        shuffle = False,\n",
        "        batch_size = batch_size,\n",
        "        collate_fn = data_collator,\n",
        "    )\n",
        "\n",
        "    batched_test_ds = tokenized_ds['test'].to_tf_dataset(\n",
        "        columns = ['attention_mask', 'input_ids', 'labels'],\n",
        "        shuffle = False,\n",
        "        batch_size = batch_size,\n",
        "        collate_fn = data_collator,\n",
        "    )\n",
        "    \n",
        "    return batched_train_ds, batched_val_ds, batched_test_ds\n",
        "\n",
        "batched_train_ds, batched_val_ds, batched_test_ds = batching(tokenized_ds, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFAutoModelForTokenClassification, create_optimizer\n",
        "\n",
        "seed = 6789767\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "num_epochs = 5\n",
        "initial_lr = 2e-5\n",
        "\n",
        "def create_model(num_epochs, initial_lr):\n",
        "\n",
        "    model = TFAutoModelForTokenClassification.from_pretrained(\n",
        "        model_checkpoint,\n",
        "        num_labels = len(label_list)\n",
        "    )\n",
        "\n",
        "    batches_per_epoch = len(tokenized_ds['train']) // batch_size\n",
        "    total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "\n",
        "    optimizer, schedule = create_optimizer(\n",
        "        init_lr = initial_lr,\n",
        "        num_warmup_steps = total_train_steps // 20,\n",
        "        num_train_steps = total_train_steps,\n",
        "        weight_decay_rate = 0.01\n",
        "    )\n",
        "\n",
        "    model.compile(optimizer = optimizer)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_model(num_epochs, initial_lr)"
      ],
      "metadata": {
        "id": "P2JF0qbzcKAQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "a50b479ef0834015ba37b38afa30a7d8",
            "5e25d9fe549e48d0974a429ea41dc440",
            "d82ef27ac0c24728af54d3b1f7623c6a",
            "4c3b95c54ab54276962ec74930761bb5",
            "cdc4759a0c4848488e879fe5da6338a0",
            "f246edd46a9346a3abbb78b814dbe16b",
            "3e950e70b95d4839bf6ecc4ea3d7a6f5",
            "8b5d51adf6e24d5f9591b1696a2cc910",
            "8429174e0bf6467cb1e25b8178f8214d",
            "91f529ee7ef8475faf11470a6accadd5",
            "2b6dece5edbb46d1a5b5a6cf01754b48"
          ]
        },
        "outputId": "1c970107-52ec-4cf7-9ada-a083df17b00d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/502M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a50b479ef0834015ba37b38afa30a7d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlqNaB8jIrJW"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from transformers.keras_callbacks import KerasMetricCallback\n",
        "\n",
        "# metric = load_metric(\"seqeval\")\n",
        "# labels = [label_list[i] for i in example['concept_tags']]\n",
        "# metric.compute(predictions=[labels], references=[labels])\n",
        "\n",
        "# def compute_metrics(p):\n",
        "#     predictions, labels = p\n",
        "#     # predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "#     # Remove ignored index (special tokens)\n",
        "#     true_predictions = [\n",
        "#         [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "#         for prediction, label in zip(predictions, labels)\n",
        "#     ]\n",
        "#     true_labels = [\n",
        "#         [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "#         for prediction, label in zip(predictions, labels)\n",
        "#     ]\n",
        "\n",
        "#     results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "#     return {\n",
        "#         \"precision\": results[\"overall_precision\"],\n",
        "#         \"recall\": results[\"overall_recall\"],\n",
        "#         \"f1\": results[\"overall_f1\"],\n",
        "#         \"accuracy\": results[\"overall_accuracy\"],\n",
        "#     }\n",
        "\n",
        "# metric_callback = KerasMetricCallback(\n",
        "#     metric_fn=compute_metrics, eval_dataset=validation_set\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, CSVLogger\n",
        "\n",
        "class update_logger(Callback):\n",
        "\n",
        "    def __init__(self):    \n",
        "        super(update_logger, self).__init__()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs = {}):\n",
        "        logs['seed'] = seed\n",
        "        logs['batch_size'] = batch_size\n",
        "        logs['learning_rate'] = initial_lr\n",
        "\n",
        "update_logger_cb = update_logger()\n",
        "\n",
        "csvlogger_file = f'{task_name_dict[ds_name]}-{model_name_dict[model_checkpoint]}.csv'\n",
        "csvlogger_cb = CSVLogger(csvlogger_file, append = True)\n",
        "\n",
        "callbacks = [update_logger_cb, csvlogger_cb]"
      ],
      "metadata": {
        "id": "wmjnGrL4Ln9t"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "J6fjhEr0WqDS",
        "outputId": "3249ae0f-cdc1-4836-8abd-4a0bf9cfc08a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:707: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  tensor = as_tensor(value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 28s 248ms/step - loss: nan - val_loss: nan - seed: 6789767.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "40/40 [==============================] - 7s 170ms/step - loss: nan - val_loss: nan - seed: 6789767.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "12/40 [========>.....................] - ETA: 4s - loss: nan"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c0ec5d30c2f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatched_val_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# model = create_model(num_epochs, initial_lr)\n",
        "\n",
        "model.fit(\n",
        "    batched_train_ds,\n",
        "    validation_data = batched_val_ds,\n",
        "    epochs = num_epochs,\n",
        "    callbacks = callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hyperparameter tuning**"
      ],
      "metadata": {
        "id": "iPOAWvTPQznQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sizes = [8] if model_type_dict[model_checkpoint] == 'roberta-base' else [8, 16]\n",
        "initial_lrs = [5e-5, 3e-5, 2e-5]\n",
        "seeds = [21916, 25412, 56281, 61712, 30488,\n",
        "         28215, 78867, 87843, 67918, 93327,\n",
        "         95420, 11905, 86349, 12082, 81996]\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "\n",
        "    batched_train_ds, batched_val_ds, batched_test_ds = batching(tokenized_ds, batch_size)\n",
        "    \n",
        "    for initial_lr in initial_lrs:\n",
        "    \n",
        "        for seed in seeds:\n",
        "    \n",
        "            tf.random.set_seed(seed)\n",
        "            model = create_model(num_epochs, initial_lr)\n",
        "\n",
        "            csvlogger_file = f'{model_name_dict[model_checkpoint]}-{task_name_dict[ds_name]}.csv'\n",
        "            csvlogger_cb = CSVLogger(csvlogger_file, append = True)\n",
        "\n",
        "            callbacks = [update_logger_cb, csvlogger_cb]\n",
        "\n",
        "            model.fit(\n",
        "                batched_train_ds,\n",
        "                validation_data = batched_val_ds,\n",
        "                epochs = num_epochs,\n",
        "                callbacks = callbacks\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkb_UO8TQ0HR",
        "outputId": "102cedc5-e441-4f9c-f4fb-ba4ca0810744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:707: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  tensor = as_tensor(value)\n",
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 201ms/step - loss: 1.3934 - val_loss: 0.8224 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.6133 - val_loss: 0.5671 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.3711 - val_loss: 0.5052 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 163ms/step - loss: 0.2369 - val_loss: 0.5099 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.1743 - val_loss: 0.5249 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 201ms/step - loss: 1.3973 - val_loss: 0.9366 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.6913 - val_loss: 0.6081 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.4025 - val_loss: 0.5586 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.2572 - val_loss: 0.5455 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.1870 - val_loss: 0.5467 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 31s 202ms/step - loss: 1.3920 - val_loss: 0.8548 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.6572 - val_loss: 0.5945 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.4051 - val_loss: 0.5353 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 164ms/step - loss: 0.2669 - val_loss: 0.5242 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.1988 - val_loss: 0.5303 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 199ms/step - loss: 1.3565 - val_loss: 0.8414 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.6254 - val_loss: 0.5783 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.3632 - val_loss: 0.5147 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 0.2390 - val_loss: 0.5151 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.1712 - val_loss: 0.5164 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 202ms/step - loss: 1.3434 - val_loss: 0.8634 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.6443 - val_loss: 0.5996 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.3768 - val_loss: 0.5071 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.2396 - val_loss: 0.5083 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.1732 - val_loss: 0.5212 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 31s 203ms/step - loss: 1.3734 - val_loss: 0.8050 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.6353 - val_loss: 0.6051 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.3739 - val_loss: 0.5214 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.2383 - val_loss: 0.5269 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.1738 - val_loss: 0.5222 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 201ms/step - loss: 1.3413 - val_loss: 0.8800 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 0.6484 - val_loss: 0.5964 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.3844 - val_loss: 0.5382 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.2486 - val_loss: 0.5264 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.1808 - val_loss: 0.5340 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 200ms/step - loss: 1.3403 - val_loss: 0.8435 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.6204 - val_loss: 0.5905 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.3817 - val_loss: 0.5358 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.2481 - val_loss: 0.5148 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.1859 - val_loss: 0.5284 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 31s 205ms/step - loss: 1.3710 - val_loss: 0.8334 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.6412 - val_loss: 0.6310 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.3860 - val_loss: 0.5198 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.2539 - val_loss: 0.5285 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.1839 - val_loss: 0.5367 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 200ms/step - loss: 1.4266 - val_loss: 0.8618 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.6539 - val_loss: 0.6019 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.3821 - val_loss: 0.5480 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 159ms/step - loss: 0.2439 - val_loss: 0.5271 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.1805 - val_loss: 0.5331 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 203ms/step - loss: 1.3160 - val_loss: 0.7994 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 162ms/step - loss: 0.6120 - val_loss: 0.5896 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.3689 - val_loss: 0.5439 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.2369 - val_loss: 0.5178 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 162ms/step - loss: 0.1764 - val_loss: 0.5235 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 204ms/step - loss: 1.3424 - val_loss: 0.8402 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.6402 - val_loss: 0.6449 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 164ms/step - loss: 0.3962 - val_loss: 0.5352 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.2526 - val_loss: 0.5351 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.1876 - val_loss: 0.5235 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 208ms/step - loss: 1.3014 - val_loss: 0.8699 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.6572 - val_loss: 0.6375 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.3863 - val_loss: 0.5283 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.2451 - val_loss: 0.5173 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.1825 - val_loss: 0.5258 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 210ms/step - loss: 1.3245 - val_loss: 0.8150 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.6338 - val_loss: 0.5706 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.3762 - val_loss: 0.5433 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.2426 - val_loss: 0.5284 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.1790 - val_loss: 0.5316 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 200ms/step - loss: 1.2865 - val_loss: 0.8331 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.6373 - val_loss: 0.6349 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.3847 - val_loss: 0.5365 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.2444 - val_loss: 0.5425 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.1788 - val_loss: 0.5620 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 31s 203ms/step - loss: 1.4469 - val_loss: 0.9212 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.7203 - val_loss: 0.6569 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.4866 - val_loss: 0.5549 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 0.3611 - val_loss: 0.5355 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.2966 - val_loss: 0.5367 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 199ms/step - loss: 1.4616 - val_loss: 0.9171 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.7241 - val_loss: 0.6401 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.4737 - val_loss: 0.5637 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.3436 - val_loss: 0.5483 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.2817 - val_loss: 0.5431 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 202ms/step - loss: 1.4602 - val_loss: 0.9354 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.7552 - val_loss: 0.7062 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.5142 - val_loss: 0.5859 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 163ms/step - loss: 0.3861 - val_loss: 0.5594 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.3166 - val_loss: 0.5554 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 203ms/step - loss: 1.4123 - val_loss: 0.9779 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 160ms/step - loss: 0.7454 - val_loss: 0.6545 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.4824 - val_loss: 0.5561 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.3481 - val_loss: 0.5303 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 161ms/step - loss: 0.2866 - val_loss: 0.5277 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 198ms/step - loss: 1.4564 - val_loss: 0.9667 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.7543 - val_loss: 0.6900 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.5038 - val_loss: 0.5993 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.3712 - val_loss: 0.5630 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.3051 - val_loss: 0.5523 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 29s 196ms/step - loss: 1.5129 - val_loss: 0.9606 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.7722 - val_loss: 0.6727 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.5132 - val_loss: 0.5619 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.3778 - val_loss: 0.5422 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.3071 - val_loss: 0.5403 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 202ms/step - loss: 1.4752 - val_loss: 0.9827 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 159ms/step - loss: 0.7707 - val_loss: 0.6809 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.5064 - val_loss: 0.5908 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.3737 - val_loss: 0.5576 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.3084 - val_loss: 0.5516 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 214ms/step - loss: 1.4705 - val_loss: 0.9558 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.7505 - val_loss: 0.7155 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.5182 - val_loss: 0.5973 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.3916 - val_loss: 0.5671 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.3253 - val_loss: 0.5597 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 211ms/step - loss: 1.4544 - val_loss: 0.9652 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 162ms/step - loss: 0.7816 - val_loss: 0.6811 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.5225 - val_loss: 0.5798 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.3857 - val_loss: 0.5610 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.3189 - val_loss: 0.5572 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 211ms/step - loss: 1.5049 - val_loss: 1.0099 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.7949 - val_loss: 0.7015 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 164ms/step - loss: 0.5300 - val_loss: 0.5989 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.3936 - val_loss: 0.5527 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.3168 - val_loss: 0.5516 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 209ms/step - loss: 1.4068 - val_loss: 0.9132 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.7308 - val_loss: 0.6696 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.4891 - val_loss: 0.5954 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.3650 - val_loss: 0.5563 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.3022 - val_loss: 0.5474 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 208ms/step - loss: 1.4339 - val_loss: 0.9387 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.7535 - val_loss: 0.6796 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.5116 - val_loss: 0.5788 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.3779 - val_loss: 0.5517 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.3127 - val_loss: 0.5444 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 210ms/step - loss: 1.4308 - val_loss: 0.9823 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 162ms/step - loss: 0.7818 - val_loss: 0.7195 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 164ms/step - loss: 0.5237 - val_loss: 0.5969 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 162ms/step - loss: 0.3944 - val_loss: 0.5716 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.3265 - val_loss: 0.5553 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 31s 203ms/step - loss: 1.3878 - val_loss: 0.9596 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 162ms/step - loss: 0.7469 - val_loss: 0.6549 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.5003 - val_loss: 0.5861 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.3694 - val_loss: 0.5482 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.3094 - val_loss: 0.5447 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 198ms/step - loss: 1.4422 - val_loss: 0.9136 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.7330 - val_loss: 0.6708 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.4928 - val_loss: 0.5936 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.3686 - val_loss: 0.5512 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.3056 - val_loss: 0.5467 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 200ms/step - loss: 1.5399 - val_loss: 1.0286 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 158ms/step - loss: 0.8493 - val_loss: 0.7581 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.6220 - val_loss: 0.6565 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 158ms/step - loss: 0.5032 - val_loss: 0.6112 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.4434 - val_loss: 0.6002 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 198ms/step - loss: 1.5785 - val_loss: 1.0496 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.8754 - val_loss: 0.7892 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.6377 - val_loss: 0.6527 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 159ms/step - loss: 0.5083 - val_loss: 0.6073 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.4402 - val_loss: 0.6063 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 196ms/step - loss: 1.6036 - val_loss: 1.0236 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.8674 - val_loss: 0.8015 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.6551 - val_loss: 0.6784 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.5302 - val_loss: 0.6338 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.4688 - val_loss: 0.6212 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 201ms/step - loss: 1.4928 - val_loss: 1.0487 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.8675 - val_loss: 0.7481 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 159ms/step - loss: 0.6170 - val_loss: 0.6333 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 161ms/step - loss: 0.4777 - val_loss: 0.5891 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.4143 - val_loss: 0.5805 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 199ms/step - loss: 1.5076 - val_loss: 1.0585 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.8823 - val_loss: 0.7758 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.6297 - val_loss: 0.6518 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.4943 - val_loss: 0.6035 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.4288 - val_loss: 0.5968 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 199ms/step - loss: 1.6249 - val_loss: 1.0412 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 0.8673 - val_loss: 0.7713 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.6321 - val_loss: 0.6511 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.5021 - val_loss: 0.5982 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.4320 - val_loss: 0.5889 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 200ms/step - loss: 1.5549 - val_loss: 1.0720 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.8783 - val_loss: 0.7851 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.6309 - val_loss: 0.6567 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.4960 - val_loss: 0.6074 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.4303 - val_loss: 0.5952 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 201ms/step - loss: 1.6366 - val_loss: 1.0358 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.8668 - val_loss: 0.7998 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.6340 - val_loss: 0.6899 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.5136 - val_loss: 0.6349 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.4523 - val_loss: 0.6258 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 201ms/step - loss: 1.5485 - val_loss: 1.0563 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.8816 - val_loss: 0.7870 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.6430 - val_loss: 0.6737 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.5197 - val_loss: 0.6319 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.4553 - val_loss: 0.6192 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 31s 206ms/step - loss: 1.5694 - val_loss: 1.0746 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.8959 - val_loss: 0.8056 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.6451 - val_loss: 0.6677 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 163ms/step - loss: 0.5121 - val_loss: 0.6322 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.4505 - val_loss: 0.6123 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 199ms/step - loss: 1.5692 - val_loss: 1.0250 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.8566 - val_loss: 0.7705 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.6232 - val_loss: 0.6580 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.4986 - val_loss: 0.6214 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.4399 - val_loss: 0.6054 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 31s 209ms/step - loss: 1.5227 - val_loss: 1.0428 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.8450 - val_loss: 0.7797 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.6256 - val_loss: 0.6737 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.5003 - val_loss: 0.6211 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 162ms/step - loss: 0.4368 - val_loss: 0.6094 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 211ms/step - loss: 1.5221 - val_loss: 1.0620 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.8946 - val_loss: 0.7892 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.6419 - val_loss: 0.6677 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.5128 - val_loss: 0.6295 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.4487 - val_loss: 0.6112 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 211ms/step - loss: 1.5818 - val_loss: 1.0365 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.8723 - val_loss: 0.7620 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.6272 - val_loss: 0.6561 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.5015 - val_loss: 0.6135 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.4385 - val_loss: 0.5968 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 203ms/step - loss: 1.6052 - val_loss: 1.0317 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.8756 - val_loss: 0.7737 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.6307 - val_loss: 0.6576 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.4987 - val_loss: 0.6224 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.4366 - val_loss: 0.6150 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 428ms/step - loss: 1.6118 - val_loss: 1.0057 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 373ms/step - loss: 0.8094 - val_loss: 0.7119 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 0.5481 - val_loss: 0.6028 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 337ms/step - loss: 0.3957 - val_loss: 0.5580 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 368ms/step - loss: 0.3234 - val_loss: 0.5506 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 421ms/step - loss: 1.6256 - val_loss: 1.0747 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 344ms/step - loss: 0.8796 - val_loss: 0.7625 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 0.5792 - val_loss: 0.6166 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 355ms/step - loss: 0.4105 - val_loss: 0.5649 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 360ms/step - loss: 0.3280 - val_loss: 0.5666 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 32s 430ms/step - loss: 1.6206 - val_loss: 1.0549 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 0.8602 - val_loss: 0.7539 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 363ms/step - loss: 0.6031 - val_loss: 0.6433 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 352ms/step - loss: 0.4556 - val_loss: 0.5925 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 364ms/step - loss: 0.3737 - val_loss: 0.5861 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 422ms/step - loss: 1.5470 - val_loss: 1.0511 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 340ms/step - loss: 0.8373 - val_loss: 0.7050 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 352ms/step - loss: 0.5360 - val_loss: 0.5998 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 363ms/step - loss: 0.3901 - val_loss: 0.5550 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 356ms/step - loss: 0.3137 - val_loss: 0.5419 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 415ms/step - loss: 1.5247 - val_loss: 1.0626 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 348ms/step - loss: 0.8517 - val_loss: 0.7327 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 0.5546 - val_loss: 0.5934 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 364ms/step - loss: 0.4022 - val_loss: 0.5736 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 341ms/step - loss: 0.3196 - val_loss: 0.5578 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 430ms/step - loss: 1.5954 - val_loss: 1.0301 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 351ms/step - loss: 0.8333 - val_loss: 0.7360 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 343ms/step - loss: 0.5726 - val_loss: 0.6045 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 349ms/step - loss: 0.4133 - val_loss: 0.5832 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 354ms/step - loss: 0.3330 - val_loss: 0.5649 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 412ms/step - loss: 1.5398 - val_loss: 1.0638 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 359ms/step - loss: 0.8897 - val_loss: 0.8191 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 374ms/step - loss: 0.5966 - val_loss: 0.6443 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 366ms/step - loss: 0.4280 - val_loss: 0.5951 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 358ms/step - loss: 0.3526 - val_loss: 0.5831 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 429ms/step - loss: 1.5480 - val_loss: 1.0257 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 353ms/step - loss: 0.8407 - val_loss: 0.7662 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 0.5884 - val_loss: 0.6503 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 356ms/step - loss: 0.4344 - val_loss: 0.5971 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 355ms/step - loss: 0.3610 - val_loss: 0.5947 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 422ms/step - loss: 1.5790 - val_loss: 1.0424 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 360ms/step - loss: 0.8491 - val_loss: 0.7700 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 356ms/step - loss: 0.5745 - val_loss: 0.6111 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 358ms/step - loss: 0.4181 - val_loss: 0.5693 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 0.3429 - val_loss: 0.5599 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 418ms/step - loss: 1.6322 - val_loss: 1.0745 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 0.9017 - val_loss: 0.7994 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 376ms/step - loss: 0.6264 - val_loss: 0.6650 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 334ms/step - loss: 0.4567 - val_loss: 0.6037 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 354ms/step - loss: 0.3688 - val_loss: 0.6011 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 428ms/step - loss: 1.5313 - val_loss: 1.0277 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 345ms/step - loss: 0.8376 - val_loss: 0.7471 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 0.5746 - val_loss: 0.6159 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 369ms/step - loss: 0.4141 - val_loss: 0.5733 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 334ms/step - loss: 0.3373 - val_loss: 0.5646 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 422ms/step - loss: 1.5859 - val_loss: 1.0545 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 345ms/step - loss: 0.8456 - val_loss: 0.7678 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 0.5791 - val_loss: 0.6353 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 356ms/step - loss: 0.4240 - val_loss: 0.5844 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 358ms/step - loss: 0.3439 - val_loss: 0.5710 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 414ms/step - loss: 1.4739 - val_loss: 1.0637 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 366ms/step - loss: 0.8658 - val_loss: 0.7676 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 358ms/step - loss: 0.5846 - val_loss: 0.6282 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 364ms/step - loss: 0.4256 - val_loss: 0.5780 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 345ms/step - loss: 0.3494 - val_loss: 0.5719 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            " 6/38 [===>..........................] - ETA: 6s - loss: 2.9276WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1105s vs `on_train_batch_end` time: 0.1159s). Check your callbacks.\n",
            "38/38 [==============================] - 30s 417ms/step - loss: 1.5371 - val_loss: 1.0702 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 0.8522 - val_loss: 0.7325 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 356ms/step - loss: 0.5709 - val_loss: 0.6132 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 352ms/step - loss: 0.4131 - val_loss: 0.5694 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 351ms/step - loss: 0.3380 - val_loss: 0.5578 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 432ms/step - loss: 1.4936 - val_loss: 1.0236 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 365ms/step - loss: 0.8327 - val_loss: 0.7418 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 338ms/step - loss: 0.5731 - val_loss: 0.6224 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 360ms/step - loss: 0.4181 - val_loss: 0.5899 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 342ms/step - loss: 0.3389 - val_loss: 0.5769 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 442ms/step - loss: 1.6765 - val_loss: 1.1097 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 356ms/step - loss: 0.9403 - val_loss: 0.8415 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 358ms/step - loss: 0.7038 - val_loss: 0.7030 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 0.5645 - val_loss: 0.6512 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 353ms/step - loss: 0.4952 - val_loss: 0.6372 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 423ms/step - loss: 1.6939 - val_loss: 1.1107 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 355ms/step - loss: 0.9914 - val_loss: 0.8992 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 351ms/step - loss: 0.7464 - val_loss: 0.7474 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 368ms/step - loss: 0.5968 - val_loss: 0.6788 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 341ms/step - loss: 0.5256 - val_loss: 0.6599 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 442ms/step - loss: 1.6890 - val_loss: 1.1088 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 368ms/step - loss: 0.9561 - val_loss: 0.8894 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 355ms/step - loss: 0.7308 - val_loss: 0.7429 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 355ms/step - loss: 0.6004 - val_loss: 0.6798 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 0.5370 - val_loss: 0.6634 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 437ms/step - loss: 1.6174 - val_loss: 1.1030 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 341ms/step - loss: 0.9854 - val_loss: 0.8867 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 362ms/step - loss: 0.7277 - val_loss: 0.7103 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 358ms/step - loss: 0.5684 - val_loss: 0.6577 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 352ms/step - loss: 0.4950 - val_loss: 0.6363 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 29s 403ms/step - loss: 1.6497 - val_loss: 1.1033 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 362ms/step - loss: 0.9695 - val_loss: 0.8767 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 351ms/step - loss: 0.7211 - val_loss: 0.7232 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 343ms/step - loss: 0.5725 - val_loss: 0.6621 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 369ms/step - loss: 0.4993 - val_loss: 0.6444 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 418ms/step - loss: 1.7355 - val_loss: 1.1147 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 358ms/step - loss: 0.9618 - val_loss: 0.8798 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 343ms/step - loss: 0.7339 - val_loss: 0.7317 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 345ms/step - loss: 0.5912 - val_loss: 0.6665 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 349ms/step - loss: 0.5182 - val_loss: 0.6453 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 441ms/step - loss: 1.6610 - val_loss: 1.1147 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 346ms/step - loss: 0.9802 - val_loss: 0.8704 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 358ms/step - loss: 0.7165 - val_loss: 0.7333 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 350ms/step - loss: 0.5651 - val_loss: 0.6646 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 353ms/step - loss: 0.4933 - val_loss: 0.6482 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 449ms/step - loss: 1.6787 - val_loss: 1.1061 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 366ms/step - loss: 0.9447 - val_loss: 0.8697 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 369ms/step - loss: 0.7137 - val_loss: 0.7294 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 370ms/step - loss: 0.5825 - val_loss: 0.6682 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 358ms/step - loss: 0.5134 - val_loss: 0.6561 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 424ms/step - loss: 1.6337 - val_loss: 1.1108 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 341ms/step - loss: 0.9883 - val_loss: 0.8768 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 355ms/step - loss: 0.7438 - val_loss: 0.7467 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 356ms/step - loss: 0.6031 - val_loss: 0.6837 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 345ms/step - loss: 0.5327 - val_loss: 0.6696 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 424ms/step - loss: 1.6907 - val_loss: 1.1188 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 0.9991 - val_loss: 0.9165 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 345ms/step - loss: 0.7612 - val_loss: 0.7658 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 355ms/step - loss: 0.6070 - val_loss: 0.6913 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 368ms/step - loss: 0.5315 - val_loss: 0.6714 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 420ms/step - loss: 1.6134 - val_loss: 1.0907 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 369ms/step - loss: 0.9487 - val_loss: 0.8688 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 355ms/step - loss: 0.7106 - val_loss: 0.7373 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 365ms/step - loss: 0.5753 - val_loss: 0.6711 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 364ms/step - loss: 0.5054 - val_loss: 0.6570 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 428ms/step - loss: 1.6610 - val_loss: 1.1105 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 364ms/step - loss: 0.9562 - val_loss: 0.8711 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 374ms/step - loss: 0.7221 - val_loss: 0.7427 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 353ms/step - loss: 0.5886 - val_loss: 0.6791 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 353ms/step - loss: 0.5202 - val_loss: 0.6579 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 418ms/step - loss: 1.6020 - val_loss: 1.1083 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 330ms/step - loss: 0.9901 - val_loss: 0.9132 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 351ms/step - loss: 0.7579 - val_loss: 0.7620 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 355ms/step - loss: 0.6115 - val_loss: 0.6958 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 344ms/step - loss: 0.5339 - val_loss: 0.6732 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 420ms/step - loss: 1.5925 - val_loss: 1.1119 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 354ms/step - loss: 0.9653 - val_loss: 0.8499 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 352ms/step - loss: 0.7155 - val_loss: 0.7024 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 354ms/step - loss: 0.5683 - val_loss: 0.6533 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 351ms/step - loss: 0.4978 - val_loss: 0.6301 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 408ms/step - loss: 1.6654 - val_loss: 1.0864 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 364ms/step - loss: 0.9618 - val_loss: 0.8617 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 356ms/step - loss: 0.7261 - val_loss: 0.7233 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 365ms/step - loss: 0.5796 - val_loss: 0.6732 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 366ms/step - loss: 0.5098 - val_loss: 0.6608 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 410ms/step - loss: 1.7737 - val_loss: 1.1437 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 334ms/step - loss: 1.0440 - val_loss: 0.9488 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 358ms/step - loss: 0.8274 - val_loss: 0.8175 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 330ms/step - loss: 0.7036 - val_loss: 0.7563 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 354ms/step - loss: 0.6441 - val_loss: 0.7352 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 427ms/step - loss: 1.8002 - val_loss: 1.1562 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 1.0708 - val_loss: 1.0006 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 0.8746 - val_loss: 0.8629 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 345ms/step - loss: 0.7459 - val_loss: 0.7883 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 344ms/step - loss: 0.6798 - val_loss: 0.7711 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 411ms/step - loss: 1.8523 - val_loss: 1.1452 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 360ms/step - loss: 1.0540 - val_loss: 0.9802 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 348ms/step - loss: 0.8606 - val_loss: 0.8528 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 352ms/step - loss: 0.7423 - val_loss: 0.7930 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 360ms/step - loss: 0.6827 - val_loss: 0.7745 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 428ms/step - loss: 1.6985 - val_loss: 1.1326 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 343ms/step - loss: 1.0579 - val_loss: 0.9970 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 331ms/step - loss: 0.8764 - val_loss: 0.8446 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 343ms/step - loss: 0.7238 - val_loss: 0.7643 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 354ms/step - loss: 0.6552 - val_loss: 0.7380 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 403ms/step - loss: 1.7071 - val_loss: 1.1390 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 352ms/step - loss: 1.0619 - val_loss: 0.9939 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 342ms/step - loss: 0.8763 - val_loss: 0.8563 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 346ms/step - loss: 0.7336 - val_loss: 0.7750 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 369ms/step - loss: 0.6664 - val_loss: 0.7576 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 432ms/step - loss: 1.8574 - val_loss: 1.1610 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 1.0551 - val_loss: 0.9808 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 364ms/step - loss: 0.8565 - val_loss: 0.8465 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 359ms/step - loss: 0.7277 - val_loss: 0.7723 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 362ms/step - loss: 0.6647 - val_loss: 0.7518 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 425ms/step - loss: 1.7703 - val_loss: 1.1430 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 352ms/step - loss: 1.0639 - val_loss: 1.0137 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 0.8930 - val_loss: 0.8738 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 364ms/step - loss: 0.7468 - val_loss: 0.8002 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 363ms/step - loss: 0.6801 - val_loss: 0.7813 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 413ms/step - loss: 1.8700 - val_loss: 1.1462 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 1.0483 - val_loss: 0.9916 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 374ms/step - loss: 0.8626 - val_loss: 0.8661 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 339ms/step - loss: 0.7332 - val_loss: 0.7997 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 341ms/step - loss: 0.6708 - val_loss: 0.7752 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 429ms/step - loss: 1.7603 - val_loss: 1.1537 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 1.0637 - val_loss: 0.9966 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 0.8695 - val_loss: 0.8493 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 356ms/step - loss: 0.7338 - val_loss: 0.7843 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 367ms/step - loss: 0.6755 - val_loss: 0.7638 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 435ms/step - loss: 1.7878 - val_loss: 1.1677 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 367ms/step - loss: 1.0862 - val_loss: 1.0118 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 360ms/step - loss: 0.8927 - val_loss: 0.8761 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 350ms/step - loss: 0.7538 - val_loss: 0.8058 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 342ms/step - loss: 0.6924 - val_loss: 0.7830 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 426ms/step - loss: 1.8068 - val_loss: 1.1369 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 360ms/step - loss: 1.0514 - val_loss: 0.9810 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 353ms/step - loss: 0.8627 - val_loss: 0.8483 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 357ms/step - loss: 0.7336 - val_loss: 0.7830 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 355ms/step - loss: 0.6691 - val_loss: 0.7625 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 467ms/step - loss: 1.7360 - val_loss: 1.1587 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 363ms/step - loss: 1.0461 - val_loss: 0.9686 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 0.8473 - val_loss: 0.8450 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 357ms/step - loss: 0.7211 - val_loss: 0.7807 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 356ms/step - loss: 0.6619 - val_loss: 0.7664 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 448ms/step - loss: 1.7338 - val_loss: 1.1478 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 358ms/step - loss: 1.0754 - val_loss: 1.0255 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 0.9006 - val_loss: 0.8863 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 363ms/step - loss: 0.7675 - val_loss: 0.8129 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 337ms/step - loss: 0.7015 - val_loss: 0.7848 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 457ms/step - loss: 1.8019 - val_loss: 1.1431 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 353ms/step - loss: 1.0693 - val_loss: 0.9854 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 362ms/step - loss: 0.8654 - val_loss: 0.8441 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 362ms/step - loss: 0.7307 - val_loss: 0.7663 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 342ms/step - loss: 0.6643 - val_loss: 0.7453 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 417ms/step - loss: 1.8246 - val_loss: 1.1301 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 355ms/step - loss: 1.0491 - val_loss: 0.9758 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 352ms/step - loss: 0.8521 - val_loss: 0.8437 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 355ms/step - loss: 0.7317 - val_loss: 0.7784 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 355ms/step - loss: 0.6668 - val_loss: 0.7638 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate on test set**"
      ],
      "metadata": {
        "id": "Zpt3-j6pCDGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicts = [model.predict(batch) for batch in batched_test_ds]"
      ],
      "metadata": {
        "id": "WiH14zw_D__V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "all_preds = []\n",
        "all_trues = []\n",
        "\n",
        "for batch in batched_test_ds:\n",
        "\n",
        "    y_preds_logits = model.predict(batch)['logits']\n",
        "    y_preds = np.argmax(y_preds_logits, axis = 2)\n",
        "    y_trues = batch['labels']\n",
        "    p = y_preds, y_trues\n",
        "\n",
        "    all_pred = [\n",
        "        [label_list[p] for (p, l) in zip(y_pred, y_true) if l != -100]\n",
        "        for y_pred, y_true in zip(y_preds, y_trues)]\n",
        "    all_true = [\n",
        "        [label_list[l] for (p, l) in zip(y_pred, y_true) if l != -100]\n",
        "        for y_pred, y_true in zip(y_preds, y_trues)]\n",
        "    \n",
        "    all_preds.extend([item for sublist in all_pred for item in sublist])\n",
        "    all_trues.extend([item for sublist in all_true for item in sublist])\n",
        "    \n",
        "    # break"
      ],
      "metadata": {
        "id": "1rqBsfR4ETCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(all_trues, all_preds))\n",
        "cr = classification_report(all_trues, all_preds, output_dict = True)"
      ],
      "metadata": {
        "id": "yY9VTrwMHKmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(cr)"
      ],
      "metadata": {
        "id": "dTq-5y5lIL7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction Pipeline**"
      ],
      "metadata": {
        "id": "ya4eePzoB8n4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TokenClassificationPipeline\n",
        "\n",
        "pipe = TokenClassificationPipeline(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    # aggregation_strategy = 'simple'\n",
        ")"
      ],
      "metadata": {
        "id": "kGyJ2dQvqqKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'The Micro-VCM datasheet shall contain the product type.'\n",
        "text = 'Storage conditions shall prevent the degredation of the structure.'\n",
        "text = 'A record of the process data shall be part of the process procedure'\n",
        "text = 'In case of doubt, the internal NRB shall classify nonconformances as major.'\n",
        "text = 'The Reserved shall be an 8-bit field that is set to 0x00.'\n",
        "\n",
        "pipe(text)"
      ],
      "metadata": {
        "id": "nyT6fezQCAGQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "t3_finetuning_seqlabel_cr",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "Zpt3-j6pCDGC",
        "ya4eePzoB8n4"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "82cc9bfa8fad47ed96ba9c8859a88965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9419781c2cbf4d4bb66fbe16147f28f3",
              "IPY_MODEL_b152fcaf325242e2a86d5e2755fa51e2",
              "IPY_MODEL_dfaea0da0e9e4255933b6c47f16660c5"
            ],
            "layout": "IPY_MODEL_068d53547f034a76998280c879bdfe59"
          }
        },
        "9419781c2cbf4d4bb66fbe16147f28f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c085bbda6a4e4c2da7f63070724e49bd",
            "placeholder": "​",
            "style": "IPY_MODEL_bff0a723d43442d4b3907fd84910f3d7",
            "value": "Downloading: 100%"
          }
        },
        "b152fcaf325242e2a86d5e2755fa51e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a625a4182d343379cf24be0d85e7c0b",
            "max": 1217,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc9ae3683f8b4ff885f37e6d9e47ca6a",
            "value": 1217
          }
        },
        "dfaea0da0e9e4255933b6c47f16660c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6abb7fb9336f49ca8a9fe4658ff66ed7",
            "placeholder": "​",
            "style": "IPY_MODEL_95fd69407c854c93acbc95613a81ab9b",
            "value": " 1.22k/1.22k [00:00&lt;00:00, 44.7kB/s]"
          }
        },
        "068d53547f034a76998280c879bdfe59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c085bbda6a4e4c2da7f63070724e49bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bff0a723d43442d4b3907fd84910f3d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a625a4182d343379cf24be0d85e7c0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc9ae3683f8b4ff885f37e6d9e47ca6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6abb7fb9336f49ca8a9fe4658ff66ed7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95fd69407c854c93acbc95613a81ab9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54c36d4a81b7404c9472b4e366d65e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcb609f8fc30466abfb7fab22b87c6d1",
              "IPY_MODEL_42c726ef1bd64695bb714ffacf0ba9d2",
              "IPY_MODEL_f54988f13a7744b2b034233afcc40dbb"
            ],
            "layout": "IPY_MODEL_593384d294a944e6a8fc024f89353b44"
          }
        },
        "fcb609f8fc30466abfb7fab22b87c6d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60e8a005f3854139b322e387e6acda4f",
            "placeholder": "​",
            "style": "IPY_MODEL_9035232f37f94d45ad15360051a52d60",
            "value": "Downloading data files: 100%"
          }
        },
        "42c726ef1bd64695bb714ffacf0ba9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29aa9b1d36f94867a127b08d17150ce7",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c39bf19d21e42c197044c4852f1f3eb",
            "value": 3
          }
        },
        "f54988f13a7744b2b034233afcc40dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0af9244b60544a48a441229a9ae03e6d",
            "placeholder": "​",
            "style": "IPY_MODEL_bfa7628750db4553b607a330e4e995cf",
            "value": " 3/3 [00:03&lt;00:00,  1.26s/it]"
          }
        },
        "593384d294a944e6a8fc024f89353b44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60e8a005f3854139b322e387e6acda4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9035232f37f94d45ad15360051a52d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29aa9b1d36f94867a127b08d17150ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c39bf19d21e42c197044c4852f1f3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0af9244b60544a48a441229a9ae03e6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfa7628750db4553b607a330e4e995cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b4921e11c674d719efde3c718bfb456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4abb482d62984706ba599dc78756cfe9",
              "IPY_MODEL_4083ddf15b494cc7815f90cb1423177f",
              "IPY_MODEL_3b80fd67bb3b46e5b30121398522abc8"
            ],
            "layout": "IPY_MODEL_8992e627cfed418eb8e5e4ac2c72ee34"
          }
        },
        "4abb482d62984706ba599dc78756cfe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6033066ea154a249c7cfad2f17bf209",
            "placeholder": "​",
            "style": "IPY_MODEL_80427df9bae145f29105e4a2139488cd",
            "value": "Downloading data: 100%"
          }
        },
        "4083ddf15b494cc7815f90cb1423177f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f1aef68fd80468ab76809f724eb7f2d",
            "max": 13195,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67e87843d5164200b674a02322e2d6ed",
            "value": 13195
          }
        },
        "3b80fd67bb3b46e5b30121398522abc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f59295ba8f004dd4ae395d3cde1c5bd6",
            "placeholder": "​",
            "style": "IPY_MODEL_29138784dba34525ba852491fac88eed",
            "value": " 13.2k/13.2k [00:00&lt;00:00, 435kB/s]"
          }
        },
        "8992e627cfed418eb8e5e4ac2c72ee34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6033066ea154a249c7cfad2f17bf209": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80427df9bae145f29105e4a2139488cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f1aef68fd80468ab76809f724eb7f2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67e87843d5164200b674a02322e2d6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f59295ba8f004dd4ae395d3cde1c5bd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29138784dba34525ba852491fac88eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b956b38083354b61a08f231dadc09284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_711c119b5aad4707b13bd296b04975a8",
              "IPY_MODEL_86f8718b4f00454a84727c8cfe2d30e5",
              "IPY_MODEL_d89df68bcf704c8b8b497f282441f51f"
            ],
            "layout": "IPY_MODEL_a4ff3eaf24cd4b14b8b4fb92a91623e6"
          }
        },
        "711c119b5aad4707b13bd296b04975a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfdb50d59c944d2c94d4c741160ac4c9",
            "placeholder": "​",
            "style": "IPY_MODEL_e1adf26a451f475c927147cf2fec3b1d",
            "value": "Downloading data: 100%"
          }
        },
        "86f8718b4f00454a84727c8cfe2d30e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bc8d9af2424413ebb53328f2ee708e5",
            "max": 13683,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9b4676e00244976adfcca07c5fede12",
            "value": 13683
          }
        },
        "d89df68bcf704c8b8b497f282441f51f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de90292d7838487d92f225daad6e53c0",
            "placeholder": "​",
            "style": "IPY_MODEL_3c857b5f8de04e2e8248487b3a738a99",
            "value": " 13.7k/13.7k [00:00&lt;00:00, 522kB/s]"
          }
        },
        "a4ff3eaf24cd4b14b8b4fb92a91623e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfdb50d59c944d2c94d4c741160ac4c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1adf26a451f475c927147cf2fec3b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bc8d9af2424413ebb53328f2ee708e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9b4676e00244976adfcca07c5fede12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de90292d7838487d92f225daad6e53c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c857b5f8de04e2e8248487b3a738a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7821c78eb9ee44459ba6e83391ad8e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cac7fc241a0042baa9a9f0b4b62d0591",
              "IPY_MODEL_3ce40f80f996418082ce89b944447e4d",
              "IPY_MODEL_8ec8734e23a44a8fbe2611ecd633df60"
            ],
            "layout": "IPY_MODEL_15a8aa2b2f014224bf18f52eb2b51ab9"
          }
        },
        "cac7fc241a0042baa9a9f0b4b62d0591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_571d7be8013e460890d0114e8973d2f2",
            "placeholder": "​",
            "style": "IPY_MODEL_292ba2cd6c4a4faaa9e82ce3420b5954",
            "value": "Downloading data: 100%"
          }
        },
        "3ce40f80f996418082ce89b944447e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2822701b8164139a5d6688ef3e8eca8",
            "max": 45841,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70269273e0e3407ba27d9209c5f9a2d4",
            "value": 45841
          }
        },
        "8ec8734e23a44a8fbe2611ecd633df60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a9458faa22e469a84939bf2231f0358",
            "placeholder": "​",
            "style": "IPY_MODEL_2b0569662c3342d780bc8dd952de7c72",
            "value": " 45.8k/45.8k [00:00&lt;00:00, 652kB/s]"
          }
        },
        "15a8aa2b2f014224bf18f52eb2b51ab9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "571d7be8013e460890d0114e8973d2f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "292ba2cd6c4a4faaa9e82ce3420b5954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2822701b8164139a5d6688ef3e8eca8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70269273e0e3407ba27d9209c5f9a2d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a9458faa22e469a84939bf2231f0358": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b0569662c3342d780bc8dd952de7c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9c5249d478e427490a45c06824ce2ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_573f801ecb5843c4a326412f69850d5a",
              "IPY_MODEL_ee7d7c2737784d0690b57b68e36140c0",
              "IPY_MODEL_d6974ca000334cb6813d5d5566658e83"
            ],
            "layout": "IPY_MODEL_a61c03ed50cc41edb078bb04a63a5f41"
          }
        },
        "573f801ecb5843c4a326412f69850d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12d357c2605f4902b8ff1692b7bb6334",
            "placeholder": "​",
            "style": "IPY_MODEL_bacc5b12bed743598c7b6b808b6f4a46",
            "value": "Extracting data files: 100%"
          }
        },
        "ee7d7c2737784d0690b57b68e36140c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a1f594e464541d8b231e5b11556480b",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e07dac7e7e044b62ba004d0bb51933ca",
            "value": 3
          }
        },
        "d6974ca000334cb6813d5d5566658e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dca1ffb8d604753b730b70671dbbc9d",
            "placeholder": "​",
            "style": "IPY_MODEL_88352dd9096c4a0aba767c7e5926d349",
            "value": " 3/3 [00:00&lt;00:00, 70.15it/s]"
          }
        },
        "a61c03ed50cc41edb078bb04a63a5f41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12d357c2605f4902b8ff1692b7bb6334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bacc5b12bed743598c7b6b808b6f4a46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a1f594e464541d8b231e5b11556480b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e07dac7e7e044b62ba004d0bb51933ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dca1ffb8d604753b730b70671dbbc9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88352dd9096c4a0aba767c7e5926d349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "268137a361a84bed871655d015965bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c93a923d1414a17a6f39585ad47abf1",
              "IPY_MODEL_18d223fb16384bb1a7e8e81d9d09596b",
              "IPY_MODEL_768b66af3d724a01b3bd0ae20855ca0c"
            ],
            "layout": "IPY_MODEL_4b511a67e10e482f8cd1f725b1035a20"
          }
        },
        "1c93a923d1414a17a6f39585ad47abf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8a002b3ea61465a92aa5e9ff1b00510",
            "placeholder": "​",
            "style": "IPY_MODEL_fc8b3013e0a246e9a623b917855e3d68",
            "value": "100%"
          }
        },
        "18d223fb16384bb1a7e8e81d9d09596b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9825745777640a087c48e29fbecda6c",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f78472ddd4f344c9a3e92c0cdf02ee6d",
            "value": 3
          }
        },
        "768b66af3d724a01b3bd0ae20855ca0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84df2f3fbf1c41df901e823fca5acaf3",
            "placeholder": "​",
            "style": "IPY_MODEL_2b1766ea99c2492d9503d76348d88944",
            "value": " 3/3 [00:00&lt;00:00, 65.51it/s]"
          }
        },
        "4b511a67e10e482f8cd1f725b1035a20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8a002b3ea61465a92aa5e9ff1b00510": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc8b3013e0a246e9a623b917855e3d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9825745777640a087c48e29fbecda6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f78472ddd4f344c9a3e92c0cdf02ee6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84df2f3fbf1c41df901e823fca5acaf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b1766ea99c2492d9503d76348d88944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2790ea0e8e44595b1ec464190f870c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37377297ee124996ae2a6a7f806c5f6b",
              "IPY_MODEL_6d0e240bd86242ec999b5b24be65e327",
              "IPY_MODEL_975a7d3304d14b46bcd70ab40b508c34"
            ],
            "layout": "IPY_MODEL_b001a2634ea84beb92aa1f775722d078"
          }
        },
        "37377297ee124996ae2a6a7f806c5f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c11b3012c38487aa9cde85771fdf990",
            "placeholder": "​",
            "style": "IPY_MODEL_cb6dc15b4f48489db8d762fb289c227b",
            "value": "Downloading: 100%"
          }
        },
        "6d0e240bd86242ec999b5b24be65e327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b283ff1b3e141b9bbef0684f76a9cc6",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_070603705dbd469781e41db2dbe4b30d",
            "value": 29
          }
        },
        "975a7d3304d14b46bcd70ab40b508c34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b41346e45fd46988d01496aaf1094c7",
            "placeholder": "​",
            "style": "IPY_MODEL_f03fc16a9f9c475194317bf24d691b49",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.16kB/s]"
          }
        },
        "b001a2634ea84beb92aa1f775722d078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c11b3012c38487aa9cde85771fdf990": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb6dc15b4f48489db8d762fb289c227b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b283ff1b3e141b9bbef0684f76a9cc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "070603705dbd469781e41db2dbe4b30d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b41346e45fd46988d01496aaf1094c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f03fc16a9f9c475194317bf24d691b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "592dd02a9b2f4503b3914213788f6127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41e423ea043f48cfa6fb8640ac1d354c",
              "IPY_MODEL_5d2f02e19ed04aaead92b5d7cdb7f3eb",
              "IPY_MODEL_075a85d179cd4cc49c1e62aadd945ceb"
            ],
            "layout": "IPY_MODEL_3e6aaa470c2d4bc0833ed7df8e4ac014"
          }
        },
        "41e423ea043f48cfa6fb8640ac1d354c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec3436e069b0426ab02b0ab4032e25a3",
            "placeholder": "​",
            "style": "IPY_MODEL_152631c1d1964265a61cee294c463e83",
            "value": "Downloading: 100%"
          }
        },
        "5d2f02e19ed04aaead92b5d7cdb7f3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8136a23ec440412fa408e0b489c005bc",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a41b5229d2d4f579b7d9d5f9b16283f",
            "value": 570
          }
        },
        "075a85d179cd4cc49c1e62aadd945ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f66495718fc14fe893b85cdf2f5843bd",
            "placeholder": "​",
            "style": "IPY_MODEL_b66d4d5e08cf4f0b8f5c4beeb8188305",
            "value": " 570/570 [00:00&lt;00:00, 11.1kB/s]"
          }
        },
        "3e6aaa470c2d4bc0833ed7df8e4ac014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec3436e069b0426ab02b0ab4032e25a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "152631c1d1964265a61cee294c463e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8136a23ec440412fa408e0b489c005bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a41b5229d2d4f579b7d9d5f9b16283f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f66495718fc14fe893b85cdf2f5843bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b66d4d5e08cf4f0b8f5c4beeb8188305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f84b8df2c5be44eeb8df8d41cb83a3ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f358f59111364dd08fb337ceb513ea8f",
              "IPY_MODEL_400f32d1ae434b468dc641a2fa727a32",
              "IPY_MODEL_c2459eb72bc440bf878ab4b388c9f7e9"
            ],
            "layout": "IPY_MODEL_cb1d85933639435c9924594c2fcd52a6"
          }
        },
        "f358f59111364dd08fb337ceb513ea8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_438334d4e75c4a7ab36c04c8ed19fd05",
            "placeholder": "​",
            "style": "IPY_MODEL_f2493b1b95354e439863a214f297886d",
            "value": "Downloading: 100%"
          }
        },
        "400f32d1ae434b468dc641a2fa727a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa8f58659e374147b4060edf4b14c300",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd7cedc4077a4ad0828761da50de014b",
            "value": 213450
          }
        },
        "c2459eb72bc440bf878ab4b388c9f7e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b9caebee0f34371ab6b2e25401267e7",
            "placeholder": "​",
            "style": "IPY_MODEL_7baeb38af2034ee9a192de15678f6343",
            "value": " 208k/208k [00:00&lt;00:00, 889kB/s]"
          }
        },
        "cb1d85933639435c9924594c2fcd52a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "438334d4e75c4a7ab36c04c8ed19fd05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2493b1b95354e439863a214f297886d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa8f58659e374147b4060edf4b14c300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd7cedc4077a4ad0828761da50de014b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b9caebee0f34371ab6b2e25401267e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7baeb38af2034ee9a192de15678f6343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e11298a46b78472d92d7d809636a7eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_147c4a926d6a469a8b00d28c1346bb9c",
              "IPY_MODEL_6b0b1971c44a4877b7eebbdd4717a022",
              "IPY_MODEL_2484a4efc15647d9814c4076ac1e1e85"
            ],
            "layout": "IPY_MODEL_254e00baa33d4b569ed50ea74ab2a1e2"
          }
        },
        "147c4a926d6a469a8b00d28c1346bb9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d9cde0d5c3d44448b3d6a8419f3b100",
            "placeholder": "​",
            "style": "IPY_MODEL_133dbdc61eb2485cad82b41e7d4d95f5",
            "value": "Downloading: 100%"
          }
        },
        "6b0b1971c44a4877b7eebbdd4717a022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac8ca3cb7fa546479bed2b6403397bca",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e550ab888104f8dab34530b1047131f",
            "value": 435797
          }
        },
        "2484a4efc15647d9814c4076ac1e1e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2a065c0ac1f45d192c215c0a0a143a5",
            "placeholder": "​",
            "style": "IPY_MODEL_5a8e582d416a4491a470de1c6969ce1f",
            "value": " 426k/426k [00:00&lt;00:00, 1.06MB/s]"
          }
        },
        "254e00baa33d4b569ed50ea74ab2a1e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d9cde0d5c3d44448b3d6a8419f3b100": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "133dbdc61eb2485cad82b41e7d4d95f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac8ca3cb7fa546479bed2b6403397bca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e550ab888104f8dab34530b1047131f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2a065c0ac1f45d192c215c0a0a143a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a8e582d416a4491a470de1c6969ce1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1630f539d9374cc8b78dd8c07eb418ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c6009a8ce8b4a0c9b3f32b2b9ff88e0",
              "IPY_MODEL_8c359f11483148369d56703c5eff5b8c",
              "IPY_MODEL_0f3937feac454eba89d0dde5983146a3"
            ],
            "layout": "IPY_MODEL_f9aad68aded84d798160590997c46c3b"
          }
        },
        "4c6009a8ce8b4a0c9b3f32b2b9ff88e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eda4a547521941038a5f4e1ade748ab1",
            "placeholder": "​",
            "style": "IPY_MODEL_a24fb4e4daf8451a9dc97d0ba8741608",
            "value": "100%"
          }
        },
        "8c359f11483148369d56703c5eff5b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_452dce863b5148b5808e4052dbf4a0c8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e2250271c91483eb3f511abe3cea2df",
            "value": 1
          }
        },
        "0f3937feac454eba89d0dde5983146a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e7e7e90426f4b5994819edc9d2c248e",
            "placeholder": "​",
            "style": "IPY_MODEL_014a170364cf48f6886fcccabf73c358",
            "value": " 1/1 [00:00&lt;00:00, 16.04ba/s]"
          }
        },
        "f9aad68aded84d798160590997c46c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eda4a547521941038a5f4e1ade748ab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a24fb4e4daf8451a9dc97d0ba8741608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "452dce863b5148b5808e4052dbf4a0c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e2250271c91483eb3f511abe3cea2df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e7e7e90426f4b5994819edc9d2c248e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "014a170364cf48f6886fcccabf73c358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "079f0ea210124860ab016a59e02d22ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4ab89d9dc8e4697a3007247b3622f25",
              "IPY_MODEL_1b05832bdf4d40b28d694f0bbf3ff634",
              "IPY_MODEL_11ae77fdc0724916b7f4251f60770a85"
            ],
            "layout": "IPY_MODEL_f290507437cb4fcfae2567337d40d009"
          }
        },
        "a4ab89d9dc8e4697a3007247b3622f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00baa101c1c64ad19f8927e0a69996a3",
            "placeholder": "​",
            "style": "IPY_MODEL_65ea27c558f4488ea2a8eeabf59195d8",
            "value": "100%"
          }
        },
        "1b05832bdf4d40b28d694f0bbf3ff634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c5f331f3f1b4949acdb97034e17674d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1336f2e26b4489b89da9879502ee28f",
            "value": 1
          }
        },
        "11ae77fdc0724916b7f4251f60770a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc06b3ccb8e14ae39a961b457aff9f1d",
            "placeholder": "​",
            "style": "IPY_MODEL_7f78c23001d04949b505cfa3c9eb7deb",
            "value": " 1/1 [00:00&lt;00:00, 17.07ba/s]"
          }
        },
        "f290507437cb4fcfae2567337d40d009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00baa101c1c64ad19f8927e0a69996a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65ea27c558f4488ea2a8eeabf59195d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c5f331f3f1b4949acdb97034e17674d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1336f2e26b4489b89da9879502ee28f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc06b3ccb8e14ae39a961b457aff9f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f78c23001d04949b505cfa3c9eb7deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c7eae84f7b14610973c0abc98003865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69f06a6ac1d14702a2b02922ec142a1d",
              "IPY_MODEL_36483c915c7743c99da29e46482a3454",
              "IPY_MODEL_2d92f1449151444a821d195fd208864c"
            ],
            "layout": "IPY_MODEL_0c74200b146a4bc8b121778736cddd07"
          }
        },
        "69f06a6ac1d14702a2b02922ec142a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d58b699882c49c5ae6e69a1317b2081",
            "placeholder": "​",
            "style": "IPY_MODEL_cfa47de663df4400a3151520142e61a1",
            "value": "100%"
          }
        },
        "36483c915c7743c99da29e46482a3454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c9815e2f80a48dd9234b0e7a0e26cad",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4525e8fac7004c8c8ece905e7de687bf",
            "value": 1
          }
        },
        "2d92f1449151444a821d195fd208864c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_237361e8c2434560ba5d059b683869aa",
            "placeholder": "​",
            "style": "IPY_MODEL_e9aef0224f2644a58734abd99c962c60",
            "value": " 1/1 [00:00&lt;00:00,  3.48ba/s]"
          }
        },
        "0c74200b146a4bc8b121778736cddd07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d58b699882c49c5ae6e69a1317b2081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa47de663df4400a3151520142e61a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c9815e2f80a48dd9234b0e7a0e26cad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4525e8fac7004c8c8ece905e7de687bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "237361e8c2434560ba5d059b683869aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9aef0224f2644a58734abd99c962c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a50b479ef0834015ba37b38afa30a7d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e25d9fe549e48d0974a429ea41dc440",
              "IPY_MODEL_d82ef27ac0c24728af54d3b1f7623c6a",
              "IPY_MODEL_4c3b95c54ab54276962ec74930761bb5"
            ],
            "layout": "IPY_MODEL_cdc4759a0c4848488e879fe5da6338a0"
          }
        },
        "5e25d9fe549e48d0974a429ea41dc440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f246edd46a9346a3abbb78b814dbe16b",
            "placeholder": "​",
            "style": "IPY_MODEL_3e950e70b95d4839bf6ecc4ea3d7a6f5",
            "value": "Downloading: 100%"
          }
        },
        "d82ef27ac0c24728af54d3b1f7623c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b5d51adf6e24d5f9591b1696a2cc910",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8429174e0bf6467cb1e25b8178f8214d",
            "value": 526681800
          }
        },
        "4c3b95c54ab54276962ec74930761bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91f529ee7ef8475faf11470a6accadd5",
            "placeholder": "​",
            "style": "IPY_MODEL_2b6dece5edbb46d1a5b5a6cf01754b48",
            "value": " 502M/502M [00:08&lt;00:00, 65.8MB/s]"
          }
        },
        "cdc4759a0c4848488e879fe5da6338a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f246edd46a9346a3abbb78b814dbe16b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e950e70b95d4839bf6ecc4ea3d7a6f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b5d51adf6e24d5f9591b1696a2cc910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8429174e0bf6467cb1e25b8178f8214d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91f529ee7ef8475faf11470a6accadd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b6dece5edbb46d1a5b5a6cf01754b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}