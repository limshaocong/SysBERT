{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limshaocong/SysBERT/blob/main/t4_finetuning_seqlabel_er.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preliminaries**"
      ],
      "metadata": {
        "id": "b0LYLPA78zuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following libraries are required for this notebook. If run locally, it can be commented out.\n",
        "\n",
        "\n",
        "* `transformers` - an excellent library by Hugging Face that provides a high-level abstraction for fine-tuning of transformer-based models, and a model hub of pre-trained models\n",
        "* `datasets` - a dataset library by Hugging Face. All datasets used for this thesis are uploaded to this dataset hub. \n",
        "* `torch` - PyTorch. When running the `allenai/scibert_scivocab_cased` pre-trained model with this notebook on GCP Vertex AI, `torch` needs to be installed.\n",
        "* `seqeval` - a library for evaluation of sequence labelling tasks"
      ],
      "metadata": {
        "id": "H6_Wt3tsjqPg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOsHUjgdIrIW"
      },
      "outputs": [],
      "source": [
        "! pip install --user datasets transformers torch seqeval"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While Google Colab provides free GPU access, the specific GPU (K80/ T4/ P100) available is a function of the subscription level (Free Tier/ Colab Pro/ Colab Pro+) and usage trends. "
      ],
      "metadata": {
        "id": "4tUv8xABlkqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG-L9BEI8uie",
        "outputId": "76e77f90-3ee0-438b-f49f-0a5d5441ff85"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-d0e63106-a3f8-ce39-513d-5cf1ec00b3b7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPRbBNbIrIl"
      },
      "source": [
        "# **Import & Pre-process Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These dictionaries will minimize the amount of adjustment within the remainder of the script."
      ],
      "metadata": {
        "id": "RIPnn4zQmLFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_type_dict = {\n",
        "    'bert-base-cased' : 'bert-base-cased',\n",
        "    'roberta-base' : 'roberta-base',\n",
        "    'allenai/scibert_scivocab_cased' : 'allenai/scibert_scivocab_cased',\n",
        "    'limsc/reqbert-tapt-epoch29' : 'bert-base-cased', # preferred\n",
        "    'limsc/reqroberta-tapt-epoch43' : 'roberta-base', # preferred\n",
        "    'limsc/reqscibert-tapt-epoch20' : 'allenai/scibert_scivocab_cased', # preferred\n",
        "}\n",
        "\n",
        "model_name_dict = {\n",
        "    'bert-base-cased' : 'bert',\n",
        "    'roberta-base' : 'roberta',\n",
        "    'allenai/scibert_scivocab_cased' : 'scibert',\n",
        "    'limsc/reqbert-tapt-epoch29' : 'reqbert-e29',\n",
        "    'limsc/reqroberta-tapt-epoch43' : 'reqroberta-e43',\n",
        "    'limsc/reqscibert-tapt-epoch20' : 'reqscibert-e20'\n",
        "}\n",
        "\n",
        "task_name_dict = {\n",
        "    'limsc/fr-nfr-classification' : 'frnfr',\n",
        "    'limsc/nfr-subclass-classification' : 'subclass',\n",
        "    'limsc/concept-recognition-not-iob' : 'cr',\n",
        "    'limsc/requirements-entity-recognition' : 'er'\n",
        "}"
      ],
      "metadata": {
        "id": "HNVQoJ1CKvSb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IreSlFmlIrIm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556,
          "referenced_widgets": [
            "1ef86c65b58d43b8b0cd7f3e1ab81cc5",
            "f7809f63a8004a7bbf6692b305cc4622",
            "529fa7a0e7a5446c8153db6a919ff086",
            "7b930c8248e34ba1bb772e7b998973f2",
            "73e6dbe728b742108f0e2b6090313080",
            "1d8bad17781442ea87e03401773f1c9c",
            "287d66b1b37c4fbc81cfaa729b85ffc3",
            "aeefb4cad0b04744a30d17fd8fd8f4d3",
            "5d03d46064e04b1ab71c168e803d39d0",
            "414edeea4d3947e4a7872b82e1b0a2de",
            "89ebaf8121c64012b9f100de9a6af299",
            "f3de3818a3e0493cb6238c30b10934e1",
            "b11bf400dc944fd8be7131a475574cd7",
            "3be76a36ae8c4a399ed8c6faa62f0ee9",
            "59e54f83d6ac43e3b2e3ee3b324022ea",
            "2a88c3ff643342deb726b8080db15a16",
            "f202bd163ed04f088f2619527eae8da2",
            "e6e185ba82c54cc88426ced34fd8ee92",
            "34290dd836c5458b9f40c036aad68982",
            "53d7d4439ca64fce864446be4b8fcd4f",
            "638419bef76f478ca79de83e3878f463",
            "b8e2f290f22d41408b3cbd5d3bf1dc75",
            "2d75842eefd340b1aeff77469872b3e6",
            "5a1466abb12d463992c1008364b5f6ad",
            "dfdee446ef84438bac9fe4c27b825ae4",
            "dbb5f30302914ac391e69583d80256a4",
            "be0effe652514beb8190d20a11b39fd8",
            "4c2c76d624744616b1945ba2a5fe97fe",
            "0be6fb50e9c14ac9aee20e81073e81f1",
            "7ba18cdcfd4b41838aed964a7045419c",
            "820dacb219f04931a3235f26e6717afc",
            "f58e8143f71947c999010f0fbd4258fd",
            "a22a568280714726b98004e63966024c",
            "876f0a13033d4bbca3525b12c23d90c7",
            "7f3d8e56780647bfb19883da562b118e",
            "2b5430d786d64a10a3ace3d44cfc97a2",
            "f7d6dae618d74298b8e4831160dbe466",
            "8541585cb404472387ec7906427be376",
            "175ee14f758140ba933e9c92f96ed28c",
            "7d213200c13c47fdb6c0c0573b589ef0",
            "866f6b37e7b44e0a9d30b349d1b2a32a",
            "530313a4e510486a8d25551034bc824c",
            "d7d5355f3cfa4969bb08a12572c377d6",
            "6cc8df35b64b46f9b3fcb19c1cf44adc",
            "cafc449bbd434613917f0f342075ba38",
            "11699ea68e744368a21f2d93d62a5d56",
            "d3732647a21846cfb464278e9c2e3536",
            "996b87d212d64aa9acd81e7544343f40",
            "13f3899110fd4f669d08a606ef9774bd",
            "51fbb16c681c4d5ebf71f25dcc830a53",
            "64ba22a884fe4670aab5353534de97d4",
            "22a14a5be11a433c9e918b0a8c8def41",
            "2b35a000e34d44f399daf291f4c572bd",
            "7a146eba53484ffabe0b1a42d615d19c",
            "375c6ac294a24cb185f1dac4344881c4",
            "4ce297a279824bc3a539470797af1fb2",
            "9c98674c7a3547f786fdc07a156f1a69",
            "96080d1803644e13979237ceae6defc8",
            "3fb3e259d8664f8888e74b55f49d9b16",
            "5603fd1114004644866020a91fc6d240",
            "52775425286740a29d6066a0ec5a8e9e",
            "6ac79de7d219460a9ef043467816e7ed",
            "a8b6e74af3694deb80d42867c633bd0e",
            "9eeee54e691443ba86f103ed1165f7e2",
            "8a81344333ee40d28a891627d8f47251",
            "ebefbbd970e24f58b28d26943efc1f0e",
            "e17731033c394b75b14870dbfe405a37",
            "6b21cfd8566c4738805085938e873d1f",
            "70513a19d4b34c5ab479683df032a749",
            "8dc17ffa2ee24e31b8dc84e864ceeb87",
            "3b8f058790ff4831b48aee5171457542",
            "31583d7292cd4f3abe5bc71ff1b2240c",
            "b66f3d5a77c345b0994ccb926befa8ce",
            "473021abcab84cf4bc24f2ccd22cbda1",
            "a2a58d8bed634732acce910e0589ff73",
            "0827a3aeb41349028f5a65dcf892bade",
            "4b7cb1dc8b224852bafd6acb8aca7f63"
          ]
        },
        "outputId": "1ee5f5b6-4c19-49b5-ab76-d717357188eb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.22k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ef86c65b58d43b8b0cd7f3e1ab81cc5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration limsc--requirements-entity-recognition-772abc9e4a496786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset None/None (download: 71.11 KiB, generated: 361.94 KiB, post-processed: Unknown size, total: 433.05 KiB) to /root/.cache/huggingface/datasets/limsc___parquet/limsc--requirements-entity-recognition-772abc9e4a496786/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3de3818a3e0493cb6238c30b10934e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d75842eefd340b1aeff77469872b3e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/46.0k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "876f0a13033d4bbca3525b12c23d90c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/13.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cafc449bbd434613917f0f342075ba38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ce297a279824bc3a539470797af1fb2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/limsc___parquet/limsc--requirements-entity-recognition-772abc9e4a496786/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e17731033c394b75b14870dbfe405a37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    val: Dataset({\n",
              "        features: ['id', 'tokens', 'ner_tags'],\n",
              "        num_rows: 138\n",
              "    })\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'ner_tags'],\n",
              "        num_rows: 646\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'ner_tags'],\n",
              "        num_rows: 139\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds_name = 'limsc/requirements-entity-recognition'\n",
        "ds = load_dataset(ds_name)\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Vn4qqTzmWqDN",
        "outputId": "200b3c95-b92b-4b55-f590-96b9f8421483",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'B-ACT',\n",
              " 'I-ACT',\n",
              " 'B-ATTR',\n",
              " 'I-ATTR',\n",
              " 'B-RELOP',\n",
              " 'I-RELOP',\n",
              " 'B-QUANT',\n",
              " 'I-QUANT',\n",
              " 'B-ENT',\n",
              " 'I-ENT']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "label_list = ds['train'].features['ner_tags'].feature.names\n",
        "label_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = 'limsc/reqroberta-tapt-epoch43'"
      ],
      "metadata": {
        "id": "h81se9qE9F8X"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "eXNLu_-nIrJI"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "prefix_space = True if model_type_dict[model_checkpoint] == 'roberta-base' else False\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_type_dict[model_checkpoint],\n",
        "    use_fast = True,\n",
        "    add_prefix_space = prefix_space\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "wGZn8Er5WqDQ"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(examples, label_all_tokens = False):\n",
        "\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples['tokens'],\n",
        "        truncation = True,\n",
        "        is_split_into_words = True\n",
        "    )\n",
        "    labels = []\n",
        "    \n",
        "    for i, label in enumerate(examples['ner_tags']):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        \n",
        "        for word_idx in word_ids:           \n",
        "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
        "            # ignored in the loss function.\n",
        "\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            \n",
        "            # We set the label for the first token of each word.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            \n",
        "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "            # the label_all_tokens flag.\n",
        "            else:\n",
        "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "            \n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs['labels'] = labels\n",
        "    \n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "DDtsaJeVIrJT",
        "outputId": "e913759d-fc09-4bc6-d785-0d8a1d004762",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "edeebfcd97c34c55aff7d54669911ede",
            "a739fc0acd8a451bacb768efe3e50b7d",
            "f5814727a8d0482d86d7dc9217bc2c1c",
            "5448d4c3845d4eeabca1ad37e1feb9f8",
            "7b6c37a0a8b941e7adfb7deacc180b19",
            "091011e980a0444ead7831fcf2c1442f",
            "cdfefe39958b48c99e3d903f6d40b014",
            "d3e7692a8da44ef0bf403757c4a8af5e",
            "bcbd5b2e562140138f2002d7383e798d",
            "b3dda80e41b747e8ab885b8665d2e47e",
            "0be9f8583a83479284c6daed2fa37400"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/limsc___parquet/limsc--requirements-entity-recognition-772abc9e4a496786/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-5993172f0b16d2f9.arrow\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edeebfcd97c34c55aff7d54669911ede"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/limsc___parquet/limsc--requirements-entity-recognition-772abc9e4a496786/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-59a308df2ec3875b.arrow\n"
          ]
        }
      ],
      "source": [
        "tokenized_ds = ds.map(tokenize_and_align_labels, batched = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Fine-tuning (Single Loop)**"
      ],
      "metadata": {
        "id": "wKmQPYsTQqyv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "caHE49prWqDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01b9817-8f51-4417-e21a-7d4be7571550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:707: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  tensor = as_tensor(value)\n"
          ]
        }
      ],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(\n",
        "    tokenizer = tokenizer,\n",
        "    padding = True,\n",
        "    return_tensors = 'tf'\n",
        ")\n",
        "\n",
        "def batching(tokenized_ds, batch_size):\n",
        "\n",
        "    batched_train_ds = tokenized_ds['train'].to_tf_dataset(\n",
        "        columns = ['attention_mask', 'input_ids', 'labels'],\n",
        "        shuffle = True,\n",
        "        batch_size = batch_size,\n",
        "        collate_fn = data_collator,\n",
        "    )\n",
        "\n",
        "    batched_val_ds = tokenized_ds['val'].to_tf_dataset(\n",
        "        columns = ['attention_mask', 'input_ids', 'labels'],\n",
        "        shuffle = False,\n",
        "        batch_size = batch_size,\n",
        "        collate_fn = data_collator,\n",
        "    )\n",
        "\n",
        "    batched_test_ds = tokenized_ds['test'].to_tf_dataset(\n",
        "        columns = ['attention_mask', 'input_ids', 'labels'],\n",
        "        shuffle = False,\n",
        "        batch_size = batch_size,\n",
        "        collate_fn = data_collator,\n",
        "    )\n",
        "    \n",
        "    return batched_train_ds, batched_val_ds, batched_test_ds\n",
        "\n",
        "batched_train_ds, batched_val_ds, batched_test_ds = batching(tokenized_ds, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFAutoModelForTokenClassification, create_optimizer\n",
        "\n",
        "seed = 6789767\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "num_epochs = 5\n",
        "initial_lr = 2e-5\n",
        "\n",
        "def create_model(num_epochs, initial_lr):\n",
        "\n",
        "    model = TFAutoModelForTokenClassification.from_pretrained(\n",
        "        model_checkpoint,\n",
        "        num_labels = len(label_list)\n",
        "    )\n",
        "\n",
        "    batches_per_epoch = len(tokenized_ds['train']) // batch_size\n",
        "    total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "\n",
        "    optimizer, schedule = create_optimizer(\n",
        "        init_lr = initial_lr,\n",
        "        num_warmup_steps = total_train_steps // 20,\n",
        "        num_train_steps = total_train_steps,\n",
        "        weight_decay_rate = 0.01\n",
        "    )\n",
        "\n",
        "    model.compile(optimizer = optimizer)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_model(num_epochs, initial_lr)"
      ],
      "metadata": {
        "id": "P2JF0qbzcKAQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "dd6e0e913cf24b83bf21b4167a3f7a5e",
            "360ddf4b57934351a0aa55efc884305c",
            "352e8988c90442a1b621bf8f22e4ef68",
            "ed3d667d92bf4511ace3cf83291b7f56",
            "08e1780b8d3d4c13af480169375d8dff",
            "698c0b5f512543d4967c9b98fc382070",
            "f96f7bd601b34876aa213514f79e8738",
            "371b9afa8f7f405cb695a79fdfdd6dcb",
            "dae4f9e4eaac42bb9064d2daab7fa648",
            "bedd9abf3f00490a979c43b61cd3ef7d",
            "7b24cfccfc83486d9d73152273697c77",
            "def6377eff9a4c75ae85e0b71344c183",
            "69632f861d3a4247bfcafcdb56f50478",
            "3fede457ca12442698304a8053057dd5",
            "3258ce25f3114c6680de34e8a9a68bdb",
            "094593899f75438c9568ec65f8abade4",
            "fcaeda16766e4b09a7cc4c77dee21ff1",
            "a68c00a06a39492c822b18e345850243",
            "0a2adcba33cd48459faef2b2ce19c207",
            "1d23b1312a24441e97a5407462c56223",
            "b98f366b55344187a13da479bf3c29dd",
            "c8bff20330bb4b3693e8f1029e914637"
          ]
        },
        "outputId": "285071cd-5747-4f59-cbf6-2af39bbd3c20"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/644 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd6e0e913cf24b83bf21b4167a3f7a5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/625M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "def6377eff9a4c75ae85e0b71344c183"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForTokenClassification.\n",
            "\n",
            "Some layers of TFRobertaForTokenClassification were not initialized from the model checkpoint at limsc/reqroberta-tapt-epoch43 and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "TlqNaB8jIrJW",
        "outputId": "81e65455-183a-416e-a21a-c4e5c4af164c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No label_cols specified for KerasMetricCallback, assuming you want the 'labels' key.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "from transformers.keras_callbacks import KerasMetricCallback\n",
        "\n",
        "metric = load_metric(\"seqeval\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }\n",
        "\n",
        "metric_cb = KerasMetricCallback(\n",
        "    metric_fn = compute_metrics,\n",
        "    eval_dataset = batched_val_ds\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, CSVLogger\n",
        "\n",
        "class update_logger(Callback):\n",
        "\n",
        "    def __init__(self):    \n",
        "        super(update_logger, self).__init__()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs = {}):\n",
        "        logs['seed'] = seed\n",
        "        logs['batch_size'] = batch_size\n",
        "        logs['learning_rate'] = initial_lr\n",
        "\n",
        "update_logger_cb = update_logger()\n",
        "\n",
        "csvlogger_file = f'{task_name_dict[ds_name]}-{model_name_dict[model_checkpoint]}.csv'\n",
        "csvlogger_cb = CSVLogger(csvlogger_file, append = True)\n",
        "\n",
        "callbacks = [metric_cb, update_logger_cb, csvlogger_cb]"
      ],
      "metadata": {
        "id": "wmjnGrL4Ln9t"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "J6fjhEr0WqDS",
        "outputId": "e238daec-beee-46b6-e59d-2ab10c34ed96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:707: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  tensor = as_tensor(value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 36s 536ms/step - loss: 1.6941 - val_loss: 0.9128 - precision: 0.4656 - recall: 0.2599 - f1: 0.3336 - accuracy: 0.7257 - seed: 6789767.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 10s 263ms/step - loss: 0.5626 - val_loss: 0.3124 - precision: 0.8222 - recall: 0.8736 - f1: 0.8471 - accuracy: 0.9288 - seed: 6789767.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "40/40 [==============================] - 10s 264ms/step - loss: 0.2720 - val_loss: 0.2483 - precision: 0.8627 - recall: 0.8835 - f1: 0.8730 - accuracy: 0.9364 - seed: 6789767.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "40/40 [==============================] - 11s 267ms/step - loss: 0.2044 - val_loss: 0.2345 - precision: 0.8669 - recall: 0.9162 - f1: 0.8909 - accuracy: 0.9449 - seed: 6789767.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "40/40 [==============================] - 11s 269ms/step - loss: 0.1749 - val_loss: 0.2250 - precision: 0.8745 - recall: 0.9205 - f1: 0.8969 - accuracy: 0.9463 - seed: 6789767.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f75c86af250>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "model.fit(\n",
        "    batched_train_ds,\n",
        "    validation_data = batched_val_ds,\n",
        "    epochs = num_epochs,\n",
        "    callbacks = callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hyperparameter tuning**"
      ],
      "metadata": {
        "id": "iPOAWvTPQznQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sizes = [8] if model_type_dict[model_checkpoint] == 'roberta-base' else [8, 16]\n",
        "initial_lrs = [5e-5, 3e-5, 2e-5]\n",
        "seeds = [21916, 25412, 56281, 61712, 30488,\n",
        "         28215, 78867, 87843, 67918, 93327,\n",
        "         95420, 11905, 86349, 12082, 81996]\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "\n",
        "    batched_train_ds, batched_val_ds, batched_test_ds = batching(tokenized_ds, batch_size)\n",
        "    \n",
        "    for initial_lr in initial_lrs:\n",
        "    \n",
        "        for seed in seeds:\n",
        "    \n",
        "            tf.random.set_seed(seed)\n",
        "            model = create_model(num_epochs, initial_lr)\n",
        "\n",
        "            csvlogger_file = f'{model_name_dict[model_checkpoint]}-{task_name_dict[ds_name]}.csv'\n",
        "            csvlogger_cb = CSVLogger(csvlogger_file, append = True)\n",
        "\n",
        "            callbacks = [update_logger_cb, csvlogger_cb]\n",
        "\n",
        "            model.fit(\n",
        "                batched_train_ds,\n",
        "                validation_data = batched_val_ds,\n",
        "                epochs = num_epochs,\n",
        "                callbacks = callbacks\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkb_UO8TQ0HR",
        "outputId": "102cedc5-e441-4f9c-f4fb-ba4ca0810744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:707: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  tensor = as_tensor(value)\n",
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 201ms/step - loss: 1.3934 - val_loss: 0.8224 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.6133 - val_loss: 0.5671 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.3711 - val_loss: 0.5052 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 163ms/step - loss: 0.2369 - val_loss: 0.5099 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.1743 - val_loss: 0.5249 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 201ms/step - loss: 1.3973 - val_loss: 0.9366 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.6913 - val_loss: 0.6081 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.4025 - val_loss: 0.5586 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.2572 - val_loss: 0.5455 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.1870 - val_loss: 0.5467 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 31s 202ms/step - loss: 1.3920 - val_loss: 0.8548 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.6572 - val_loss: 0.5945 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.4051 - val_loss: 0.5353 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 164ms/step - loss: 0.2669 - val_loss: 0.5242 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.1988 - val_loss: 0.5303 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 199ms/step - loss: 1.3565 - val_loss: 0.8414 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.6254 - val_loss: 0.5783 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.3632 - val_loss: 0.5147 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 0.2390 - val_loss: 0.5151 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.1712 - val_loss: 0.5164 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 202ms/step - loss: 1.3434 - val_loss: 0.8634 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.6443 - val_loss: 0.5996 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.3768 - val_loss: 0.5071 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.2396 - val_loss: 0.5083 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.1732 - val_loss: 0.5212 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 31s 203ms/step - loss: 1.3734 - val_loss: 0.8050 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.6353 - val_loss: 0.6051 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.3739 - val_loss: 0.5214 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.2383 - val_loss: 0.5269 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.1738 - val_loss: 0.5222 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 201ms/step - loss: 1.3413 - val_loss: 0.8800 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 0.6484 - val_loss: 0.5964 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.3844 - val_loss: 0.5382 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.2486 - val_loss: 0.5264 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.1808 - val_loss: 0.5340 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 200ms/step - loss: 1.3403 - val_loss: 0.8435 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.6204 - val_loss: 0.5905 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.3817 - val_loss: 0.5358 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.2481 - val_loss: 0.5148 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.1859 - val_loss: 0.5284 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 31s 205ms/step - loss: 1.3710 - val_loss: 0.8334 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.6412 - val_loss: 0.6310 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.3860 - val_loss: 0.5198 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.2539 - val_loss: 0.5285 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.1839 - val_loss: 0.5367 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 200ms/step - loss: 1.4266 - val_loss: 0.8618 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.6539 - val_loss: 0.6019 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.3821 - val_loss: 0.5480 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 159ms/step - loss: 0.2439 - val_loss: 0.5271 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.1805 - val_loss: 0.5331 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 203ms/step - loss: 1.3160 - val_loss: 0.7994 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 162ms/step - loss: 0.6120 - val_loss: 0.5896 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.3689 - val_loss: 0.5439 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.2369 - val_loss: 0.5178 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 162ms/step - loss: 0.1764 - val_loss: 0.5235 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 204ms/step - loss: 1.3424 - val_loss: 0.8402 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.6402 - val_loss: 0.6449 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 164ms/step - loss: 0.3962 - val_loss: 0.5352 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.2526 - val_loss: 0.5351 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.1876 - val_loss: 0.5235 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 208ms/step - loss: 1.3014 - val_loss: 0.8699 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.6572 - val_loss: 0.6375 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.3863 - val_loss: 0.5283 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.2451 - val_loss: 0.5173 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.1825 - val_loss: 0.5258 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 210ms/step - loss: 1.3245 - val_loss: 0.8150 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.6338 - val_loss: 0.5706 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.3762 - val_loss: 0.5433 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.2426 - val_loss: 0.5284 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.1790 - val_loss: 0.5316 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 200ms/step - loss: 1.2865 - val_loss: 0.8331 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.6373 - val_loss: 0.6349 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.3847 - val_loss: 0.5365 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.2444 - val_loss: 0.5425 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.1788 - val_loss: 0.5620 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 31s 203ms/step - loss: 1.4469 - val_loss: 0.9212 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.7203 - val_loss: 0.6569 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.4866 - val_loss: 0.5549 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 0.3611 - val_loss: 0.5355 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.2966 - val_loss: 0.5367 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 199ms/step - loss: 1.4616 - val_loss: 0.9171 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.7241 - val_loss: 0.6401 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.4737 - val_loss: 0.5637 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.3436 - val_loss: 0.5483 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.2817 - val_loss: 0.5431 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 202ms/step - loss: 1.4602 - val_loss: 0.9354 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.7552 - val_loss: 0.7062 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.5142 - val_loss: 0.5859 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 163ms/step - loss: 0.3861 - val_loss: 0.5594 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.3166 - val_loss: 0.5554 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 203ms/step - loss: 1.4123 - val_loss: 0.9779 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 160ms/step - loss: 0.7454 - val_loss: 0.6545 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.4824 - val_loss: 0.5561 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.3481 - val_loss: 0.5303 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 161ms/step - loss: 0.2866 - val_loss: 0.5277 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 198ms/step - loss: 1.4564 - val_loss: 0.9667 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.7543 - val_loss: 0.6900 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.5038 - val_loss: 0.5993 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.3712 - val_loss: 0.5630 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.3051 - val_loss: 0.5523 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 29s 196ms/step - loss: 1.5129 - val_loss: 0.9606 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.7722 - val_loss: 0.6727 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.5132 - val_loss: 0.5619 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.3778 - val_loss: 0.5422 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.3071 - val_loss: 0.5403 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 202ms/step - loss: 1.4752 - val_loss: 0.9827 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 159ms/step - loss: 0.7707 - val_loss: 0.6809 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.5064 - val_loss: 0.5908 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.3737 - val_loss: 0.5576 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.3084 - val_loss: 0.5516 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 214ms/step - loss: 1.4705 - val_loss: 0.9558 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.7505 - val_loss: 0.7155 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.5182 - val_loss: 0.5973 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.3916 - val_loss: 0.5671 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.3253 - val_loss: 0.5597 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 211ms/step - loss: 1.4544 - val_loss: 0.9652 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 162ms/step - loss: 0.7816 - val_loss: 0.6811 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.5225 - val_loss: 0.5798 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.3857 - val_loss: 0.5610 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.3189 - val_loss: 0.5572 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 211ms/step - loss: 1.5049 - val_loss: 1.0099 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.7949 - val_loss: 0.7015 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 164ms/step - loss: 0.5300 - val_loss: 0.5989 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.3936 - val_loss: 0.5527 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.3168 - val_loss: 0.5516 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 209ms/step - loss: 1.4068 - val_loss: 0.9132 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.7308 - val_loss: 0.6696 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.4891 - val_loss: 0.5954 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.3650 - val_loss: 0.5563 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.3022 - val_loss: 0.5474 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 208ms/step - loss: 1.4339 - val_loss: 0.9387 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.7535 - val_loss: 0.6796 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.5116 - val_loss: 0.5788 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.3779 - val_loss: 0.5517 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.3127 - val_loss: 0.5444 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 210ms/step - loss: 1.4308 - val_loss: 0.9823 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 162ms/step - loss: 0.7818 - val_loss: 0.7195 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 164ms/step - loss: 0.5237 - val_loss: 0.5969 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 162ms/step - loss: 0.3944 - val_loss: 0.5716 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.3265 - val_loss: 0.5553 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 31s 203ms/step - loss: 1.3878 - val_loss: 0.9596 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 162ms/step - loss: 0.7469 - val_loss: 0.6549 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.5003 - val_loss: 0.5861 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.3694 - val_loss: 0.5482 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.3094 - val_loss: 0.5447 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 198ms/step - loss: 1.4422 - val_loss: 0.9136 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.7330 - val_loss: 0.6708 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.4928 - val_loss: 0.5936 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.3686 - val_loss: 0.5512 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.3056 - val_loss: 0.5467 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 200ms/step - loss: 1.5399 - val_loss: 1.0286 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 158ms/step - loss: 0.8493 - val_loss: 0.7581 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.6220 - val_loss: 0.6565 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 158ms/step - loss: 0.5032 - val_loss: 0.6112 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.4434 - val_loss: 0.6002 - seed: 21916.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 198ms/step - loss: 1.5785 - val_loss: 1.0496 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.8754 - val_loss: 0.7892 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.6377 - val_loss: 0.6527 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 159ms/step - loss: 0.5083 - val_loss: 0.6073 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.4402 - val_loss: 0.6063 - seed: 25412.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 196ms/step - loss: 1.6036 - val_loss: 1.0236 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.8674 - val_loss: 0.8015 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.6551 - val_loss: 0.6784 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.5302 - val_loss: 0.6338 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.4688 - val_loss: 0.6212 - seed: 56281.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 201ms/step - loss: 1.4928 - val_loss: 1.0487 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.8675 - val_loss: 0.7481 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 159ms/step - loss: 0.6170 - val_loss: 0.6333 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 161ms/step - loss: 0.4777 - val_loss: 0.5891 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.4143 - val_loss: 0.5805 - seed: 61712.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 199ms/step - loss: 1.5076 - val_loss: 1.0585 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.8823 - val_loss: 0.7758 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.6297 - val_loss: 0.6518 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.4943 - val_loss: 0.6035 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.4288 - val_loss: 0.5968 - seed: 30488.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 199ms/step - loss: 1.6249 - val_loss: 1.0412 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 0.8673 - val_loss: 0.7713 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.6321 - val_loss: 0.6511 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.5021 - val_loss: 0.5982 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.4320 - val_loss: 0.5889 - seed: 28215.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 200ms/step - loss: 1.5549 - val_loss: 1.0720 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.8783 - val_loss: 0.7851 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.6309 - val_loss: 0.6567 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.4960 - val_loss: 0.6074 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.4303 - val_loss: 0.5952 - seed: 78867.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 201ms/step - loss: 1.6366 - val_loss: 1.0358 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.8668 - val_loss: 0.7998 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.6340 - val_loss: 0.6899 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.5136 - val_loss: 0.6349 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.4523 - val_loss: 0.6258 - seed: 87843.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 201ms/step - loss: 1.5485 - val_loss: 1.0563 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 0.8816 - val_loss: 0.7870 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.6430 - val_loss: 0.6737 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.5197 - val_loss: 0.6319 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 0.4553 - val_loss: 0.6192 - seed: 67918.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 31s 206ms/step - loss: 1.5694 - val_loss: 1.0746 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.8959 - val_loss: 0.8056 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.6451 - val_loss: 0.6677 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 163ms/step - loss: 0.5121 - val_loss: 0.6322 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.4505 - val_loss: 0.6123 - seed: 93327.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 199ms/step - loss: 1.5692 - val_loss: 1.0250 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.8566 - val_loss: 0.7705 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.6232 - val_loss: 0.6580 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.4986 - val_loss: 0.6214 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.4399 - val_loss: 0.6054 - seed: 95420.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 31s 209ms/step - loss: 1.5227 - val_loss: 1.0428 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.8450 - val_loss: 0.7797 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.6256 - val_loss: 0.6737 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 166ms/step - loss: 0.5003 - val_loss: 0.6211 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 162ms/step - loss: 0.4368 - val_loss: 0.6094 - seed: 11905.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 211ms/step - loss: 1.5221 - val_loss: 1.0620 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.8946 - val_loss: 0.7892 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.6419 - val_loss: 0.6677 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 12s 164ms/step - loss: 0.5128 - val_loss: 0.6295 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.4487 - val_loss: 0.6112 - seed: 86349.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 211ms/step - loss: 1.5818 - val_loss: 1.0365 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.8723 - val_loss: 0.7620 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.6272 - val_loss: 0.6561 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.5015 - val_loss: 0.6135 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.4385 - val_loss: 0.5968 - seed: 12082.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "76/76 [==============================] - 30s 203ms/step - loss: 1.6052 - val_loss: 1.0317 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "76/76 [==============================] - 12s 165ms/step - loss: 0.8756 - val_loss: 0.7737 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "76/76 [==============================] - 12s 163ms/step - loss: 0.6307 - val_loss: 0.6576 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.4987 - val_loss: 0.6224 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 0.4366 - val_loss: 0.6150 - seed: 81996.0000 - batch_size: 8.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 428ms/step - loss: 1.6118 - val_loss: 1.0057 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 373ms/step - loss: 0.8094 - val_loss: 0.7119 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 0.5481 - val_loss: 0.6028 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 337ms/step - loss: 0.3957 - val_loss: 0.5580 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 368ms/step - loss: 0.3234 - val_loss: 0.5506 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 421ms/step - loss: 1.6256 - val_loss: 1.0747 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 344ms/step - loss: 0.8796 - val_loss: 0.7625 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 0.5792 - val_loss: 0.6166 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 355ms/step - loss: 0.4105 - val_loss: 0.5649 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 360ms/step - loss: 0.3280 - val_loss: 0.5666 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 32s 430ms/step - loss: 1.6206 - val_loss: 1.0549 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 0.8602 - val_loss: 0.7539 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 363ms/step - loss: 0.6031 - val_loss: 0.6433 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 352ms/step - loss: 0.4556 - val_loss: 0.5925 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 364ms/step - loss: 0.3737 - val_loss: 0.5861 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 422ms/step - loss: 1.5470 - val_loss: 1.0511 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 340ms/step - loss: 0.8373 - val_loss: 0.7050 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 352ms/step - loss: 0.5360 - val_loss: 0.5998 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 363ms/step - loss: 0.3901 - val_loss: 0.5550 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 356ms/step - loss: 0.3137 - val_loss: 0.5419 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 415ms/step - loss: 1.5247 - val_loss: 1.0626 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 348ms/step - loss: 0.8517 - val_loss: 0.7327 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 0.5546 - val_loss: 0.5934 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 364ms/step - loss: 0.4022 - val_loss: 0.5736 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 341ms/step - loss: 0.3196 - val_loss: 0.5578 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 430ms/step - loss: 1.5954 - val_loss: 1.0301 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 351ms/step - loss: 0.8333 - val_loss: 0.7360 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 343ms/step - loss: 0.5726 - val_loss: 0.6045 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 349ms/step - loss: 0.4133 - val_loss: 0.5832 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 354ms/step - loss: 0.3330 - val_loss: 0.5649 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 412ms/step - loss: 1.5398 - val_loss: 1.0638 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 359ms/step - loss: 0.8897 - val_loss: 0.8191 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 374ms/step - loss: 0.5966 - val_loss: 0.6443 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 366ms/step - loss: 0.4280 - val_loss: 0.5951 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 358ms/step - loss: 0.3526 - val_loss: 0.5831 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 429ms/step - loss: 1.5480 - val_loss: 1.0257 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 353ms/step - loss: 0.8407 - val_loss: 0.7662 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 0.5884 - val_loss: 0.6503 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 356ms/step - loss: 0.4344 - val_loss: 0.5971 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 355ms/step - loss: 0.3610 - val_loss: 0.5947 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 422ms/step - loss: 1.5790 - val_loss: 1.0424 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 360ms/step - loss: 0.8491 - val_loss: 0.7700 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 356ms/step - loss: 0.5745 - val_loss: 0.6111 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 358ms/step - loss: 0.4181 - val_loss: 0.5693 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 0.3429 - val_loss: 0.5599 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 418ms/step - loss: 1.6322 - val_loss: 1.0745 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 0.9017 - val_loss: 0.7994 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 376ms/step - loss: 0.6264 - val_loss: 0.6650 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 334ms/step - loss: 0.4567 - val_loss: 0.6037 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 354ms/step - loss: 0.3688 - val_loss: 0.6011 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 428ms/step - loss: 1.5313 - val_loss: 1.0277 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 345ms/step - loss: 0.8376 - val_loss: 0.7471 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 0.5746 - val_loss: 0.6159 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 369ms/step - loss: 0.4141 - val_loss: 0.5733 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 334ms/step - loss: 0.3373 - val_loss: 0.5646 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 422ms/step - loss: 1.5859 - val_loss: 1.0545 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 345ms/step - loss: 0.8456 - val_loss: 0.7678 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 0.5791 - val_loss: 0.6353 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 356ms/step - loss: 0.4240 - val_loss: 0.5844 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 358ms/step - loss: 0.3439 - val_loss: 0.5710 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 414ms/step - loss: 1.4739 - val_loss: 1.0637 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 366ms/step - loss: 0.8658 - val_loss: 0.7676 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 358ms/step - loss: 0.5846 - val_loss: 0.6282 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 364ms/step - loss: 0.4256 - val_loss: 0.5780 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 345ms/step - loss: 0.3494 - val_loss: 0.5719 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            " 6/38 [===>..........................] - ETA: 6s - loss: 2.9276WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1105s vs `on_train_batch_end` time: 0.1159s). Check your callbacks.\n",
            "38/38 [==============================] - 30s 417ms/step - loss: 1.5371 - val_loss: 1.0702 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 0.8522 - val_loss: 0.7325 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 356ms/step - loss: 0.5709 - val_loss: 0.6132 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 352ms/step - loss: 0.4131 - val_loss: 0.5694 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 351ms/step - loss: 0.3380 - val_loss: 0.5578 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 432ms/step - loss: 1.4936 - val_loss: 1.0236 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 365ms/step - loss: 0.8327 - val_loss: 0.7418 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 338ms/step - loss: 0.5731 - val_loss: 0.6224 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 360ms/step - loss: 0.4181 - val_loss: 0.5899 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 342ms/step - loss: 0.3389 - val_loss: 0.5769 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 442ms/step - loss: 1.6765 - val_loss: 1.1097 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 356ms/step - loss: 0.9403 - val_loss: 0.8415 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 358ms/step - loss: 0.7038 - val_loss: 0.7030 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 0.5645 - val_loss: 0.6512 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 353ms/step - loss: 0.4952 - val_loss: 0.6372 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 423ms/step - loss: 1.6939 - val_loss: 1.1107 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 355ms/step - loss: 0.9914 - val_loss: 0.8992 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 351ms/step - loss: 0.7464 - val_loss: 0.7474 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 368ms/step - loss: 0.5968 - val_loss: 0.6788 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 341ms/step - loss: 0.5256 - val_loss: 0.6599 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 442ms/step - loss: 1.6890 - val_loss: 1.1088 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 368ms/step - loss: 0.9561 - val_loss: 0.8894 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 355ms/step - loss: 0.7308 - val_loss: 0.7429 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 355ms/step - loss: 0.6004 - val_loss: 0.6798 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 0.5370 - val_loss: 0.6634 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 437ms/step - loss: 1.6174 - val_loss: 1.1030 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 341ms/step - loss: 0.9854 - val_loss: 0.8867 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 362ms/step - loss: 0.7277 - val_loss: 0.7103 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 358ms/step - loss: 0.5684 - val_loss: 0.6577 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 352ms/step - loss: 0.4950 - val_loss: 0.6363 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 29s 403ms/step - loss: 1.6497 - val_loss: 1.1033 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 362ms/step - loss: 0.9695 - val_loss: 0.8767 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 351ms/step - loss: 0.7211 - val_loss: 0.7232 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 343ms/step - loss: 0.5725 - val_loss: 0.6621 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 369ms/step - loss: 0.4993 - val_loss: 0.6444 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 418ms/step - loss: 1.7355 - val_loss: 1.1147 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 358ms/step - loss: 0.9618 - val_loss: 0.8798 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 343ms/step - loss: 0.7339 - val_loss: 0.7317 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 345ms/step - loss: 0.5912 - val_loss: 0.6665 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 349ms/step - loss: 0.5182 - val_loss: 0.6453 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 441ms/step - loss: 1.6610 - val_loss: 1.1147 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 346ms/step - loss: 0.9802 - val_loss: 0.8704 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 358ms/step - loss: 0.7165 - val_loss: 0.7333 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 350ms/step - loss: 0.5651 - val_loss: 0.6646 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 353ms/step - loss: 0.4933 - val_loss: 0.6482 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 449ms/step - loss: 1.6787 - val_loss: 1.1061 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 366ms/step - loss: 0.9447 - val_loss: 0.8697 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 369ms/step - loss: 0.7137 - val_loss: 0.7294 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 370ms/step - loss: 0.5825 - val_loss: 0.6682 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 358ms/step - loss: 0.5134 - val_loss: 0.6561 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 424ms/step - loss: 1.6337 - val_loss: 1.1108 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 341ms/step - loss: 0.9883 - val_loss: 0.8768 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 355ms/step - loss: 0.7438 - val_loss: 0.7467 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 356ms/step - loss: 0.6031 - val_loss: 0.6837 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 345ms/step - loss: 0.5327 - val_loss: 0.6696 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 424ms/step - loss: 1.6907 - val_loss: 1.1188 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 0.9991 - val_loss: 0.9165 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 345ms/step - loss: 0.7612 - val_loss: 0.7658 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 355ms/step - loss: 0.6070 - val_loss: 0.6913 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 368ms/step - loss: 0.5315 - val_loss: 0.6714 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 420ms/step - loss: 1.6134 - val_loss: 1.0907 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 369ms/step - loss: 0.9487 - val_loss: 0.8688 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 355ms/step - loss: 0.7106 - val_loss: 0.7373 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 365ms/step - loss: 0.5753 - val_loss: 0.6711 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 364ms/step - loss: 0.5054 - val_loss: 0.6570 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 428ms/step - loss: 1.6610 - val_loss: 1.1105 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 364ms/step - loss: 0.9562 - val_loss: 0.8711 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 374ms/step - loss: 0.7221 - val_loss: 0.7427 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 353ms/step - loss: 0.5886 - val_loss: 0.6791 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 353ms/step - loss: 0.5202 - val_loss: 0.6579 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 418ms/step - loss: 1.6020 - val_loss: 1.1083 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 330ms/step - loss: 0.9901 - val_loss: 0.9132 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 351ms/step - loss: 0.7579 - val_loss: 0.7620 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 355ms/step - loss: 0.6115 - val_loss: 0.6958 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 344ms/step - loss: 0.5339 - val_loss: 0.6732 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 420ms/step - loss: 1.5925 - val_loss: 1.1119 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 354ms/step - loss: 0.9653 - val_loss: 0.8499 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 352ms/step - loss: 0.7155 - val_loss: 0.7024 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 354ms/step - loss: 0.5683 - val_loss: 0.6533 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 351ms/step - loss: 0.4978 - val_loss: 0.6301 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 408ms/step - loss: 1.6654 - val_loss: 1.0864 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 364ms/step - loss: 0.9618 - val_loss: 0.8617 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 356ms/step - loss: 0.7261 - val_loss: 0.7233 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 365ms/step - loss: 0.5796 - val_loss: 0.6732 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 366ms/step - loss: 0.5098 - val_loss: 0.6608 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 410ms/step - loss: 1.7737 - val_loss: 1.1437 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 334ms/step - loss: 1.0440 - val_loss: 0.9488 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 358ms/step - loss: 0.8274 - val_loss: 0.8175 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 330ms/step - loss: 0.7036 - val_loss: 0.7563 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 354ms/step - loss: 0.6441 - val_loss: 0.7352 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 427ms/step - loss: 1.8002 - val_loss: 1.1562 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 1.0708 - val_loss: 1.0006 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 0.8746 - val_loss: 0.8629 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 345ms/step - loss: 0.7459 - val_loss: 0.7883 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 344ms/step - loss: 0.6798 - val_loss: 0.7711 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 411ms/step - loss: 1.8523 - val_loss: 1.1452 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 360ms/step - loss: 1.0540 - val_loss: 0.9802 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 348ms/step - loss: 0.8606 - val_loss: 0.8528 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 352ms/step - loss: 0.7423 - val_loss: 0.7930 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 360ms/step - loss: 0.6827 - val_loss: 0.7745 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 428ms/step - loss: 1.6985 - val_loss: 1.1326 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 343ms/step - loss: 1.0579 - val_loss: 0.9970 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 331ms/step - loss: 0.8764 - val_loss: 0.8446 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 343ms/step - loss: 0.7238 - val_loss: 0.7643 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 354ms/step - loss: 0.6552 - val_loss: 0.7380 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 403ms/step - loss: 1.7071 - val_loss: 1.1390 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 352ms/step - loss: 1.0619 - val_loss: 0.9939 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 342ms/step - loss: 0.8763 - val_loss: 0.8563 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 346ms/step - loss: 0.7336 - val_loss: 0.7750 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 369ms/step - loss: 0.6664 - val_loss: 0.7576 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 432ms/step - loss: 1.8574 - val_loss: 1.1610 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 1.0551 - val_loss: 0.9808 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 364ms/step - loss: 0.8565 - val_loss: 0.8465 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 359ms/step - loss: 0.7277 - val_loss: 0.7723 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 362ms/step - loss: 0.6647 - val_loss: 0.7518 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 425ms/step - loss: 1.7703 - val_loss: 1.1430 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 352ms/step - loss: 1.0639 - val_loss: 1.0137 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 0.8930 - val_loss: 0.8738 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 364ms/step - loss: 0.7468 - val_loss: 0.8002 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 363ms/step - loss: 0.6801 - val_loss: 0.7813 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 413ms/step - loss: 1.8700 - val_loss: 1.1462 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 1.0483 - val_loss: 0.9916 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 374ms/step - loss: 0.8626 - val_loss: 0.8661 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 339ms/step - loss: 0.7332 - val_loss: 0.7997 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 341ms/step - loss: 0.6708 - val_loss: 0.7752 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 429ms/step - loss: 1.7603 - val_loss: 1.1537 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 1.0637 - val_loss: 0.9966 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 0.8695 - val_loss: 0.8493 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 356ms/step - loss: 0.7338 - val_loss: 0.7843 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 367ms/step - loss: 0.6755 - val_loss: 0.7638 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 435ms/step - loss: 1.7878 - val_loss: 1.1677 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 367ms/step - loss: 1.0862 - val_loss: 1.0118 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 360ms/step - loss: 0.8927 - val_loss: 0.8761 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 350ms/step - loss: 0.7538 - val_loss: 0.8058 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 342ms/step - loss: 0.6924 - val_loss: 0.7830 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 426ms/step - loss: 1.8068 - val_loss: 1.1369 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 360ms/step - loss: 1.0514 - val_loss: 0.9810 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 353ms/step - loss: 0.8627 - val_loss: 0.8483 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 357ms/step - loss: 0.7336 - val_loss: 0.7830 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 355ms/step - loss: 0.6691 - val_loss: 0.7625 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 467ms/step - loss: 1.7360 - val_loss: 1.1587 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 14s 363ms/step - loss: 1.0461 - val_loss: 0.9686 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 361ms/step - loss: 0.8473 - val_loss: 0.8450 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 13s 357ms/step - loss: 0.7211 - val_loss: 0.7807 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 356ms/step - loss: 0.6619 - val_loss: 0.7664 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 448ms/step - loss: 1.7338 - val_loss: 1.1478 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 358ms/step - loss: 1.0754 - val_loss: 1.0255 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 347ms/step - loss: 0.9006 - val_loss: 0.8863 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 363ms/step - loss: 0.7675 - val_loss: 0.8129 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 337ms/step - loss: 0.7015 - val_loss: 0.7848 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 457ms/step - loss: 1.8019 - val_loss: 1.1431 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 353ms/step - loss: 1.0693 - val_loss: 0.9854 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 14s 362ms/step - loss: 0.8654 - val_loss: 0.8441 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 362ms/step - loss: 0.7307 - val_loss: 0.7663 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 13s 342ms/step - loss: 0.6643 - val_loss: 0.7453 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 31s 417ms/step - loss: 1.8246 - val_loss: 1.1301 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 13s 355ms/step - loss: 1.0491 - val_loss: 0.9758 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 13s 352ms/step - loss: 0.8521 - val_loss: 0.8437 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 14s 355ms/step - loss: 0.7317 - val_loss: 0.7784 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 14s 355ms/step - loss: 0.6668 - val_loss: 0.7638 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate on test set**"
      ],
      "metadata": {
        "id": "Zpt3-j6pCDGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicts = [model.predict(batch) for batch in batched_test_ds]"
      ],
      "metadata": {
        "id": "WiH14zw_D__V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "all_preds = []\n",
        "all_trues = []\n",
        "\n",
        "for batch in batched_test_ds:\n",
        "\n",
        "    y_preds_logits = model.predict(batch)['logits']\n",
        "    y_preds = np.argmax(y_preds_logits, axis = 2)\n",
        "    y_trues = batch['labels']\n",
        "    p = y_preds, y_trues\n",
        "\n",
        "    all_pred = [\n",
        "        [label_list[p] for (p, l) in zip(y_pred, y_true) if l != -100]\n",
        "        for y_pred, y_true in zip(y_preds, y_trues)]\n",
        "    all_true = [\n",
        "        [label_list[l] for (p, l) in zip(y_pred, y_true) if l != -100]\n",
        "        for y_pred, y_true in zip(y_preds, y_trues)]\n",
        "    \n",
        "    all_preds.extend([item for sublist in all_pred for item in sublist])\n",
        "    all_trues.extend([item for sublist in all_true for item in sublist])\n",
        "    \n",
        "    # break"
      ],
      "metadata": {
        "id": "1rqBsfR4ETCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(all_trues, all_preds))\n",
        "cr = classification_report(all_trues, all_preds, output_dict = True)"
      ],
      "metadata": {
        "id": "yY9VTrwMHKmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(cr)"
      ],
      "metadata": {
        "id": "dTq-5y5lIL7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction Pipeline**"
      ],
      "metadata": {
        "id": "ya4eePzoB8n4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TokenClassificationPipeline\n",
        "\n",
        "pipe = TokenClassificationPipeline(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    # aggregation_strategy = 'simple'\n",
        ")"
      ],
      "metadata": {
        "id": "kGyJ2dQvqqKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'The Micro-VCM datasheet shall contain the product type.'\n",
        "text = 'Storage conditions shall prevent the degredation of the structure.'\n",
        "text = 'A record of the process data shall be part of the process procedure'\n",
        "text = 'In case of doubt, the internal NRB shall classify nonconformances as major.'\n",
        "text = 'The Reserved shall be an 8-bit field that is set to 0x00.'\n",
        "\n",
        "pipe(text)"
      ],
      "metadata": {
        "id": "nyT6fezQCAGQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "t4_finetuning_seqlabel_er",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "Zpt3-j6pCDGC",
        "ya4eePzoB8n4"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ef86c65b58d43b8b0cd7f3e1ab81cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7809f63a8004a7bbf6692b305cc4622",
              "IPY_MODEL_529fa7a0e7a5446c8153db6a919ff086",
              "IPY_MODEL_7b930c8248e34ba1bb772e7b998973f2"
            ],
            "layout": "IPY_MODEL_73e6dbe728b742108f0e2b6090313080"
          }
        },
        "f7809f63a8004a7bbf6692b305cc4622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d8bad17781442ea87e03401773f1c9c",
            "placeholder": "​",
            "style": "IPY_MODEL_287d66b1b37c4fbc81cfaa729b85ffc3",
            "value": "Downloading: 100%"
          }
        },
        "529fa7a0e7a5446c8153db6a919ff086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aeefb4cad0b04744a30d17fd8fd8f4d3",
            "max": 1217,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d03d46064e04b1ab71c168e803d39d0",
            "value": 1217
          }
        },
        "7b930c8248e34ba1bb772e7b998973f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_414edeea4d3947e4a7872b82e1b0a2de",
            "placeholder": "​",
            "style": "IPY_MODEL_89ebaf8121c64012b9f100de9a6af299",
            "value": " 1.22k/1.22k [00:00&lt;00:00, 42.0kB/s]"
          }
        },
        "73e6dbe728b742108f0e2b6090313080": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d8bad17781442ea87e03401773f1c9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "287d66b1b37c4fbc81cfaa729b85ffc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aeefb4cad0b04744a30d17fd8fd8f4d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d03d46064e04b1ab71c168e803d39d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "414edeea4d3947e4a7872b82e1b0a2de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89ebaf8121c64012b9f100de9a6af299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3de3818a3e0493cb6238c30b10934e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b11bf400dc944fd8be7131a475574cd7",
              "IPY_MODEL_3be76a36ae8c4a399ed8c6faa62f0ee9",
              "IPY_MODEL_59e54f83d6ac43e3b2e3ee3b324022ea"
            ],
            "layout": "IPY_MODEL_2a88c3ff643342deb726b8080db15a16"
          }
        },
        "b11bf400dc944fd8be7131a475574cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f202bd163ed04f088f2619527eae8da2",
            "placeholder": "​",
            "style": "IPY_MODEL_e6e185ba82c54cc88426ced34fd8ee92",
            "value": "Downloading data files: 100%"
          }
        },
        "3be76a36ae8c4a399ed8c6faa62f0ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34290dd836c5458b9f40c036aad68982",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53d7d4439ca64fce864446be4b8fcd4f",
            "value": 3
          }
        },
        "59e54f83d6ac43e3b2e3ee3b324022ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_638419bef76f478ca79de83e3878f463",
            "placeholder": "​",
            "style": "IPY_MODEL_b8e2f290f22d41408b3cbd5d3bf1dc75",
            "value": " 3/3 [00:04&lt;00:00,  1.51s/it]"
          }
        },
        "2a88c3ff643342deb726b8080db15a16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f202bd163ed04f088f2619527eae8da2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6e185ba82c54cc88426ced34fd8ee92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34290dd836c5458b9f40c036aad68982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53d7d4439ca64fce864446be4b8fcd4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "638419bef76f478ca79de83e3878f463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8e2f290f22d41408b3cbd5d3bf1dc75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d75842eefd340b1aeff77469872b3e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a1466abb12d463992c1008364b5f6ad",
              "IPY_MODEL_dfdee446ef84438bac9fe4c27b825ae4",
              "IPY_MODEL_dbb5f30302914ac391e69583d80256a4"
            ],
            "layout": "IPY_MODEL_be0effe652514beb8190d20a11b39fd8"
          }
        },
        "5a1466abb12d463992c1008364b5f6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c2c76d624744616b1945ba2a5fe97fe",
            "placeholder": "​",
            "style": "IPY_MODEL_0be6fb50e9c14ac9aee20e81073e81f1",
            "value": "Downloading data: 100%"
          }
        },
        "dfdee446ef84438bac9fe4c27b825ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ba18cdcfd4b41838aed964a7045419c",
            "max": 13139,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_820dacb219f04931a3235f26e6717afc",
            "value": 13139
          }
        },
        "dbb5f30302914ac391e69583d80256a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f58e8143f71947c999010f0fbd4258fd",
            "placeholder": "​",
            "style": "IPY_MODEL_a22a568280714726b98004e63966024c",
            "value": " 13.1k/13.1k [00:00&lt;00:00, 433kB/s]"
          }
        },
        "be0effe652514beb8190d20a11b39fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c2c76d624744616b1945ba2a5fe97fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0be6fb50e9c14ac9aee20e81073e81f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ba18cdcfd4b41838aed964a7045419c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "820dacb219f04931a3235f26e6717afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f58e8143f71947c999010f0fbd4258fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a22a568280714726b98004e63966024c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "876f0a13033d4bbca3525b12c23d90c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f3d8e56780647bfb19883da562b118e",
              "IPY_MODEL_2b5430d786d64a10a3ace3d44cfc97a2",
              "IPY_MODEL_f7d6dae618d74298b8e4831160dbe466"
            ],
            "layout": "IPY_MODEL_8541585cb404472387ec7906427be376"
          }
        },
        "7f3d8e56780647bfb19883da562b118e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_175ee14f758140ba933e9c92f96ed28c",
            "placeholder": "​",
            "style": "IPY_MODEL_7d213200c13c47fdb6c0c0573b589ef0",
            "value": "Downloading data: 100%"
          }
        },
        "2b5430d786d64a10a3ace3d44cfc97a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_866f6b37e7b44e0a9d30b349d1b2a32a",
            "max": 45986,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_530313a4e510486a8d25551034bc824c",
            "value": 45986
          }
        },
        "f7d6dae618d74298b8e4831160dbe466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7d5355f3cfa4969bb08a12572c377d6",
            "placeholder": "​",
            "style": "IPY_MODEL_6cc8df35b64b46f9b3fcb19c1cf44adc",
            "value": " 46.0k/46.0k [00:00&lt;00:00, 629kB/s]"
          }
        },
        "8541585cb404472387ec7906427be376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "175ee14f758140ba933e9c92f96ed28c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d213200c13c47fdb6c0c0573b589ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "866f6b37e7b44e0a9d30b349d1b2a32a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "530313a4e510486a8d25551034bc824c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7d5355f3cfa4969bb08a12572c377d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cc8df35b64b46f9b3fcb19c1cf44adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cafc449bbd434613917f0f342075ba38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11699ea68e744368a21f2d93d62a5d56",
              "IPY_MODEL_d3732647a21846cfb464278e9c2e3536",
              "IPY_MODEL_996b87d212d64aa9acd81e7544343f40"
            ],
            "layout": "IPY_MODEL_13f3899110fd4f669d08a606ef9774bd"
          }
        },
        "11699ea68e744368a21f2d93d62a5d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51fbb16c681c4d5ebf71f25dcc830a53",
            "placeholder": "​",
            "style": "IPY_MODEL_64ba22a884fe4670aab5353534de97d4",
            "value": "Downloading data: 100%"
          }
        },
        "d3732647a21846cfb464278e9c2e3536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22a14a5be11a433c9e918b0a8c8def41",
            "max": 13691,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b35a000e34d44f399daf291f4c572bd",
            "value": 13691
          }
        },
        "996b87d212d64aa9acd81e7544343f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a146eba53484ffabe0b1a42d615d19c",
            "placeholder": "​",
            "style": "IPY_MODEL_375c6ac294a24cb185f1dac4344881c4",
            "value": " 13.7k/13.7k [00:00&lt;00:00, 503kB/s]"
          }
        },
        "13f3899110fd4f669d08a606ef9774bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51fbb16c681c4d5ebf71f25dcc830a53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64ba22a884fe4670aab5353534de97d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22a14a5be11a433c9e918b0a8c8def41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b35a000e34d44f399daf291f4c572bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a146eba53484ffabe0b1a42d615d19c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "375c6ac294a24cb185f1dac4344881c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ce297a279824bc3a539470797af1fb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c98674c7a3547f786fdc07a156f1a69",
              "IPY_MODEL_96080d1803644e13979237ceae6defc8",
              "IPY_MODEL_3fb3e259d8664f8888e74b55f49d9b16"
            ],
            "layout": "IPY_MODEL_5603fd1114004644866020a91fc6d240"
          }
        },
        "9c98674c7a3547f786fdc07a156f1a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52775425286740a29d6066a0ec5a8e9e",
            "placeholder": "​",
            "style": "IPY_MODEL_6ac79de7d219460a9ef043467816e7ed",
            "value": "Extracting data files: 100%"
          }
        },
        "96080d1803644e13979237ceae6defc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8b6e74af3694deb80d42867c633bd0e",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9eeee54e691443ba86f103ed1165f7e2",
            "value": 3
          }
        },
        "3fb3e259d8664f8888e74b55f49d9b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a81344333ee40d28a891627d8f47251",
            "placeholder": "​",
            "style": "IPY_MODEL_ebefbbd970e24f58b28d26943efc1f0e",
            "value": " 3/3 [00:00&lt;00:00, 69.52it/s]"
          }
        },
        "5603fd1114004644866020a91fc6d240": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52775425286740a29d6066a0ec5a8e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ac79de7d219460a9ef043467816e7ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8b6e74af3694deb80d42867c633bd0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eeee54e691443ba86f103ed1165f7e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a81344333ee40d28a891627d8f47251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebefbbd970e24f58b28d26943efc1f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e17731033c394b75b14870dbfe405a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b21cfd8566c4738805085938e873d1f",
              "IPY_MODEL_70513a19d4b34c5ab479683df032a749",
              "IPY_MODEL_8dc17ffa2ee24e31b8dc84e864ceeb87"
            ],
            "layout": "IPY_MODEL_3b8f058790ff4831b48aee5171457542"
          }
        },
        "6b21cfd8566c4738805085938e873d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31583d7292cd4f3abe5bc71ff1b2240c",
            "placeholder": "​",
            "style": "IPY_MODEL_b66f3d5a77c345b0994ccb926befa8ce",
            "value": "100%"
          }
        },
        "70513a19d4b34c5ab479683df032a749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_473021abcab84cf4bc24f2ccd22cbda1",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2a58d8bed634732acce910e0589ff73",
            "value": 3
          }
        },
        "8dc17ffa2ee24e31b8dc84e864ceeb87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0827a3aeb41349028f5a65dcf892bade",
            "placeholder": "​",
            "style": "IPY_MODEL_4b7cb1dc8b224852bafd6acb8aca7f63",
            "value": " 3/3 [00:00&lt;00:00, 74.07it/s]"
          }
        },
        "3b8f058790ff4831b48aee5171457542": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31583d7292cd4f3abe5bc71ff1b2240c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b66f3d5a77c345b0994ccb926befa8ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "473021abcab84cf4bc24f2ccd22cbda1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2a58d8bed634732acce910e0589ff73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0827a3aeb41349028f5a65dcf892bade": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b7cb1dc8b224852bafd6acb8aca7f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edeebfcd97c34c55aff7d54669911ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a739fc0acd8a451bacb768efe3e50b7d",
              "IPY_MODEL_f5814727a8d0482d86d7dc9217bc2c1c",
              "IPY_MODEL_5448d4c3845d4eeabca1ad37e1feb9f8"
            ],
            "layout": "IPY_MODEL_7b6c37a0a8b941e7adfb7deacc180b19"
          }
        },
        "a739fc0acd8a451bacb768efe3e50b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_091011e980a0444ead7831fcf2c1442f",
            "placeholder": "​",
            "style": "IPY_MODEL_cdfefe39958b48c99e3d903f6d40b014",
            "value": "100%"
          }
        },
        "f5814727a8d0482d86d7dc9217bc2c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3e7692a8da44ef0bf403757c4a8af5e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcbd5b2e562140138f2002d7383e798d",
            "value": 1
          }
        },
        "5448d4c3845d4eeabca1ad37e1feb9f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3dda80e41b747e8ab885b8665d2e47e",
            "placeholder": "​",
            "style": "IPY_MODEL_0be9f8583a83479284c6daed2fa37400",
            "value": " 1/1 [00:00&lt;00:00,  9.00ba/s]"
          }
        },
        "7b6c37a0a8b941e7adfb7deacc180b19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "091011e980a0444ead7831fcf2c1442f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdfefe39958b48c99e3d903f6d40b014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3e7692a8da44ef0bf403757c4a8af5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcbd5b2e562140138f2002d7383e798d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3dda80e41b747e8ab885b8665d2e47e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0be9f8583a83479284c6daed2fa37400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd6e0e913cf24b83bf21b4167a3f7a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_360ddf4b57934351a0aa55efc884305c",
              "IPY_MODEL_352e8988c90442a1b621bf8f22e4ef68",
              "IPY_MODEL_ed3d667d92bf4511ace3cf83291b7f56"
            ],
            "layout": "IPY_MODEL_08e1780b8d3d4c13af480169375d8dff"
          }
        },
        "360ddf4b57934351a0aa55efc884305c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_698c0b5f512543d4967c9b98fc382070",
            "placeholder": "​",
            "style": "IPY_MODEL_f96f7bd601b34876aa213514f79e8738",
            "value": "Downloading: 100%"
          }
        },
        "352e8988c90442a1b621bf8f22e4ef68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_371b9afa8f7f405cb695a79fdfdd6dcb",
            "max": 644,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dae4f9e4eaac42bb9064d2daab7fa648",
            "value": 644
          }
        },
        "ed3d667d92bf4511ace3cf83291b7f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bedd9abf3f00490a979c43b61cd3ef7d",
            "placeholder": "​",
            "style": "IPY_MODEL_7b24cfccfc83486d9d73152273697c77",
            "value": " 644/644 [00:00&lt;00:00, 24.2kB/s]"
          }
        },
        "08e1780b8d3d4c13af480169375d8dff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "698c0b5f512543d4967c9b98fc382070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f96f7bd601b34876aa213514f79e8738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "371b9afa8f7f405cb695a79fdfdd6dcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dae4f9e4eaac42bb9064d2daab7fa648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bedd9abf3f00490a979c43b61cd3ef7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b24cfccfc83486d9d73152273697c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "def6377eff9a4c75ae85e0b71344c183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69632f861d3a4247bfcafcdb56f50478",
              "IPY_MODEL_3fede457ca12442698304a8053057dd5",
              "IPY_MODEL_3258ce25f3114c6680de34e8a9a68bdb"
            ],
            "layout": "IPY_MODEL_094593899f75438c9568ec65f8abade4"
          }
        },
        "69632f861d3a4247bfcafcdb56f50478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcaeda16766e4b09a7cc4c77dee21ff1",
            "placeholder": "​",
            "style": "IPY_MODEL_a68c00a06a39492c822b18e345850243",
            "value": "Downloading: 100%"
          }
        },
        "3fede457ca12442698304a8053057dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a2adcba33cd48459faef2b2ce19c207",
            "max": 655071244,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d23b1312a24441e97a5407462c56223",
            "value": 655071244
          }
        },
        "3258ce25f3114c6680de34e8a9a68bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b98f366b55344187a13da479bf3c29dd",
            "placeholder": "​",
            "style": "IPY_MODEL_c8bff20330bb4b3693e8f1029e914637",
            "value": " 625M/625M [00:23&lt;00:00, 19.1MB/s]"
          }
        },
        "094593899f75438c9568ec65f8abade4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcaeda16766e4b09a7cc4c77dee21ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a68c00a06a39492c822b18e345850243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a2adcba33cd48459faef2b2ce19c207": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d23b1312a24441e97a5407462c56223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b98f366b55344187a13da479bf3c29dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8bff20330bb4b3693e8f1029e914637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}