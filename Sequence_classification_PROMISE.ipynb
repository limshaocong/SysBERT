{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence_classification_PROMISE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/limshaocong/SysBERT/blob/main/Sequence_classification_PROMISE.ipynb",
      "authorship_tag": "ABX9TyOBGT6BS3pXbIyZaP9nvpCE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9deb9b05fc004000890c8e575a8c6423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2c42feb699a464883d07ce7613fc2bc",
              "IPY_MODEL_29dabea013b94fe8acf9c85874f4df4b",
              "IPY_MODEL_941f346f49c147698dc8ebee2ec750c6"
            ],
            "layout": "IPY_MODEL_d2138faa1e21440c8c4c036b860a2ceb"
          }
        },
        "b2c42feb699a464883d07ce7613fc2bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e66d5df0e00f481e99df672983000a43",
            "placeholder": "​",
            "style": "IPY_MODEL_15cd074a0d80425e80425354240b92df",
            "value": "100%"
          }
        },
        "29dabea013b94fe8acf9c85874f4df4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a7094bda6594803b222067aa767f7a9",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d607f25229b47509b11f207725a72ae",
            "value": 3
          }
        },
        "941f346f49c147698dc8ebee2ec750c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5e86d095c5844babd5ea6c65b2c4c8d",
            "placeholder": "​",
            "style": "IPY_MODEL_97289058c6d947a290f3b884fb94dd2d",
            "value": " 3/3 [00:00&lt;00:00, 62.01it/s]"
          }
        },
        "d2138faa1e21440c8c4c036b860a2ceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e66d5df0e00f481e99df672983000a43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15cd074a0d80425e80425354240b92df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a7094bda6594803b222067aa767f7a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d607f25229b47509b11f207725a72ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5e86d095c5844babd5ea6c65b2c4c8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97289058c6d947a290f3b884fb94dd2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62717babe0a04e5ba6fb884485980a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_021f7ca5faed45c3ba2700dc5132be3b",
              "IPY_MODEL_6a60aef37bed4d37a18ed59b45f48ba8",
              "IPY_MODEL_d063691520a5440b98d12fa0f8160eb5"
            ],
            "layout": "IPY_MODEL_43ece8dc853d48cbb5b2ce8abd94de05"
          }
        },
        "021f7ca5faed45c3ba2700dc5132be3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac6febd239f74ecc870594e0d18fd410",
            "placeholder": "​",
            "style": "IPY_MODEL_6ff44363c4914f5693e2582ab882c4c5",
            "value": "Downloading: 100%"
          }
        },
        "6a60aef37bed4d37a18ed59b45f48ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d984965519544d609f4ea79924b7ec0d",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_449b1602bb5e4532a18cb38d790ce35c",
            "value": 481
          }
        },
        "d063691520a5440b98d12fa0f8160eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ad5107d08b640d5a97d54e96f76db74",
            "placeholder": "​",
            "style": "IPY_MODEL_f6e089a37c114b8ebe03c5d8aa22b435",
            "value": " 481/481 [00:00&lt;00:00, 17.6kB/s]"
          }
        },
        "43ece8dc853d48cbb5b2ce8abd94de05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac6febd239f74ecc870594e0d18fd410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff44363c4914f5693e2582ab882c4c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d984965519544d609f4ea79924b7ec0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "449b1602bb5e4532a18cb38d790ce35c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ad5107d08b640d5a97d54e96f76db74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6e089a37c114b8ebe03c5d8aa22b435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9ec0062990b4052b6b959e7bdbf35f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16e3c64e87064fc49496ff85675792ee",
              "IPY_MODEL_b228d694c7b1469d821d7835fe39359b",
              "IPY_MODEL_7430658590e7453c97e53f5a24a3193c"
            ],
            "layout": "IPY_MODEL_7086fb6858d741c799b37dc9040039aa"
          }
        },
        "16e3c64e87064fc49496ff85675792ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d0fcf99c49e40f6ba7f3151a8fef16a",
            "placeholder": "​",
            "style": "IPY_MODEL_690ebeaa57ee4325ac23f7d3740393ea",
            "value": "Downloading: 100%"
          }
        },
        "b228d694c7b1469d821d7835fe39359b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a0abc99b5d0468d8f92a0e2de322613",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76d066f677c846c9a1d8529698234b96",
            "value": 898823
          }
        },
        "7430658590e7453c97e53f5a24a3193c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3a70c52693047da92583ed4d951e06e",
            "placeholder": "​",
            "style": "IPY_MODEL_1911edb724a749cb90a8ca291bc71813",
            "value": " 878k/878k [00:01&lt;00:00, 1.23MB/s]"
          }
        },
        "7086fb6858d741c799b37dc9040039aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d0fcf99c49e40f6ba7f3151a8fef16a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "690ebeaa57ee4325ac23f7d3740393ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a0abc99b5d0468d8f92a0e2de322613": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76d066f677c846c9a1d8529698234b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3a70c52693047da92583ed4d951e06e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1911edb724a749cb90a8ca291bc71813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e87ddc4b0d8498583231f2059eff368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e81426cac57467c8fbf0e1ef0819ef9",
              "IPY_MODEL_9a329a9247f44bf993d2c41bdd4d3731",
              "IPY_MODEL_9fcb8a65acd2401981872ac3cf223717"
            ],
            "layout": "IPY_MODEL_981efe40c5b940f98bee635b04ce3294"
          }
        },
        "3e81426cac57467c8fbf0e1ef0819ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33a9491c5dcd4422bbf9b2dccb45ca2e",
            "placeholder": "​",
            "style": "IPY_MODEL_b3c890e83230451a975c4d70c59701ca",
            "value": "Downloading: 100%"
          }
        },
        "9a329a9247f44bf993d2c41bdd4d3731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d754ca9ba9e47dcb1eaf5bc384d1d42",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2a7434b809c4687a9b0a41017c2f222",
            "value": 456318
          }
        },
        "9fcb8a65acd2401981872ac3cf223717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90c6a6be03834385902805aa83a1b790",
            "placeholder": "​",
            "style": "IPY_MODEL_e388ee6ca82e4368974ade5dc58f1aad",
            "value": " 446k/446k [00:00&lt;00:00, 636kB/s]"
          }
        },
        "981efe40c5b940f98bee635b04ce3294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33a9491c5dcd4422bbf9b2dccb45ca2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3c890e83230451a975c4d70c59701ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d754ca9ba9e47dcb1eaf5bc384d1d42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2a7434b809c4687a9b0a41017c2f222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90c6a6be03834385902805aa83a1b790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e388ee6ca82e4368974ade5dc58f1aad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c017b5c7d404d0b9aa7f839c11f9ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e21560a9998e4ab5a9f60725fb0d8fb7",
              "IPY_MODEL_a4a769a845d44f2695e0554a25df0de1",
              "IPY_MODEL_7ff1e709166d497e83b30bd5c98bec01"
            ],
            "layout": "IPY_MODEL_d753806f9f214141aa38e914e528f901"
          }
        },
        "e21560a9998e4ab5a9f60725fb0d8fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f37773bba5947f78ded73852ec6be60",
            "placeholder": "​",
            "style": "IPY_MODEL_a455462102264c018da9a2e9f1f69c25",
            "value": "Downloading: 100%"
          }
        },
        "a4a769a845d44f2695e0554a25df0de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06f010efc8fb45d3be1d12a8ce8741be",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7d82d84dd4346f78ad051f21b86b124",
            "value": 1355863
          }
        },
        "7ff1e709166d497e83b30bd5c98bec01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_923f903841874e60b59f2b8eaa299905",
            "placeholder": "​",
            "style": "IPY_MODEL_7ffcfb86362544cabd5764e4e14f68dd",
            "value": " 1.29M/1.29M [00:01&lt;00:00, 1.22MB/s]"
          }
        },
        "d753806f9f214141aa38e914e528f901": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f37773bba5947f78ded73852ec6be60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a455462102264c018da9a2e9f1f69c25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06f010efc8fb45d3be1d12a8ce8741be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7d82d84dd4346f78ad051f21b86b124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "923f903841874e60b59f2b8eaa299905": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ffcfb86362544cabd5764e4e14f68dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b47f0bcced1a48c386ec6a296415f73f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d41820b1bbc4b09828e10ea0a3a68f1",
              "IPY_MODEL_f6707b23ae404824aeb432b473e1e2b9",
              "IPY_MODEL_e86fbe05213341eb817a4bf4e0f090b4"
            ],
            "layout": "IPY_MODEL_ae0b4c06da4f45b4a85dc46db731940d"
          }
        },
        "6d41820b1bbc4b09828e10ea0a3a68f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e29d60ca208a4c69b3d7c064bcfb0db0",
            "placeholder": "​",
            "style": "IPY_MODEL_fe3e76af39724401a8cc39b3a546997d",
            "value": "100%"
          }
        },
        "f6707b23ae404824aeb432b473e1e2b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cf59c1b1b8f4836811cf0839d95ce73",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fff6849b7df49de944b88d07d2d3a0b",
            "value": 1
          }
        },
        "e86fbe05213341eb817a4bf4e0f090b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7063844d1c404692b58c65af054c54dd",
            "placeholder": "​",
            "style": "IPY_MODEL_3645a3a273a841e2ae158cfe0b8c4170",
            "value": " 1/1 [00:00&lt;00:00, 19.93ba/s]"
          }
        },
        "ae0b4c06da4f45b4a85dc46db731940d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e29d60ca208a4c69b3d7c064bcfb0db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe3e76af39724401a8cc39b3a546997d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cf59c1b1b8f4836811cf0839d95ce73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fff6849b7df49de944b88d07d2d3a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7063844d1c404692b58c65af054c54dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3645a3a273a841e2ae158cfe0b8c4170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d88e8cf7da934d3092775eb8fd03f9cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_980e0746a2874fcc917a20f065706304",
              "IPY_MODEL_8c08c8d032504d80bbe9c7724165c4e8",
              "IPY_MODEL_66bd83b1bb1b4876b200f922d438769b"
            ],
            "layout": "IPY_MODEL_0135de1f4a3b485ea99009bb2f88e083"
          }
        },
        "980e0746a2874fcc917a20f065706304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_496878de8d6445dca171656474b8b52f",
            "placeholder": "​",
            "style": "IPY_MODEL_ccfe8c5f399a41f985049406b02d27ee",
            "value": "100%"
          }
        },
        "8c08c8d032504d80bbe9c7724165c4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_983977de7c254dab8d675181bb556e23",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f99a62252d8408da0f935c8027be3ab",
            "value": 1
          }
        },
        "66bd83b1bb1b4876b200f922d438769b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69659252ecf044cebe1a073a60c1846e",
            "placeholder": "​",
            "style": "IPY_MODEL_c7b586d2198a48f6b7b40bf9b22a3f9c",
            "value": " 1/1 [00:00&lt;00:00, 16.14ba/s]"
          }
        },
        "0135de1f4a3b485ea99009bb2f88e083": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "496878de8d6445dca171656474b8b52f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccfe8c5f399a41f985049406b02d27ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "983977de7c254dab8d675181bb556e23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f99a62252d8408da0f935c8027be3ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69659252ecf044cebe1a073a60c1846e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7b586d2198a48f6b7b40bf9b22a3f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b61d45682234ee2a7736bf08f84e709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea58273264a048409041a3bafab96f6b",
              "IPY_MODEL_a771060517b84ababba9fef8c619fcf0",
              "IPY_MODEL_d8ef876c0f0349fd9f1422ffaf55d97e"
            ],
            "layout": "IPY_MODEL_098001d0c751430798545b06f2fef161"
          }
        },
        "ea58273264a048409041a3bafab96f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae95061e0bda4681ac325c81cd1b13ad",
            "placeholder": "​",
            "style": "IPY_MODEL_5e839f055f0d4899833b338ca4efda75",
            "value": "100%"
          }
        },
        "a771060517b84ababba9fef8c619fcf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4e0099eeb944a749f62a70f881825fd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3405075160b45ea836d7581a3122f4f",
            "value": 1
          }
        },
        "d8ef876c0f0349fd9f1422ffaf55d97e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adf28f9f17214debb1081d2823494683",
            "placeholder": "​",
            "style": "IPY_MODEL_1c2aa96f0c0b4da9ac2f4a0fe863a1e6",
            "value": " 1/1 [00:00&lt;00:00, 26.12ba/s]"
          }
        },
        "098001d0c751430798545b06f2fef161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae95061e0bda4681ac325c81cd1b13ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e839f055f0d4899833b338ca4efda75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4e0099eeb944a749f62a70f881825fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3405075160b45ea836d7581a3122f4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "adf28f9f17214debb1081d2823494683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c2aa96f0c0b4da9ac2f4a0fe863a1e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75465b25fed349008c1b242ad77e1f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bff5dde5a57482b830129aad4da8671",
              "IPY_MODEL_4ce81d252d5a48d58cffdb752022fbb8",
              "IPY_MODEL_814af0a2b44247269df5e08f9a8c3a21"
            ],
            "layout": "IPY_MODEL_fd02a796ce5a40c8bf6fdee45c1c0b14"
          }
        },
        "8bff5dde5a57482b830129aad4da8671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c895191066745e6a1f5e084c09d71c3",
            "placeholder": "​",
            "style": "IPY_MODEL_2d53ab209a6042878d5cd47969484df8",
            "value": "Downloading: 100%"
          }
        },
        "4ce81d252d5a48d58cffdb752022fbb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16da5163ebcb4cfdb73f0da3982eed2c",
            "max": 657434796,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6299d29396aa4bd2907f6670ab271803",
            "value": 657434796
          }
        },
        "814af0a2b44247269df5e08f9a8c3a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_148f85999fc94f6b878b658bfcd3a294",
            "placeholder": "​",
            "style": "IPY_MODEL_3d5ce607782e4aefb7f5032102f9a486",
            "value": " 627M/627M [00:09&lt;00:00, 62.9MB/s]"
          }
        },
        "fd02a796ce5a40c8bf6fdee45c1c0b14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c895191066745e6a1f5e084c09d71c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d53ab209a6042878d5cd47969484df8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16da5163ebcb4cfdb73f0da3982eed2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6299d29396aa4bd2907f6670ab271803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "148f85999fc94f6b878b658bfcd3a294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d5ce607782e4aefb7f5032102f9a486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limshaocong/SysBERT/blob/main/Sequence_classification_PROMISE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminaries"
      ],
      "metadata": {
        "id": "TqR3LVRwwOUL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j_Fcva80wIoC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc08cb32-99e5-4de2-94a0-e1374581fd37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: dill<0.3.5 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "# Colab\n",
        "! pip install datasets transformers\n",
        "\n",
        "# GCP Vertax\n",
        "# ! pip install --user datasets transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYf42IlbwT71",
        "outputId": "552b7ee5-cb08-4c2b-f766-e7b9010de066"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-c36be9f3-7c2b-d9ab-c697-cbed9c0379fe)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! huggingface-cli login\n",
        "# # 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"
      ],
      "metadata": {
        "id": "CK9BND9CN-Zp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import & Pre-process Data"
      ],
      "metadata": {
        "id": "tnUpDgCHwXve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_type_dict = {\n",
        "    'bert-base-cased' : 'bert-base-cased',\n",
        "    'roberta-base' : 'roberta-base',\n",
        "    'allenai/scibert_scivocab_cased' : 'allenai/scibert_scivocab_cased',\n",
        "    'limsc/reqbert-tapt-epoch29' : 'bert-base-cased',\n",
        "    'limsc/reqbert-tapt-epoch30' : 'bert-base-cased',\n",
        "    'limsc/reqroberta-tapt-epoch20' : 'roberta-base',\n",
        "    'limsc/reqroberta-tapt-epoch33' : 'roberta-base',\n",
        "    'limsc/reqroberta-tapt-epoch43' : 'roberta-base',\n",
        "    'limsc/reqroberta-tapt-epoch50' : 'roberta-base',\n",
        "    'limsc/reqscibert-tapt-epoch10' : 'allenai/scibert_scivocab_cased',\n",
        "    'limsc/reqscibert-tapt-epoch20' : 'allenai/scibert_scivocab_cased',\n",
        "    'limsc/reqscibert-tapt-epoch31' : 'allenai/scibert_scivocab_cased',\n",
        "    'limsc/reqscibert-tapt-epoch49' : 'allenai/scibert_scivocab_cased',\n",
        "}\n",
        "\n",
        "model_name_dict = {\n",
        "    'bert-base-cased' : 'bert',\n",
        "    'roberta-base' : 'roberta',\n",
        "    'allenai/scibert_scivocab_cased' : 'scibert',\n",
        "    'limsc/reqbert-tapt-epoch29' : 'reqbert-e29',\n",
        "    'limsc/reqbert-tapt-epoch30' : 'reqbert-e30',\n",
        "    'limsc/reqroberta-tapt-epoch20' : 'reqroberta-e20',\n",
        "    'limsc/reqroberta-tapt-epoch33' : 'reqroberta-e33',\n",
        "    'limsc/reqroberta-tapt-epoch43' : 'reqroberta-e43',\n",
        "    'limsc/reqroberta-tapt-epoch50' : 'reqroberta-e50',\n",
        "    'limsc/reqscibert-tapt-epoch10' : 'reqscibert-e10',\n",
        "    'limsc/reqscibert-tapt-epoch20' : 'reqscibert-e20',\n",
        "    'limsc/reqscibert-tapt-epoch31' : 'reqscibert-e31',\n",
        "    'limsc/reqscibert-tapt-epoch49' : 'reqscibert-e49',\n",
        "}\n",
        "\n",
        "task_name_dict = {\n",
        "    'limsc/fr-nfr-classification' : 'frnfr',\n",
        "    'limsc/nfr-subclass-classification' : 'subclass',\n",
        "    'limsc/concept-recognition' : 'cr',\n",
        "    'limsc/sysmlv2-entity-extraction' : 'ee'\n",
        "}"
      ],
      "metadata": {
        "id": "J8uBkFb9opfV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds_name = 'limsc/fr-nfr-classification'\n",
        "ds = load_dataset(ds_name)\n",
        "ds"
      ],
      "metadata": {
        "id": "DWmcoTZ1OMyg",
        "outputId": "29d2edd6-04bf-499d-ad30-5a0ea966fbf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347,
          "referenced_widgets": [
            "9deb9b05fc004000890c8e575a8c6423",
            "b2c42feb699a464883d07ce7613fc2bc",
            "29dabea013b94fe8acf9c85874f4df4b",
            "941f346f49c147698dc8ebee2ec750c6",
            "d2138faa1e21440c8c4c036b860a2ceb",
            "e66d5df0e00f481e99df672983000a43",
            "15cd074a0d80425e80425354240b92df",
            "7a7094bda6594803b222067aa767f7a9",
            "3d607f25229b47509b11f207725a72ae",
            "d5e86d095c5844babd5ea6c65b2c4c8d",
            "97289058c6d947a290f3b884fb94dd2d"
          ]
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration limsc--fr-nfr-classification-665313997f6e1426\n",
            "Reusing dataset parquet (/root/.cache/huggingface/datasets/limsc___parquet/limsc--fr-nfr-classification-665313997f6e1426/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9deb9b05fc004000890c8e575a8c6423"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    val: Dataset({\n",
              "        features: ['reqs', 'is_functional'],\n",
              "        num_rows: 143\n",
              "    })\n",
              "    train: Dataset({\n",
              "        features: ['reqs', 'is_functional'],\n",
              "        num_rows: 669\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['reqs', 'is_functional'],\n",
              "        num_rows: 144\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To transform natural language requirements into a BERT-compatible format, the text must first be tokenized. This is performed using a pre-trained tokenizer."
      ],
      "metadata": {
        "id": "zn7Ap9euKCSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = 'roberta-base'"
      ],
      "metadata": {
        "id": "JD9a0nLfmOTh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_type_dict[model_checkpoint],\n",
        "    use_fast = True\n",
        ")\n",
        "\n",
        "def encode(requirements):\n",
        "    return tokenizer(requirements['reqs'], truncation = True, max_length = 128)\n",
        "\n",
        "tokenized_ds = ds.map(encode, batched = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "62717babe0a04e5ba6fb884485980a09",
            "021f7ca5faed45c3ba2700dc5132be3b",
            "6a60aef37bed4d37a18ed59b45f48ba8",
            "d063691520a5440b98d12fa0f8160eb5",
            "43ece8dc853d48cbb5b2ce8abd94de05",
            "ac6febd239f74ecc870594e0d18fd410",
            "6ff44363c4914f5693e2582ab882c4c5",
            "d984965519544d609f4ea79924b7ec0d",
            "449b1602bb5e4532a18cb38d790ce35c",
            "7ad5107d08b640d5a97d54e96f76db74",
            "f6e089a37c114b8ebe03c5d8aa22b435",
            "b9ec0062990b4052b6b959e7bdbf35f0",
            "16e3c64e87064fc49496ff85675792ee",
            "b228d694c7b1469d821d7835fe39359b",
            "7430658590e7453c97e53f5a24a3193c",
            "7086fb6858d741c799b37dc9040039aa",
            "1d0fcf99c49e40f6ba7f3151a8fef16a",
            "690ebeaa57ee4325ac23f7d3740393ea",
            "4a0abc99b5d0468d8f92a0e2de322613",
            "76d066f677c846c9a1d8529698234b96",
            "f3a70c52693047da92583ed4d951e06e",
            "1911edb724a749cb90a8ca291bc71813",
            "3e87ddc4b0d8498583231f2059eff368",
            "3e81426cac57467c8fbf0e1ef0819ef9",
            "9a329a9247f44bf993d2c41bdd4d3731",
            "9fcb8a65acd2401981872ac3cf223717",
            "981efe40c5b940f98bee635b04ce3294",
            "33a9491c5dcd4422bbf9b2dccb45ca2e",
            "b3c890e83230451a975c4d70c59701ca",
            "7d754ca9ba9e47dcb1eaf5bc384d1d42",
            "d2a7434b809c4687a9b0a41017c2f222",
            "90c6a6be03834385902805aa83a1b790",
            "e388ee6ca82e4368974ade5dc58f1aad",
            "7c017b5c7d404d0b9aa7f839c11f9ac3",
            "e21560a9998e4ab5a9f60725fb0d8fb7",
            "a4a769a845d44f2695e0554a25df0de1",
            "7ff1e709166d497e83b30bd5c98bec01",
            "d753806f9f214141aa38e914e528f901",
            "9f37773bba5947f78ded73852ec6be60",
            "a455462102264c018da9a2e9f1f69c25",
            "06f010efc8fb45d3be1d12a8ce8741be",
            "d7d82d84dd4346f78ad051f21b86b124",
            "923f903841874e60b59f2b8eaa299905",
            "7ffcfb86362544cabd5764e4e14f68dd",
            "b47f0bcced1a48c386ec6a296415f73f",
            "6d41820b1bbc4b09828e10ea0a3a68f1",
            "f6707b23ae404824aeb432b473e1e2b9",
            "e86fbe05213341eb817a4bf4e0f090b4",
            "ae0b4c06da4f45b4a85dc46db731940d",
            "e29d60ca208a4c69b3d7c064bcfb0db0",
            "fe3e76af39724401a8cc39b3a546997d",
            "2cf59c1b1b8f4836811cf0839d95ce73",
            "2fff6849b7df49de944b88d07d2d3a0b",
            "7063844d1c404692b58c65af054c54dd",
            "3645a3a273a841e2ae158cfe0b8c4170",
            "d88e8cf7da934d3092775eb8fd03f9cf",
            "980e0746a2874fcc917a20f065706304",
            "8c08c8d032504d80bbe9c7724165c4e8",
            "66bd83b1bb1b4876b200f922d438769b",
            "0135de1f4a3b485ea99009bb2f88e083",
            "496878de8d6445dca171656474b8b52f",
            "ccfe8c5f399a41f985049406b02d27ee",
            "983977de7c254dab8d675181bb556e23",
            "9f99a62252d8408da0f935c8027be3ab",
            "69659252ecf044cebe1a073a60c1846e",
            "c7b586d2198a48f6b7b40bf9b22a3f9c",
            "8b61d45682234ee2a7736bf08f84e709",
            "ea58273264a048409041a3bafab96f6b",
            "a771060517b84ababba9fef8c619fcf0",
            "d8ef876c0f0349fd9f1422ffaf55d97e",
            "098001d0c751430798545b06f2fef161",
            "ae95061e0bda4681ac325c81cd1b13ad",
            "5e839f055f0d4899833b338ca4efda75",
            "b4e0099eeb944a749f62a70f881825fd",
            "a3405075160b45ea836d7581a3122f4f",
            "adf28f9f17214debb1081d2823494683",
            "1c2aa96f0c0b4da9ac2f4a0fe863a1e6"
          ]
        },
        "id": "spE8dDfKx334",
        "outputId": "a1022fa3-f68a-42c1-b607-a2d2ae332d24"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62717babe0a04e5ba6fb884485980a09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9ec0062990b4052b6b959e7bdbf35f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e87ddc4b0d8498583231f2059eff368"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c017b5c7d404d0b9aa7f839c11f9ac3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b47f0bcced1a48c386ec6a296415f73f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d88e8cf7da934d3092775eb8fd03f9cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b61d45682234ee2a7736bf08f84e709"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkfXOWxKHbMT",
        "outputId": "3991eb62-3224-42f9-f831-c379ffc4ebaf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    val: Dataset({\n",
              "        features: ['reqs', 'is_functional', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 143\n",
              "    })\n",
              "    train: Dataset({\n",
              "        features: ['reqs', 'is_functional', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 669\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['reqs', 'is_functional', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 144\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "batch_size = 32\n",
        "output_col = 'is_functional'\n",
        "\n",
        "data_collator = DataCollatorWithPadding(\n",
        "    tokenizer = tokenizer,\n",
        "    return_tensors = 'tf'\n",
        ")\n",
        "\n",
        "def batching(tokenized_ds, batch_size):\n",
        "\n",
        "  batched_train_ds = tokenized_ds['train'].to_tf_dataset(\n",
        "      columns = ['attention_mask', 'input_ids', 'token_type_ids'],\n",
        "      label_cols = [output_col],\n",
        "      shuffle = False,\n",
        "      drop_remainder = False,\n",
        "      collate_fn = data_collator,\n",
        "      batch_size = batch_size\n",
        "  )\n",
        "\n",
        "  batched_val_ds = tokenized_ds['val'].to_tf_dataset(\n",
        "      columns = ['attention_mask', 'input_ids', 'token_type_ids'],\n",
        "      label_cols = [output_col],\n",
        "      shuffle = False,\n",
        "      drop_remainder = False,\n",
        "      collate_fn = data_collator,\n",
        "      batch_size = batch_size\n",
        "  )\n",
        "\n",
        "  batched_test_ds = tokenized_ds['test'].to_tf_dataset(\n",
        "      columns = ['attention_mask', 'input_ids', 'token_type_ids'],\n",
        "      label_cols = [output_col],\n",
        "      shuffle = False,\n",
        "      drop_remainder = False,\n",
        "      collate_fn = data_collator,\n",
        "      batch_size = batch_size\n",
        "  )\n",
        "\n",
        "  return batched_train_ds, batched_val_ds, batched_test_ds\n",
        "\n",
        "batched_train_ds, batched_val_ds, batched_test_ds = batching(tokenized_ds, batch_size)"
      ],
      "metadata": {
        "id": "Ys8SWafJG8Rs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Fine-tuning (Single Loop)"
      ],
      "metadata": {
        "id": "RrKSsoCDKzxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFAutoModelForSequenceClassification, create_optimizer\n",
        "\n",
        "# For Tensorflow 2.6, the weights of the classification head is only affected\n",
        "# by seeds set using tf.random_set_seed.\n",
        "# https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras\n",
        "\n",
        "seed = 67897\n",
        "tf.random.set_seed(seed)\n",
        "num_epochs = 3\n",
        "initial_lr = 2e-5\n",
        "\n",
        "def create_model(num_epochs, initial_lr):\n",
        "\n",
        "  model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "      model_checkpoint,\n",
        "      num_labels = 2\n",
        "  )\n",
        "\n",
        "  batches_per_epoch = len(tokenized_ds['train']) // batch_size\n",
        "  total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "\n",
        "  optimizer, schedule = create_optimizer(\n",
        "      init_lr = initial_lr,\n",
        "      num_warmup_steps = 0,\n",
        "      num_train_steps = total_train_steps,\n",
        "      weight_decay_rate = 0.01\n",
        "  )\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
        "\n",
        "  model.compile(\n",
        "      optimizer = optimizer,\n",
        "      loss = loss,\n",
        "      metrics = tf.metrics.SparseCategoricalAccuracy()\n",
        "  )\n",
        "\n",
        "  return model\n",
        "\n",
        "model = create_model(num_epochs, initial_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "75465b25fed349008c1b242ad77e1f2a",
            "8bff5dde5a57482b830129aad4da8671",
            "4ce81d252d5a48d58cffdb752022fbb8",
            "814af0a2b44247269df5e08f9a8c3a21",
            "fd02a796ce5a40c8bf6fdee45c1c0b14",
            "3c895191066745e6a1f5e084c09d71c3",
            "2d53ab209a6042878d5cd47969484df8",
            "16da5163ebcb4cfdb73f0da3982eed2c",
            "6299d29396aa4bd2907f6670ab271803",
            "148f85999fc94f6b878b658bfcd3a294",
            "3d5ce607782e4aefb7f5032102f9a486"
          ]
        },
        "id": "xki_owc0kv4r",
        "outputId": "32de892c-805c-4840-9a81-5dd94822a1f3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/627M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75465b25fed349008c1b242ad77e1f2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import models\n",
        "\n",
        "for layer in model.layers[:]:\n",
        "    print(layer, layer.trainable)\n",
        "\n",
        "print('=========================================================================')\n",
        "\n",
        "encoder_layer_name = {\n",
        "    'bert-base-cased' : models.bert.modeling_tf_bert.TFBertMainLayer,\n",
        "    'roberta-base' : models.roberta.modeling_tf_roberta.TFRobertaMainLayer,\n",
        "    'scibert_scivocab_cased' : models.bert.modeling_tf_bert.TFBertMainLayer\n",
        "}\n",
        "\n",
        "frozen_layers = []\n",
        "\n",
        "for layer in model.layers[:]:\n",
        "  \n",
        "  # Replace transformers.models.bert.modeling_tf_bert.TFBertMainLayer\n",
        "  # with the corresponding MainLayer name from the previous code output\n",
        "  if isinstance(layer, encoder_layer_name[model_type_dict[model_checkpoint]]):\n",
        "    \n",
        "    for idx, layer in enumerate(layer.encoder.layer):\n",
        "      \n",
        "      if idx in frozen_layers:\n",
        "        layer.trainable = False\n",
        "      \n",
        "      # Confirm the chosen layers are frozen\n",
        "      print(layer, layer.trainable)"
      ],
      "metadata": {
        "id": "dTDuB43XlB2H",
        "outputId": "0e337439-3fb6-430a-ebff-780d30414012",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<transformers.models.roberta.modeling_tf_roberta.TFRobertaMainLayer object at 0x7f260037d190> True\n",
            "<transformers.models.roberta.modeling_tf_roberta.TFRobertaClassificationHead object at 0x7f26000b1d90> True\n",
            "=========================================================================\n",
            "<transformers.models.roberta.modeling_tf_roberta.TFRobertaLayer object at 0x7f26003078d0> True\n",
            "<transformers.models.roberta.modeling_tf_roberta.TFRobertaLayer object at 0x7f26004f2e50> True\n",
            "<transformers.models.roberta.modeling_tf_roberta.TFRobertaLayer object at 0x7f26001bd810> True\n",
            "<transformers.models.roberta.modeling_tf_roberta.TFRobertaLayer object at 0x7f26001d8450> True\n",
            "<transformers.models.roberta.modeling_tf_roberta.TFRobertaLayer object at 0x7f2600171190> True\n",
            "<transformers.models.roberta.modeling_tf_roberta.TFRobertaLayer object at 0x7f2600183fd0> True\n",
            "<transformers.models.roberta.modeling_tf_roberta.TFRobertaLayer object at 0x7f26001a3090> True\n",
            "<transformers.models.roberta.modeling_tf_roberta.TFRobertaLayer object at 0x7f260013a210> True\n",
            "<transformers.models.roberta.modeling_tf_roberta.TFRobertaLayer object at 0x7f260014d390> True\n",
            "<transformers.models.roberta.modeling_tf_roberta.TFRobertaLayer object at 0x7f2600183f10> True\n",
            "<transformers.models.roberta.modeling_tf_roberta.TFRobertaLayer object at 0x7f26000fb750> True\n",
            "<transformers.models.roberta.modeling_tf_roberta.TFRobertaLayer object at 0x7f2600110990> True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFZ7HnUlK9CV",
        "outputId": "db96b1d9-c45e-442f-9a12-900273d6bcb1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_roberta_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " roberta (TFRobertaMainLayer  multiple                 124055040 \n",
            " )                                                               \n",
            "                                                                 \n",
            " classifier (TFRobertaClassi  multiple                 592130    \n",
            " ficationHead)                                                   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124,647,170\n",
            "Trainable params: 124,647,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import Callback, CSVLogger, ModelCheckpoint\n",
        "from transformers.keras_callbacks import PushToHubCallback\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "class macro_F1(Callback):\n",
        "\n",
        "    def __init__(self):    \n",
        "        super(macro_F1, self).__init__()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs = {}):\n",
        "\n",
        "        y_train_true = tokenized_ds['train']['is_functional']\n",
        "        y_train_pred = np.argmax(self.model.predict(batched_train_ds)['logits'], axis = 1)\n",
        "        logs['train_macro_f1'] = f1_score(y_train_true, y_train_pred)\n",
        "\n",
        "        y_val_true = tokenized_ds['val']['is_functional']\n",
        "        y_val_pred = np.argmax(self.model.predict(batched_val_ds)['logits'], axis = 1)\n",
        "        logs['val_macro_f1'] = f1_score(y_val_true, y_val_pred)\n",
        "\n",
        "        logs['seed'] = seed\n",
        "        logs['batch_size'] = batch_size\n",
        "        logs['learning_rate'] = initial_lr\n",
        "\n",
        "macro_F1_cb = macro_F1()\n",
        "\n",
        "csvlogger_file = f'{model_name_dict[model_checkpoint]}-{task_name_dict[ds_name]}.csv'\n",
        "csvlogger_cb = CSVLogger(csvlogger_file, append = True)"
      ],
      "metadata": {
        "id": "DcWoBH2lHG4i"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [macro_F1_cb, csvlogger_cb]"
      ],
      "metadata": {
        "id": "a6x516hsnnJ2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit(\n",
        "#     batched_train_ds,\n",
        "#     validation_data = batched_val_ds,\n",
        "#     epochs = num_epochs,\n",
        "#     callbacks = callbacks\n",
        "# )"
      ],
      "metadata": {
        "id": "qnA0PIzbnuR2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_true = tokenized_ds['test']['is_functional']\n",
        "# y_pred = np.argmax(model.predict(batched_test_ds)['logits'], axis = 1)\n",
        "# micro_f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "# print(f'Test macro F1: {micro_f1:2f}')"
      ],
      "metadata": {
        "id": "D_44WYGKynNL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter tuning"
      ],
      "metadata": {
        "id": "JDsgMI2Z1wYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_sizes = [16, 32]\n",
        "# initial_lrs = [5e-5, 3e-5, 2e-5]\n",
        "# seeds = [21916, 25412, 56281, 61712, 30488,\n",
        "#          28215, 78867, 87843, 67918, 93327,\n",
        "#          95420, 11905, 86349, 12082, 81996]\n",
        "\n",
        "# num_epochs = 5\n",
        "\n",
        "# for initial_lr in initial_lrs:\n",
        "  \n",
        "#   for seed in seeds:\n",
        "  \n",
        "#     tf.random.set_seed(seed)\n",
        "#     model = create_model(num_epochs, initial_lr)\n",
        "\n",
        "#     frozen_layers = []\n",
        "\n",
        "#     for layer in model.layers[:]:\n",
        "      \n",
        "#       # Replace transformers.models.bert.modeling_tf_bert.TFBertMainLayer\n",
        "#       # with the corresponding MainLayer name from the previous code output\n",
        "#       if isinstance(layer, encoder_layer_name[model_type_dict[model_checkpoint]]):\n",
        "        \n",
        "#         for idx, layer in enumerate(layer.encoder.layer):\n",
        "          \n",
        "#           if idx in frozen_layers:\n",
        "#             layer.trainable = False\n",
        "\n",
        "#     csvlogger_file = f'logs/{task_name_dict[ds_name]}-{model_name_dict[model_checkpoint]}-bs{batch_size}-lr{initial_lr}.csv'\n",
        "#     csvlogger_cb = CSVLogger(csvlogger_file, append = True)\n",
        "\n",
        "#     callbacks = [macro_F1_cb, csvlogger_cb]\n",
        "    \n",
        "#     model.fit(\n",
        "#         batched_train_ds,\n",
        "#         validation_data = batched_val_ds,\n",
        "#         epochs = num_epochs,\n",
        "#         callbacks = callbacks\n",
        "#     )"
      ],
      "metadata": {
        "id": "-TvE4lrrzHGe"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sizes = [16, 32]\n",
        "initial_lrs = [5e-5, 3e-5, 2e-5]\n",
        "seeds = [21916, 25412, 56281, 61712, 30488,\n",
        "         28215, 78867, 87843, 67918, 93327,\n",
        "         95420, 11905, 86349, 12082, 81996]\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "\n",
        "  batched_train_ds, batched_val_ds, batched_test_ds = batching(tokenized_ds, batch_size)\n",
        "\n",
        "  for initial_lr in initial_lrs:\n",
        "    \n",
        "    for seed in seeds:\n",
        "    \n",
        "      tf.random.set_seed(seed)\n",
        "      model = create_model(num_epochs, initial_lr)\n",
        "\n",
        "      frozen_layers = []\n",
        "\n",
        "      for layer in model.layers[:]:\n",
        "        \n",
        "        if isinstance(layer, encoder_layer_name[model_type_dict[model_checkpoint]]):\n",
        "          \n",
        "          for idx, layer in enumerate(layer.encoder.layer):\n",
        "            \n",
        "            if idx in frozen_layers:\n",
        "              layer.trainable = False\n",
        "\n",
        "      csvlogger_file = f'frnfr/{task_name_dict[ds_name]}-{model_name_dict[model_checkpoint]}.csv'\n",
        "      csvlogger_cb = CSVLogger(csvlogger_file, append = True)\n",
        "\n",
        "      callbacks = [macro_F1_cb, csvlogger_cb]\n",
        "      \n",
        "      model.fit(\n",
        "          batched_train_ds,\n",
        "          validation_data = batched_val_ds,\n",
        "          epochs = num_epochs,\n",
        "          callbacks = callbacks\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CywJJnlKOuJj",
        "outputId": "e4fa3ed2-4d8d-482e-daae-636ccf84c8c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 33s 342ms/step - loss: 0.5753 - sparse_categorical_accuracy: 0.6936 - val_loss: 0.3448 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9126 - val_macro_f1: 0.8659 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.2841 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.3871 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9392 - val_macro_f1: 0.8696 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1959 - sparse_categorical_accuracy: 0.9238 - val_loss: 0.4010 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9840 - val_macro_f1: 0.8827 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.0949 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.4120 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9938 - val_macro_f1: 0.8817 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.0420 - sparse_categorical_accuracy: 0.9895 - val_loss: 0.3839 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9951 - val_macro_f1: 0.9017 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 334ms/step - loss: 0.6736 - sparse_categorical_accuracy: 0.6039 - val_loss: 0.6666 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.6745 - sparse_categorical_accuracy: 0.6009 - val_loss: 0.6708 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.6699 - sparse_categorical_accuracy: 0.6084 - val_loss: 0.6671 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.6742 - sparse_categorical_accuracy: 0.6084 - val_loss: 0.6667 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.6691 - sparse_categorical_accuracy: 0.6084 - val_loss: 0.6665 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 336ms/step - loss: 0.6882 - sparse_categorical_accuracy: 0.6009 - val_loss: 0.6671 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.6557 - sparse_categorical_accuracy: 0.6084 - val_loss: 0.5853 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.4417 - sparse_categorical_accuracy: 0.8221 - val_loss: 0.5028 - val_sparse_categorical_accuracy: 0.7692 - train_macro_f1: 0.8501 - val_macro_f1: 0.7843 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.3896 - sparse_categorical_accuracy: 0.8505 - val_loss: 0.4064 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9136 - val_macro_f1: 0.8659 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.2232 - sparse_categorical_accuracy: 0.9283 - val_loss: 0.3489 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9475 - val_macro_f1: 0.9029 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 336ms/step - loss: 0.5764 - sparse_categorical_accuracy: 0.6951 - val_loss: 0.7010 - val_sparse_categorical_accuracy: 0.5804 - train_macro_f1: 0.4728 - val_macro_f1: 0.4828 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.3517 - sparse_categorical_accuracy: 0.8580 - val_loss: 0.4019 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9670 - val_macro_f1: 0.8715 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1628 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.4689 - val_sparse_categorical_accuracy: 0.8252 - train_macro_f1: 0.9800 - val_macro_f1: 0.8485 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.0892 - sparse_categorical_accuracy: 0.9671 - val_loss: 0.3846 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9951 - val_macro_f1: 0.8953 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.0418 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.4150 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9951 - val_macro_f1: 0.8851 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 339ms/step - loss: 0.5760 - sparse_categorical_accuracy: 0.7010 - val_loss: 0.3559 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.9253 - val_macro_f1: 0.8750 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.2323 - sparse_categorical_accuracy: 0.9133 - val_loss: 0.4041 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9752 - val_macro_f1: 0.8671 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.1363 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.3571 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9854 - val_macro_f1: 0.8889 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.0803 - sparse_categorical_accuracy: 0.9731 - val_loss: 0.5898 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9888 - val_macro_f1: 0.8690 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.0445 - sparse_categorical_accuracy: 0.9895 - val_loss: 0.4424 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9963 - val_macro_f1: 0.8800 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 345ms/step - loss: 0.5606 - sparse_categorical_accuracy: 0.6891 - val_loss: 0.3858 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.8969 - val_macro_f1: 0.8696 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 213ms/step - loss: 0.2910 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.3921 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9587 - val_macro_f1: 0.8750 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.1956 - sparse_categorical_accuracy: 0.9342 - val_loss: 0.3554 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9802 - val_macro_f1: 0.9011 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.0872 - sparse_categorical_accuracy: 0.9716 - val_loss: 0.4102 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9774 - val_macro_f1: 0.8810 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 214ms/step - loss: 0.0585 - sparse_categorical_accuracy: 0.9791 - val_loss: 0.3872 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9901 - val_macro_f1: 0.8953 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 337ms/step - loss: 0.6312 - sparse_categorical_accuracy: 0.6308 - val_loss: 0.4162 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9229 - val_macro_f1: 0.8901 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.3511 - sparse_categorical_accuracy: 0.8685 - val_loss: 0.4264 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.9655 - val_macro_f1: 0.8636 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.1936 - sparse_categorical_accuracy: 0.9253 - val_loss: 0.4747 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9817 - val_macro_f1: 0.8913 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1323 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.4638 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.9788 - val_macro_f1: 0.8554 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.0633 - sparse_categorical_accuracy: 0.9776 - val_loss: 0.4354 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9926 - val_macro_f1: 0.8927 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 334ms/step - loss: 0.5192 - sparse_categorical_accuracy: 0.7235 - val_loss: 0.5113 - val_sparse_categorical_accuracy: 0.7762 - train_macro_f1: 0.8267 - val_macro_f1: 0.7895 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.3096 - sparse_categorical_accuracy: 0.8789 - val_loss: 0.3936 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9644 - val_macro_f1: 0.8791 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.1512 - sparse_categorical_accuracy: 0.9462 - val_loss: 0.4059 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9851 - val_macro_f1: 0.8750 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.1178 - sparse_categorical_accuracy: 0.9537 - val_loss: 0.3543 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9938 - val_macro_f1: 0.9000 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.0465 - sparse_categorical_accuracy: 0.9895 - val_loss: 0.3861 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9951 - val_macro_f1: 0.8927 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 347ms/step - loss: 0.6172 - sparse_categorical_accuracy: 0.6547 - val_loss: 0.4078 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9250 - val_macro_f1: 0.8851 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.2883 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.2918 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9741 - val_macro_f1: 0.8950 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.1296 - sparse_categorical_accuracy: 0.9492 - val_loss: 0.4821 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.9876 - val_macro_f1: 0.8621 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 214ms/step - loss: 0.0732 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.3950 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9963 - val_macro_f1: 0.8876 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.0249 - sparse_categorical_accuracy: 0.9940 - val_loss: 0.4194 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9963 - val_macro_f1: 0.8927 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 31s 348ms/step - loss: 0.6146 - sparse_categorical_accuracy: 0.6308 - val_loss: 0.4505 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9253 - val_macro_f1: 0.8840 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.4271 - sparse_categorical_accuracy: 0.8221 - val_loss: 0.5003 - val_sparse_categorical_accuracy: 0.7902 - train_macro_f1: 0.8919 - val_macro_f1: 0.8052 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 213ms/step - loss: 0.2861 - sparse_categorical_accuracy: 0.8894 - val_loss: 0.3741 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9646 - val_macro_f1: 0.8743 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.1659 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.3887 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9816 - val_macro_f1: 0.8840 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 214ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9761 - val_loss: 0.3523 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9863 - val_macro_f1: 0.8786 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 31s 342ms/step - loss: 0.5919 - sparse_categorical_accuracy: 0.6801 - val_loss: 0.5647 - val_sparse_categorical_accuracy: 0.7902 - train_macro_f1: 0.8373 - val_macro_f1: 0.8052 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.2832 - sparse_categorical_accuracy: 0.8969 - val_loss: 0.3996 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9669 - val_macro_f1: 0.8913 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 213ms/step - loss: 0.1444 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.3342 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9877 - val_macro_f1: 0.8876 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.0821 - sparse_categorical_accuracy: 0.9761 - val_loss: 0.3193 - val_sparse_categorical_accuracy: 0.8881 - train_macro_f1: 0.9963 - val_macro_f1: 0.9111 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.0352 - sparse_categorical_accuracy: 0.9880 - val_loss: 0.3732 - val_sparse_categorical_accuracy: 0.8951 - train_macro_f1: 0.9975 - val_macro_f1: 0.9180 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 339ms/step - loss: 0.5677 - sparse_categorical_accuracy: 0.6876 - val_loss: 0.4228 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9250 - val_macro_f1: 0.8655 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 213ms/step - loss: 0.2598 - sparse_categorical_accuracy: 0.8969 - val_loss: 0.6583 - val_sparse_categorical_accuracy: 0.8042 - train_macro_f1: 0.9584 - val_macro_f1: 0.8333 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 214ms/step - loss: 0.1495 - sparse_categorical_accuracy: 0.9507 - val_loss: 0.5127 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9855 - val_macro_f1: 0.8852 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.0912 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.4856 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9901 - val_macro_f1: 0.8736 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.0307 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.5216 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9975 - val_macro_f1: 0.8889 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 31s 347ms/step - loss: 0.5624 - sparse_categorical_accuracy: 0.6966 - val_loss: 0.5606 - val_sparse_categorical_accuracy: 0.7692 - train_macro_f1: 0.8070 - val_macro_f1: 0.7724 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.2789 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.3481 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9700 - val_macro_f1: 0.8864 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.2121 - sparse_categorical_accuracy: 0.9088 - val_loss: 0.2914 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9804 - val_macro_f1: 0.8950 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.0940 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.3579 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9926 - val_macro_f1: 0.9032 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.0439 - sparse_categorical_accuracy: 0.9865 - val_loss: 0.2897 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9951 - val_macro_f1: 0.9006 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 31s 347ms/step - loss: 0.5582 - sparse_categorical_accuracy: 0.6876 - val_loss: 0.3507 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.9187 - val_macro_f1: 0.8571 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 213ms/step - loss: 0.2686 - sparse_categorical_accuracy: 0.9043 - val_loss: 0.4176 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9654 - val_macro_f1: 0.8977 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 213ms/step - loss: 0.1811 - sparse_categorical_accuracy: 0.9342 - val_loss: 0.3299 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9877 - val_macro_f1: 0.8852 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.0642 - sparse_categorical_accuracy: 0.9821 - val_loss: 0.4458 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9926 - val_macro_f1: 0.8953 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 213ms/step - loss: 0.0415 - sparse_categorical_accuracy: 0.9895 - val_loss: 0.4356 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9926 - val_macro_f1: 0.8914 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 31s 345ms/step - loss: 0.5753 - sparse_categorical_accuracy: 0.6981 - val_loss: 0.4830 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.9126 - val_macro_f1: 0.8500 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 217ms/step - loss: 0.2643 - sparse_categorical_accuracy: 0.8984 - val_loss: 0.4590 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9598 - val_macro_f1: 0.8606 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.1166 - sparse_categorical_accuracy: 0.9492 - val_loss: 0.4542 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9878 - val_macro_f1: 0.9032 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 214ms/step - loss: 0.0602 - sparse_categorical_accuracy: 0.9761 - val_loss: 0.4321 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9938 - val_macro_f1: 0.8914 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 213ms/step - loss: 0.0289 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.4446 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9988 - val_macro_f1: 0.8989 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 31s 345ms/step - loss: 0.5464 - sparse_categorical_accuracy: 0.7175 - val_loss: 0.3598 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9299 - val_macro_f1: 0.8814 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.2511 - sparse_categorical_accuracy: 0.9148 - val_loss: 0.3474 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9413 - val_macro_f1: 0.8834 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.1789 - sparse_categorical_accuracy: 0.9387 - val_loss: 0.3939 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9841 - val_macro_f1: 0.8876 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.0991 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.3890 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9889 - val_macro_f1: 0.8902 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.0627 - sparse_categorical_accuracy: 0.9821 - val_loss: 0.4025 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9901 - val_macro_f1: 0.8902 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 345ms/step - loss: 0.5959 - sparse_categorical_accuracy: 0.6652 - val_loss: 0.3830 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9141 - val_macro_f1: 0.8736 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.2928 - sparse_categorical_accuracy: 0.8924 - val_loss: 0.3938 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9588 - val_macro_f1: 0.8772 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.2036 - sparse_categorical_accuracy: 0.9208 - val_loss: 0.3547 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9778 - val_macro_f1: 0.8791 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.0951 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.3973 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9939 - val_macro_f1: 0.8804 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.0422 - sparse_categorical_accuracy: 0.9895 - val_loss: 0.3909 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9963 - val_macro_f1: 0.8939 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 31s 347ms/step - loss: 0.6140 - sparse_categorical_accuracy: 0.6532 - val_loss: 0.5250 - val_sparse_categorical_accuracy: 0.7832 - train_macro_f1: 0.7829 - val_macro_f1: 0.7891 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 214ms/step - loss: 0.3117 - sparse_categorical_accuracy: 0.8789 - val_loss: 0.3817 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.9523 - val_macro_f1: 0.8537 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.1609 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.4154 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9805 - val_macro_f1: 0.8962 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.0825 - sparse_categorical_accuracy: 0.9746 - val_loss: 0.4267 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9926 - val_macro_f1: 0.8953 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.0516 - sparse_categorical_accuracy: 0.9865 - val_loss: 0.4210 - val_sparse_categorical_accuracy: 0.8951 - train_macro_f1: 0.9938 - val_macro_f1: 0.9153 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 31s 343ms/step - loss: 0.5447 - sparse_categorical_accuracy: 0.6996 - val_loss: 0.3744 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9239 - val_macro_f1: 0.8743 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.2459 - sparse_categorical_accuracy: 0.9133 - val_loss: 0.5671 - val_sparse_categorical_accuracy: 0.8112 - train_macro_f1: 0.9127 - val_macro_f1: 0.8235 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.2238 - sparse_categorical_accuracy: 0.9088 - val_loss: 0.3833 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9724 - val_macro_f1: 0.8830 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.0964 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.3481 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9914 - val_macro_f1: 0.9022 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 214ms/step - loss: 0.0519 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.3556 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9951 - val_macro_f1: 0.8902 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 336ms/step - loss: 0.5960 - sparse_categorical_accuracy: 0.6891 - val_loss: 0.4866 - val_sparse_categorical_accuracy: 0.7692 - train_macro_f1: 0.7523 - val_macro_f1: 0.7724 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.2891 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.3981 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9570 - val_macro_f1: 0.8606 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.1704 - sparse_categorical_accuracy: 0.9357 - val_loss: 0.3651 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9830 - val_macro_f1: 0.9043 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.0682 - sparse_categorical_accuracy: 0.9791 - val_loss: 0.4012 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9963 - val_macro_f1: 0.8939 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.0320 - sparse_categorical_accuracy: 0.9895 - val_loss: 0.4103 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9963 - val_macro_f1: 0.8977 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 31s 346ms/step - loss: 0.5797 - sparse_categorical_accuracy: 0.6756 - val_loss: 0.4627 - val_sparse_categorical_accuracy: 0.7902 - train_macro_f1: 0.8307 - val_macro_f1: 0.8052 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.2840 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.4372 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.9227 - val_macro_f1: 0.8500 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.2414 - sparse_categorical_accuracy: 0.9088 - val_loss: 0.3402 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9792 - val_macro_f1: 0.8840 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.1057 - sparse_categorical_accuracy: 0.9626 - val_loss: 0.3856 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9927 - val_macro_f1: 0.8729 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.0556 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.4044 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9926 - val_macro_f1: 0.8800 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 339ms/step - loss: 0.5715 - sparse_categorical_accuracy: 0.6906 - val_loss: 0.4251 - val_sparse_categorical_accuracy: 0.8112 - train_macro_f1: 0.8733 - val_macro_f1: 0.8280 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.2650 - sparse_categorical_accuracy: 0.8984 - val_loss: 0.3801 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9689 - val_macro_f1: 0.8824 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.1453 - sparse_categorical_accuracy: 0.9492 - val_loss: 0.4031 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9794 - val_macro_f1: 0.8947 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.0982 - sparse_categorical_accuracy: 0.9567 - val_loss: 0.3612 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9902 - val_macro_f1: 0.9050 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.0555 - sparse_categorical_accuracy: 0.9865 - val_loss: 0.4395 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9938 - val_macro_f1: 0.8743 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 31s 343ms/step - loss: 0.5823 - sparse_categorical_accuracy: 0.6637 - val_loss: 0.4018 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.8980 - val_macro_f1: 0.8642 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.2595 - sparse_categorical_accuracy: 0.9088 - val_loss: 0.4003 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9422 - val_macro_f1: 0.8675 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.1841 - sparse_categorical_accuracy: 0.9312 - val_loss: 0.3742 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9866 - val_macro_f1: 0.8950 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.0856 - sparse_categorical_accuracy: 0.9746 - val_loss: 0.3855 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9939 - val_macro_f1: 0.8913 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.0479 - sparse_categorical_accuracy: 0.9865 - val_loss: 0.3878 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9963 - val_macro_f1: 0.8977 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 344ms/step - loss: 0.5828 - sparse_categorical_accuracy: 0.6667 - val_loss: 0.3814 - val_sparse_categorical_accuracy: 0.8112 - train_macro_f1: 0.8868 - val_macro_f1: 0.8323 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 214ms/step - loss: 0.2705 - sparse_categorical_accuracy: 0.9073 - val_loss: 0.3742 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9622 - val_macro_f1: 0.8743 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.1581 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.3610 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9852 - val_macro_f1: 0.8939 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.0923 - sparse_categorical_accuracy: 0.9716 - val_loss: 0.3294 - val_sparse_categorical_accuracy: 0.8951 - train_macro_f1: 0.9864 - val_macro_f1: 0.9143 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.0547 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.3484 - val_sparse_categorical_accuracy: 0.8951 - train_macro_f1: 0.9901 - val_macro_f1: 0.9153 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 342ms/step - loss: 0.5847 - sparse_categorical_accuracy: 0.6622 - val_loss: 0.3701 - val_sparse_categorical_accuracy: 0.8252 - train_macro_f1: 0.9258 - val_macro_f1: 0.8503 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.2439 - sparse_categorical_accuracy: 0.9118 - val_loss: 0.4127 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9476 - val_macro_f1: 0.8606 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1795 - sparse_categorical_accuracy: 0.9387 - val_loss: 0.3913 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9804 - val_macro_f1: 0.8950 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.1020 - sparse_categorical_accuracy: 0.9611 - val_loss: 0.3674 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9926 - val_macro_f1: 0.9071 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.0459 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.3773 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9951 - val_macro_f1: 0.8977 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 337ms/step - loss: 0.5638 - sparse_categorical_accuracy: 0.6876 - val_loss: 0.3743 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9227 - val_macro_f1: 0.8639 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.2562 - sparse_categorical_accuracy: 0.9163 - val_loss: 0.3929 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9663 - val_macro_f1: 0.8675 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.1588 - sparse_categorical_accuracy: 0.9462 - val_loss: 0.4166 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9770 - val_macro_f1: 0.8958 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.1003 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.4355 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9914 - val_macro_f1: 0.8736 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.0513 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.4254 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9926 - val_macro_f1: 0.8814 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 333ms/step - loss: 0.5830 - sparse_categorical_accuracy: 0.6667 - val_loss: 0.3751 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9296 - val_macro_f1: 0.8913 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.2746 - sparse_categorical_accuracy: 0.8954 - val_loss: 0.4549 - val_sparse_categorical_accuracy: 0.7902 - train_macro_f1: 0.9020 - val_macro_f1: 0.8052 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.2108 - sparse_categorical_accuracy: 0.9208 - val_loss: 0.3930 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9794 - val_macro_f1: 0.8936 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.0944 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.3787 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9902 - val_macro_f1: 0.9022 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.0601 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.4150 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9901 - val_macro_f1: 0.8757 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 339ms/step - loss: 0.5778 - sparse_categorical_accuracy: 0.6846 - val_loss: 0.3466 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9181 - val_macro_f1: 0.9000 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.2789 - sparse_categorical_accuracy: 0.8939 - val_loss: 0.3717 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9436 - val_macro_f1: 0.8589 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.2238 - sparse_categorical_accuracy: 0.9163 - val_loss: 0.2901 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9740 - val_macro_f1: 0.8966 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.1065 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.3319 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9878 - val_macro_f1: 0.9071 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 213ms/step - loss: 0.0606 - sparse_categorical_accuracy: 0.9776 - val_loss: 0.3021 - val_sparse_categorical_accuracy: 0.8881 - train_macro_f1: 0.9914 - val_macro_f1: 0.9080 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 344ms/step - loss: 0.5896 - sparse_categorical_accuracy: 0.6652 - val_loss: 0.3927 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9151 - val_macro_f1: 0.8727 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.2763 - sparse_categorical_accuracy: 0.8939 - val_loss: 0.4642 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9569 - val_macro_f1: 0.8606 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1693 - sparse_categorical_accuracy: 0.9372 - val_loss: 0.3193 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9852 - val_macro_f1: 0.9040 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.0903 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.3260 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9926 - val_macro_f1: 0.8889 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.0433 - sparse_categorical_accuracy: 0.9865 - val_loss: 0.3502 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9913 - val_macro_f1: 0.8889 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 336ms/step - loss: 0.5492 - sparse_categorical_accuracy: 0.7010 - val_loss: 0.6359 - val_sparse_categorical_accuracy: 0.7552 - train_macro_f1: 0.8174 - val_macro_f1: 0.7552 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.2739 - sparse_categorical_accuracy: 0.9013 - val_loss: 0.4064 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9665 - val_macro_f1: 0.8743 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1715 - sparse_categorical_accuracy: 0.9387 - val_loss: 0.3797 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9842 - val_macro_f1: 0.8877 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 208ms/step - loss: 0.1091 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.3740 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9926 - val_macro_f1: 0.9011 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.0495 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.3953 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9926 - val_macro_f1: 0.9029 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 29s 332ms/step - loss: 0.5871 - sparse_categorical_accuracy: 0.6756 - val_loss: 0.3478 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9035 - val_macro_f1: 0.8795 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 208ms/step - loss: 0.2654 - sparse_categorical_accuracy: 0.8954 - val_loss: 0.3458 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9598 - val_macro_f1: 0.8655 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1387 - sparse_categorical_accuracy: 0.9507 - val_loss: 0.3991 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9864 - val_macro_f1: 0.9061 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1165 - sparse_categorical_accuracy: 0.9611 - val_loss: 0.4079 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9825 - val_macro_f1: 0.8862 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 208ms/step - loss: 0.0691 - sparse_categorical_accuracy: 0.9776 - val_loss: 0.3585 - val_sparse_categorical_accuracy: 0.8881 - train_macro_f1: 0.9901 - val_macro_f1: 0.9091 - seed: 21916.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 29s 331ms/step - loss: 0.6268 - sparse_categorical_accuracy: 0.6278 - val_loss: 0.4004 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.8717 - val_macro_f1: 0.8727 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.2997 - sparse_categorical_accuracy: 0.8819 - val_loss: 0.3606 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9371 - val_macro_f1: 0.8743 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1965 - sparse_categorical_accuracy: 0.9193 - val_loss: 0.3646 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9794 - val_macro_f1: 0.8770 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1053 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.4073 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9863 - val_macro_f1: 0.8772 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.0543 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.3943 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9963 - val_macro_f1: 0.8721 - seed: 25412.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 29s 334ms/step - loss: 0.6642 - sparse_categorical_accuracy: 0.5994 - val_loss: 0.5240 - val_sparse_categorical_accuracy: 0.7063 - train_macro_f1: 0.8052 - val_macro_f1: 0.8037 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.3698 - sparse_categorical_accuracy: 0.8490 - val_loss: 0.3795 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9184 - val_macro_f1: 0.8679 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 212ms/step - loss: 0.1955 - sparse_categorical_accuracy: 0.9223 - val_loss: 0.3312 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9827 - val_macro_f1: 0.9050 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.1160 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.3363 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9888 - val_macro_f1: 0.9017 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.0717 - sparse_categorical_accuracy: 0.9880 - val_loss: 0.3518 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9901 - val_macro_f1: 0.9029 - seed: 56281.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 29s 332ms/step - loss: 0.5959 - sparse_categorical_accuracy: 0.6577 - val_loss: 0.3966 - val_sparse_categorical_accuracy: 0.8182 - train_macro_f1: 0.8753 - val_macro_f1: 0.8375 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.2905 - sparse_categorical_accuracy: 0.8894 - val_loss: 0.3780 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9525 - val_macro_f1: 0.8810 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1650 - sparse_categorical_accuracy: 0.9492 - val_loss: 0.3735 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9778 - val_macro_f1: 0.8927 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1191 - sparse_categorical_accuracy: 0.9581 - val_loss: 0.3628 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9901 - val_macro_f1: 0.8939 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.0650 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.3802 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9901 - val_macro_f1: 0.8966 - seed: 61712.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 339ms/step - loss: 0.6043 - sparse_categorical_accuracy: 0.6726 - val_loss: 0.5439 - val_sparse_categorical_accuracy: 0.7622 - train_macro_f1: 0.7595 - val_macro_f1: 0.7639 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 208ms/step - loss: 0.3226 - sparse_categorical_accuracy: 0.8700 - val_loss: 0.3285 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9542 - val_macro_f1: 0.8927 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1907 - sparse_categorical_accuracy: 0.9283 - val_loss: 0.3020 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9814 - val_macro_f1: 0.8927 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.1171 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.3386 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9853 - val_macro_f1: 0.9000 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.0708 - sparse_categorical_accuracy: 0.9776 - val_loss: 0.3477 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9926 - val_macro_f1: 0.9000 - seed: 30488.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 29s 334ms/step - loss: 0.6125 - sparse_categorical_accuracy: 0.6233 - val_loss: 0.4941 - val_sparse_categorical_accuracy: 0.7832 - train_macro_f1: 0.8000 - val_macro_f1: 0.7919 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.3554 - sparse_categorical_accuracy: 0.8670 - val_loss: 0.3297 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9521 - val_macro_f1: 0.8876 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1864 - sparse_categorical_accuracy: 0.9297 - val_loss: 0.3430 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9815 - val_macro_f1: 0.8778 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1291 - sparse_categorical_accuracy: 0.9522 - val_loss: 0.3538 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9851 - val_macro_f1: 0.8864 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9731 - val_loss: 0.3754 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9901 - val_macro_f1: 0.8814 - seed: 28215.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 29s 330ms/step - loss: 0.6099 - sparse_categorical_accuracy: 0.6293 - val_loss: 0.4332 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.8938 - val_macro_f1: 0.8571 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.3129 - sparse_categorical_accuracy: 0.8924 - val_loss: 0.3776 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9395 - val_macro_f1: 0.8712 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.2121 - sparse_categorical_accuracy: 0.9283 - val_loss: 0.3083 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9766 - val_macro_f1: 0.9050 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1339 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.3349 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9827 - val_macro_f1: 0.8939 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 208ms/step - loss: 0.0773 - sparse_categorical_accuracy: 0.9716 - val_loss: 0.3638 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9813 - val_macro_f1: 0.8862 - seed: 78867.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 29s 332ms/step - loss: 0.6029 - sparse_categorical_accuracy: 0.6129 - val_loss: 0.4255 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.8871 - val_macro_f1: 0.8675 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.2805 - sparse_categorical_accuracy: 0.9043 - val_loss: 0.3733 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9508 - val_macro_f1: 0.8757 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.2164 - sparse_categorical_accuracy: 0.9283 - val_loss: 0.3315 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9752 - val_macro_f1: 0.8927 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1202 - sparse_categorical_accuracy: 0.9581 - val_loss: 0.3719 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9902 - val_macro_f1: 0.8865 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.0767 - sparse_categorical_accuracy: 0.9731 - val_loss: 0.3599 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9901 - val_macro_f1: 0.8953 - seed: 87843.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 29s 333ms/step - loss: 0.6030 - sparse_categorical_accuracy: 0.6428 - val_loss: 0.3707 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.8973 - val_macro_f1: 0.8623 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.3195 - sparse_categorical_accuracy: 0.8729 - val_loss: 0.3491 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9567 - val_macro_f1: 0.9043 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.1758 - sparse_categorical_accuracy: 0.9357 - val_loss: 0.3297 - val_sparse_categorical_accuracy: 0.8881 - train_macro_f1: 0.9788 - val_macro_f1: 0.9059 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.1271 - sparse_categorical_accuracy: 0.9537 - val_loss: 0.3395 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9876 - val_macro_f1: 0.8966 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.0790 - sparse_categorical_accuracy: 0.9716 - val_loss: 0.3470 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9926 - val_macro_f1: 0.8977 - seed: 67918.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 29s 333ms/step - loss: 0.5916 - sparse_categorical_accuracy: 0.6293 - val_loss: 0.4081 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.9206 - val_macro_f1: 0.8554 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.2732 - sparse_categorical_accuracy: 0.9058 - val_loss: 0.3991 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9677 - val_macro_f1: 0.8786 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1667 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.3987 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9791 - val_macro_f1: 0.9011 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.0952 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.4062 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9888 - val_macro_f1: 0.8914 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.0573 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.4171 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9913 - val_macro_f1: 0.8721 - seed: 93327.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 29s 337ms/step - loss: 0.5989 - sparse_categorical_accuracy: 0.6607 - val_loss: 0.3775 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9023 - val_macro_f1: 0.8675 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.2914 - sparse_categorical_accuracy: 0.8984 - val_loss: 0.3612 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9574 - val_macro_f1: 0.8606 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1858 - sparse_categorical_accuracy: 0.9357 - val_loss: 0.3874 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9738 - val_macro_f1: 0.8786 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1196 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.3877 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9889 - val_macro_f1: 0.8973 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.0726 - sparse_categorical_accuracy: 0.9791 - val_loss: 0.3726 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9876 - val_macro_f1: 0.8786 - seed: 95420.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 335ms/step - loss: 0.6138 - sparse_categorical_accuracy: 0.6233 - val_loss: 0.4402 - val_sparse_categorical_accuracy: 0.8252 - train_macro_f1: 0.9209 - val_macro_f1: 0.8731 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.3214 - sparse_categorical_accuracy: 0.9073 - val_loss: 0.3658 - val_sparse_categorical_accuracy: 0.8112 - train_macro_f1: 0.9211 - val_macro_f1: 0.8280 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 214ms/step - loss: 0.2269 - sparse_categorical_accuracy: 0.9088 - val_loss: 0.3296 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9738 - val_macro_f1: 0.8800 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.1229 - sparse_categorical_accuracy: 0.9581 - val_loss: 0.3991 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9815 - val_macro_f1: 0.8877 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.0828 - sparse_categorical_accuracy: 0.9731 - val_loss: 0.3764 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9812 - val_macro_f1: 0.8941 - seed: 11905.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 337ms/step - loss: 0.6011 - sparse_categorical_accuracy: 0.6457 - val_loss: 0.5169 - val_sparse_categorical_accuracy: 0.7622 - train_macro_f1: 0.7396 - val_macro_f1: 0.7606 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.3368 - sparse_categorical_accuracy: 0.8565 - val_loss: 0.3545 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9505 - val_macro_f1: 0.8800 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.2013 - sparse_categorical_accuracy: 0.9208 - val_loss: 0.3253 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9737 - val_macro_f1: 0.8772 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1029 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.3292 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9840 - val_macro_f1: 0.8977 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.0815 - sparse_categorical_accuracy: 0.9716 - val_loss: 0.3463 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9876 - val_macro_f1: 0.8837 - seed: 86349.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 30s 337ms/step - loss: 0.6224 - sparse_categorical_accuracy: 0.6203 - val_loss: 0.4412 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9066 - val_macro_f1: 0.8821 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.3042 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.3433 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9587 - val_macro_f1: 0.8837 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 209ms/step - loss: 0.1529 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.3710 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9852 - val_macro_f1: 0.8876 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.0897 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.4060 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9876 - val_macro_f1: 0.8824 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 208ms/step - loss: 0.0692 - sparse_categorical_accuracy: 0.9791 - val_loss: 0.4150 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9901 - val_macro_f1: 0.8889 - seed: 12082.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42/42 [==============================] - 29s 336ms/step - loss: 0.5939 - sparse_categorical_accuracy: 0.6607 - val_loss: 0.4446 - val_sparse_categorical_accuracy: 0.8112 - train_macro_f1: 0.8480 - val_macro_f1: 0.8212 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 9s 211ms/step - loss: 0.3141 - sparse_categorical_accuracy: 0.8744 - val_loss: 0.3933 - val_sparse_categorical_accuracy: 0.8252 - train_macro_f1: 0.9607 - val_macro_f1: 0.8555 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.1823 - sparse_categorical_accuracy: 0.9312 - val_loss: 0.3717 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9777 - val_macro_f1: 0.8671 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.0782 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.4249 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9889 - val_macro_f1: 0.8814 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 9s 210ms/step - loss: 0.0701 - sparse_categorical_accuracy: 0.9776 - val_loss: 0.4278 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9913 - val_macro_f1: 0.8837 - seed: 81996.0000 - batch_size: 16.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 632ms/step - loss: 0.5708 - sparse_categorical_accuracy: 0.6876 - val_loss: 0.4114 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.8979 - val_macro_f1: 0.8519 - seed: 21916.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.3314 - sparse_categorical_accuracy: 0.8714 - val_loss: 0.4022 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9183 - val_macro_f1: 0.8606 - seed: 21916.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.2113 - sparse_categorical_accuracy: 0.9327 - val_loss: 0.3502 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9730 - val_macro_f1: 0.9000 - seed: 21916.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1139 - sparse_categorical_accuracy: 0.9611 - val_loss: 0.5000 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9830 - val_macro_f1: 0.8947 - seed: 21916.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.0934 - sparse_categorical_accuracy: 0.9626 - val_loss: 0.3904 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9762 - val_macro_f1: 0.8810 - seed: 21916.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 641ms/step - loss: 0.6065 - sparse_categorical_accuracy: 0.6009 - val_loss: 0.4947 - val_sparse_categorical_accuracy: 0.8252 - train_macro_f1: 0.8689 - val_macro_f1: 0.8366 - seed: 25412.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.3199 - sparse_categorical_accuracy: 0.9043 - val_loss: 0.4593 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.9608 - val_macro_f1: 0.8710 - seed: 25412.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.1880 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.4014 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9698 - val_macro_f1: 0.8772 - seed: 25412.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1129 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.4321 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9876 - val_macro_f1: 0.8950 - seed: 25412.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 377ms/step - loss: 0.0654 - sparse_categorical_accuracy: 0.9746 - val_loss: 0.4527 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9813 - val_macro_f1: 0.8772 - seed: 25412.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 28s 630ms/step - loss: 0.6062 - sparse_categorical_accuracy: 0.6517 - val_loss: 0.4169 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.8785 - val_macro_f1: 0.8500 - seed: 56281.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.3042 - sparse_categorical_accuracy: 0.8849 - val_loss: 0.3253 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9593 - val_macro_f1: 0.8977 - seed: 56281.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1591 - sparse_categorical_accuracy: 0.9372 - val_loss: 0.3873 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9749 - val_macro_f1: 0.8953 - seed: 56281.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.0832 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.5536 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9854 - val_macro_f1: 0.8877 - seed: 56281.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 377ms/step - loss: 0.0709 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.4550 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9876 - val_macro_f1: 0.8862 - seed: 56281.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 632ms/step - loss: 0.6392 - sparse_categorical_accuracy: 0.6158 - val_loss: 0.4954 - val_sparse_categorical_accuracy: 0.7203 - train_macro_f1: 0.8032 - val_macro_f1: 0.8148 - seed: 61712.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.4597 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.3665 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9231 - val_macro_f1: 0.8865 - seed: 61712.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.2765 - sparse_categorical_accuracy: 0.9013 - val_loss: 0.3473 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9533 - val_macro_f1: 0.8727 - seed: 61712.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.1522 - sparse_categorical_accuracy: 0.9492 - val_loss: 0.3553 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9802 - val_macro_f1: 0.8950 - seed: 61712.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.1327 - sparse_categorical_accuracy: 0.9522 - val_loss: 0.4133 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9722 - val_macro_f1: 0.8712 - seed: 61712.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 637ms/step - loss: 0.5764 - sparse_categorical_accuracy: 0.6801 - val_loss: 0.4191 - val_sparse_categorical_accuracy: 0.8112 - train_macro_f1: 0.9079 - val_macro_f1: 0.8323 - seed: 30488.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.2933 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.3814 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9602 - val_macro_f1: 0.8936 - seed: 30488.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1555 - sparse_categorical_accuracy: 0.9372 - val_loss: 0.3617 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9761 - val_macro_f1: 0.8795 - seed: 30488.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.0978 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.3917 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9914 - val_macro_f1: 0.9032 - seed: 30488.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.0487 - sparse_categorical_accuracy: 0.9821 - val_loss: 0.3679 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9938 - val_macro_f1: 0.8889 - seed: 30488.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 28s 631ms/step - loss: 0.6129 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.5494 - val_sparse_categorical_accuracy: 0.7343 - train_macro_f1: 0.7620 - val_macro_f1: 0.7286 - seed: 28215.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.3050 - sparse_categorical_accuracy: 0.8849 - val_loss: 0.3407 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9526 - val_macro_f1: 0.8973 - seed: 28215.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.1521 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.3344 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9890 - val_macro_f1: 0.8927 - seed: 28215.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.0828 - sparse_categorical_accuracy: 0.9761 - val_loss: 0.4107 - val_sparse_categorical_accuracy: 0.8881 - train_macro_f1: 0.9902 - val_macro_f1: 0.9149 - seed: 28215.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.0574 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.3775 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9888 - val_macro_f1: 0.8953 - seed: 28215.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 640ms/step - loss: 0.5522 - sparse_categorical_accuracy: 0.6936 - val_loss: 0.3351 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.8991 - val_macro_f1: 0.8780 - seed: 78867.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.3277 - sparse_categorical_accuracy: 0.8834 - val_loss: 0.3122 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9633 - val_macro_f1: 0.9000 - seed: 78867.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.1890 - sparse_categorical_accuracy: 0.9357 - val_loss: 0.3646 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9751 - val_macro_f1: 0.8889 - seed: 78867.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.0931 - sparse_categorical_accuracy: 0.9716 - val_loss: 0.4481 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9841 - val_macro_f1: 0.8973 - seed: 78867.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.0938 - sparse_categorical_accuracy: 0.9626 - val_loss: 0.4188 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9774 - val_macro_f1: 0.8712 - seed: 78867.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 28s 635ms/step - loss: 0.6193 - sparse_categorical_accuracy: 0.6084 - val_loss: 0.4216 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.9119 - val_macro_f1: 0.8763 - seed: 87843.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.3099 - sparse_categorical_accuracy: 0.9028 - val_loss: 0.3380 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9701 - val_macro_f1: 0.8814 - seed: 87843.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.1523 - sparse_categorical_accuracy: 0.9492 - val_loss: 0.3257 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9813 - val_macro_f1: 0.8994 - seed: 87843.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.0707 - sparse_categorical_accuracy: 0.9821 - val_loss: 0.5097 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9926 - val_macro_f1: 0.9053 - seed: 87843.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.0536 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.3767 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9926 - val_macro_f1: 0.8889 - seed: 87843.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 28s 632ms/step - loss: 0.5777 - sparse_categorical_accuracy: 0.6846 - val_loss: 0.3715 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.8945 - val_macro_f1: 0.8537 - seed: 67918.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.3589 - sparse_categorical_accuracy: 0.8625 - val_loss: 0.3321 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9296 - val_macro_f1: 0.8795 - seed: 67918.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.1991 - sparse_categorical_accuracy: 0.9253 - val_loss: 0.3236 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9728 - val_macro_f1: 0.8989 - seed: 67918.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.1199 - sparse_categorical_accuracy: 0.9567 - val_loss: 0.4696 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9758 - val_macro_f1: 0.8866 - seed: 67918.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.0925 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.3241 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9826 - val_macro_f1: 0.8772 - seed: 67918.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 631ms/step - loss: 0.5801 - sparse_categorical_accuracy: 0.6562 - val_loss: 0.4373 - val_sparse_categorical_accuracy: 0.7972 - train_macro_f1: 0.8481 - val_macro_f1: 0.8105 - seed: 93327.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.3233 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.3038 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9497 - val_macro_f1: 0.8810 - seed: 93327.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1623 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.3176 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9853 - val_macro_f1: 0.8827 - seed: 93327.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 377ms/step - loss: 0.0836 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.4695 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9806 - val_macro_f1: 0.9005 - seed: 93327.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.1003 - sparse_categorical_accuracy: 0.9626 - val_loss: 0.3682 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9723 - val_macro_f1: 0.8765 - seed: 93327.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 639ms/step - loss: 0.6249 - sparse_categorical_accuracy: 0.6368 - val_loss: 0.4832 - val_sparse_categorical_accuracy: 0.7622 - train_macro_f1: 0.8175 - val_macro_f1: 0.7733 - seed: 95420.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.3341 - sparse_categorical_accuracy: 0.8610 - val_loss: 0.3756 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9382 - val_macro_f1: 0.8837 - seed: 95420.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1886 - sparse_categorical_accuracy: 0.9357 - val_loss: 0.3507 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9584 - val_macro_f1: 0.8876 - seed: 95420.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1123 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.4393 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9794 - val_macro_f1: 0.8901 - seed: 95420.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.1069 - sparse_categorical_accuracy: 0.9567 - val_loss: 0.3935 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9735 - val_macro_f1: 0.8795 - seed: 95420.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 630ms/step - loss: 0.5495 - sparse_categorical_accuracy: 0.6936 - val_loss: 0.3733 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9086 - val_macro_f1: 0.8606 - seed: 11905.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.2990 - sparse_categorical_accuracy: 0.8759 - val_loss: 0.3389 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9649 - val_macro_f1: 0.8865 - seed: 11905.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1816 - sparse_categorical_accuracy: 0.9402 - val_loss: 0.4164 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.9361 - val_macro_f1: 0.8481 - seed: 11905.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.1070 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.4301 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9805 - val_macro_f1: 0.8995 - seed: 11905.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.0756 - sparse_categorical_accuracy: 0.9671 - val_loss: 0.3656 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9876 - val_macro_f1: 0.8851 - seed: 11905.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 636ms/step - loss: 0.5897 - sparse_categorical_accuracy: 0.6592 - val_loss: 0.3557 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9132 - val_macro_f1: 0.8889 - seed: 86349.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.2763 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.3374 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9663 - val_macro_f1: 0.9029 - seed: 86349.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1552 - sparse_categorical_accuracy: 0.9522 - val_loss: 0.3459 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9829 - val_macro_f1: 0.9061 - seed: 86349.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1350 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.3763 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9903 - val_macro_f1: 0.8936 - seed: 86349.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.0681 - sparse_categorical_accuracy: 0.9791 - val_loss: 0.3356 - val_sparse_categorical_accuracy: 0.8881 - train_macro_f1: 0.9914 - val_macro_f1: 0.9080 - seed: 86349.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 640ms/step - loss: 0.5781 - sparse_categorical_accuracy: 0.6816 - val_loss: 0.3672 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9074 - val_macro_f1: 0.8727 - seed: 12082.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.3375 - sparse_categorical_accuracy: 0.8729 - val_loss: 0.3562 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.9509 - val_macro_f1: 0.8571 - seed: 12082.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1905 - sparse_categorical_accuracy: 0.9372 - val_loss: 0.3799 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9766 - val_macro_f1: 0.8914 - seed: 12082.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.0989 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.4380 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9805 - val_macro_f1: 0.8962 - seed: 12082.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.0764 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.4034 - val_sparse_categorical_accuracy: 0.8252 - train_macro_f1: 0.9901 - val_macro_f1: 0.8538 - seed: 12082.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 28s 629ms/step - loss: 0.5643 - sparse_categorical_accuracy: 0.6921 - val_loss: 0.4334 - val_sparse_categorical_accuracy: 0.8112 - train_macro_f1: 0.8575 - val_macro_f1: 0.8235 - seed: 81996.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.3511 - sparse_categorical_accuracy: 0.8685 - val_loss: 0.4632 - val_sparse_categorical_accuracy: 0.8252 - train_macro_f1: 0.9357 - val_macro_f1: 0.8466 - seed: 81996.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.2072 - sparse_categorical_accuracy: 0.9312 - val_loss: 0.3879 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9840 - val_macro_f1: 0.8950 - seed: 81996.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.1054 - sparse_categorical_accuracy: 0.9716 - val_loss: 0.5822 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9842 - val_macro_f1: 0.8808 - seed: 81996.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9731 - val_loss: 0.4159 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9877 - val_macro_f1: 0.8966 - seed: 81996.0000 - batch_size: 32.0000 - learning_rate: 5.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 631ms/step - loss: 0.6251 - sparse_categorical_accuracy: 0.6442 - val_loss: 0.4161 - val_sparse_categorical_accuracy: 0.8112 - train_macro_f1: 0.9042 - val_macro_f1: 0.8601 - seed: 21916.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.3015 - sparse_categorical_accuracy: 0.8984 - val_loss: 0.3969 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9467 - val_macro_f1: 0.8675 - seed: 21916.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.1731 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.4732 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.9592 - val_macro_f1: 0.8519 - seed: 21916.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.0915 - sparse_categorical_accuracy: 0.9731 - val_loss: 0.4472 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9914 - val_macro_f1: 0.8852 - seed: 21916.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.0681 - sparse_categorical_accuracy: 0.9746 - val_loss: 0.4277 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9876 - val_macro_f1: 0.8623 - seed: 21916.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 639ms/step - loss: 0.6457 - sparse_categorical_accuracy: 0.5815 - val_loss: 0.4978 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 25412.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.3766 - sparse_categorical_accuracy: 0.8386 - val_loss: 0.4818 - val_sparse_categorical_accuracy: 0.8112 - train_macro_f1: 0.9383 - val_macro_f1: 0.8556 - seed: 25412.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.2147 - sparse_categorical_accuracy: 0.9163 - val_loss: 0.3455 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9699 - val_macro_f1: 0.8953 - seed: 25412.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.1450 - sparse_categorical_accuracy: 0.9537 - val_loss: 0.3651 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9826 - val_macro_f1: 0.9029 - seed: 25412.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.0982 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.4187 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9749 - val_macro_f1: 0.8824 - seed: 25412.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 638ms/step - loss: 0.6539 - sparse_categorical_accuracy: 0.5979 - val_loss: 0.4827 - val_sparse_categorical_accuracy: 0.8042 - train_macro_f1: 0.8656 - val_macro_f1: 0.8614 - seed: 56281.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.3283 - sparse_categorical_accuracy: 0.8610 - val_loss: 0.3708 - val_sparse_categorical_accuracy: 0.8252 - train_macro_f1: 0.9153 - val_macro_f1: 0.8428 - seed: 56281.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.1995 - sparse_categorical_accuracy: 0.9208 - val_loss: 0.3839 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9526 - val_macro_f1: 0.8765 - seed: 56281.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1082 - sparse_categorical_accuracy: 0.9671 - val_loss: 0.3466 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9804 - val_macro_f1: 0.9000 - seed: 56281.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1035 - sparse_categorical_accuracy: 0.9626 - val_loss: 0.4088 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9711 - val_macro_f1: 0.8780 - seed: 56281.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 632ms/step - loss: 0.6458 - sparse_categorical_accuracy: 0.6099 - val_loss: 0.5150 - val_sparse_categorical_accuracy: 0.6434 - train_macro_f1: 0.7650 - val_macro_f1: 0.7753 - seed: 61712.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.3951 - sparse_categorical_accuracy: 0.8296 - val_loss: 0.3723 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9444 - val_macro_f1: 0.8913 - seed: 61712.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1955 - sparse_categorical_accuracy: 0.9268 - val_loss: 0.4052 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9632 - val_macro_f1: 0.8659 - seed: 61712.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.1072 - sparse_categorical_accuracy: 0.9731 - val_loss: 0.3675 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9914 - val_macro_f1: 0.8973 - seed: 61712.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.0875 - sparse_categorical_accuracy: 0.9746 - val_loss: 0.4380 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9800 - val_macro_f1: 0.8743 - seed: 61712.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 639ms/step - loss: 0.6301 - sparse_categorical_accuracy: 0.6084 - val_loss: 0.4332 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9024 - val_macro_f1: 0.8830 - seed: 30488.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.2992 - sparse_categorical_accuracy: 0.8849 - val_loss: 0.3358 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9642 - val_macro_f1: 0.8764 - seed: 30488.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1316 - sparse_categorical_accuracy: 0.9462 - val_loss: 0.3069 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9839 - val_macro_f1: 0.9017 - seed: 30488.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.0967 - sparse_categorical_accuracy: 0.9671 - val_loss: 0.3582 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9927 - val_macro_f1: 0.8973 - seed: 30488.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.0718 - sparse_categorical_accuracy: 0.9746 - val_loss: 0.3419 - val_sparse_categorical_accuracy: 0.8881 - train_macro_f1: 0.9889 - val_macro_f1: 0.9048 - seed: 30488.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 633ms/step - loss: 0.6453 - sparse_categorical_accuracy: 0.5934 - val_loss: 0.5142 - val_sparse_categorical_accuracy: 0.6713 - train_macro_f1: 0.7823 - val_macro_f1: 0.7892 - seed: 28215.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.8490 - val_loss: 0.3507 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9514 - val_macro_f1: 0.8686 - seed: 28215.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.1798 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.3821 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9739 - val_macro_f1: 0.9061 - seed: 28215.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 377ms/step - loss: 0.1157 - sparse_categorical_accuracy: 0.9611 - val_loss: 0.4716 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9840 - val_macro_f1: 0.8984 - seed: 28215.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.0985 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.4046 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9788 - val_macro_f1: 0.8876 - seed: 28215.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 630ms/step - loss: 0.6172 - sparse_categorical_accuracy: 0.6203 - val_loss: 0.4331 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.8953 - val_macro_f1: 0.8851 - seed: 78867.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.3296 - sparse_categorical_accuracy: 0.8744 - val_loss: 0.3703 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9471 - val_macro_f1: 0.8796 - seed: 78867.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1821 - sparse_categorical_accuracy: 0.9327 - val_loss: 0.3850 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9698 - val_macro_f1: 0.8862 - seed: 78867.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.1132 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.5273 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.9711 - val_macro_f1: 0.8763 - seed: 78867.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.1093 - sparse_categorical_accuracy: 0.9671 - val_loss: 0.4157 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9825 - val_macro_f1: 0.8929 - seed: 78867.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 28s 625ms/step - loss: 0.6318 - sparse_categorical_accuracy: 0.5725 - val_loss: 0.4425 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9089 - val_macro_f1: 0.8962 - seed: 87843.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.3503 - sparse_categorical_accuracy: 0.8685 - val_loss: 0.3631 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9557 - val_macro_f1: 0.8889 - seed: 87843.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.1953 - sparse_categorical_accuracy: 0.9223 - val_loss: 0.3482 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9554 - val_macro_f1: 0.8848 - seed: 87843.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.1136 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.3593 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9805 - val_macro_f1: 0.8995 - seed: 87843.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.0798 - sparse_categorical_accuracy: 0.9731 - val_loss: 0.3023 - val_sparse_categorical_accuracy: 0.8951 - train_macro_f1: 0.9913 - val_macro_f1: 0.9133 - seed: 87843.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 628ms/step - loss: 0.6109 - sparse_categorical_accuracy: 0.6562 - val_loss: 0.3622 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.8926 - val_macro_f1: 0.8675 - seed: 67918.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.2949 - sparse_categorical_accuracy: 0.8819 - val_loss: 0.3234 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9617 - val_macro_f1: 0.8778 - seed: 67918.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1552 - sparse_categorical_accuracy: 0.9402 - val_loss: 0.3735 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9632 - val_macro_f1: 0.8659 - seed: 67918.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 377ms/step - loss: 0.0976 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.4050 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9914 - val_macro_f1: 0.8984 - seed: 67918.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.0658 - sparse_categorical_accuracy: 0.9776 - val_loss: 0.3938 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9863 - val_macro_f1: 0.8772 - seed: 67918.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 631ms/step - loss: 0.6307 - sparse_categorical_accuracy: 0.5964 - val_loss: 0.4113 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9142 - val_macro_f1: 0.9071 - seed: 93327.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.3222 - sparse_categorical_accuracy: 0.8759 - val_loss: 0.3118 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9376 - val_macro_f1: 0.8876 - seed: 93327.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1682 - sparse_categorical_accuracy: 0.9462 - val_loss: 0.3674 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9742 - val_macro_f1: 0.8962 - seed: 93327.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1316 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.4068 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9804 - val_macro_f1: 0.8936 - seed: 93327.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.0919 - sparse_categorical_accuracy: 0.9716 - val_loss: 0.3009 - val_sparse_categorical_accuracy: 0.8881 - train_macro_f1: 0.9827 - val_macro_f1: 0.9091 - seed: 93327.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 627ms/step - loss: 0.6434 - sparse_categorical_accuracy: 0.6084 - val_loss: 0.4753 - val_sparse_categorical_accuracy: 0.6434 - train_macro_f1: 0.7711 - val_macro_f1: 0.7753 - seed: 95420.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 377ms/step - loss: 0.3263 - sparse_categorical_accuracy: 0.8759 - val_loss: 0.3627 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.9255 - val_macro_f1: 0.8500 - seed: 95420.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.1779 - sparse_categorical_accuracy: 0.9357 - val_loss: 0.3350 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9789 - val_macro_f1: 0.8989 - seed: 95420.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.0956 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.4336 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9804 - val_macro_f1: 0.8913 - seed: 95420.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 378ms/step - loss: 0.0846 - sparse_categorical_accuracy: 0.9671 - val_loss: 0.3632 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9825 - val_macro_f1: 0.8929 - seed: 95420.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 640ms/step - loss: 0.6090 - sparse_categorical_accuracy: 0.6233 - val_loss: 0.4907 - val_sparse_categorical_accuracy: 0.7692 - train_macro_f1: 0.8183 - val_macro_f1: 0.7755 - seed: 11905.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.3012 - sparse_categorical_accuracy: 0.8894 - val_loss: 0.3753 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9637 - val_macro_f1: 0.8706 - seed: 11905.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.1508 - sparse_categorical_accuracy: 0.9522 - val_loss: 0.4240 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9762 - val_macro_f1: 0.8929 - seed: 11905.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.1000 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.4839 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9877 - val_macro_f1: 0.9043 - seed: 11905.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 373ms/step - loss: 0.0844 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.4592 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9825 - val_macro_f1: 0.8743 - seed: 11905.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 631ms/step - loss: 0.6598 - sparse_categorical_accuracy: 0.5979 - val_loss: 0.5392 - val_sparse_categorical_accuracy: 0.6364 - train_macro_f1: 0.7622 - val_macro_f1: 0.7719 - seed: 86349.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.3746 - sparse_categorical_accuracy: 0.8445 - val_loss: 0.3294 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9451 - val_macro_f1: 0.8827 - seed: 86349.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.1911 - sparse_categorical_accuracy: 0.9238 - val_loss: 0.3321 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9726 - val_macro_f1: 0.8851 - seed: 86349.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.1463 - sparse_categorical_accuracy: 0.9447 - val_loss: 0.3556 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9831 - val_macro_f1: 0.9053 - seed: 86349.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.0861 - sparse_categorical_accuracy: 0.9716 - val_loss: 0.3354 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9863 - val_macro_f1: 0.8824 - seed: 86349.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 637ms/step - loss: 0.6288 - sparse_categorical_accuracy: 0.6084 - val_loss: 0.4821 - val_sparse_categorical_accuracy: 0.6923 - train_macro_f1: 0.8153 - val_macro_f1: 0.7982 - seed: 12082.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.3458 - sparse_categorical_accuracy: 0.8685 - val_loss: 0.3156 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9554 - val_macro_f1: 0.8902 - seed: 12082.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1682 - sparse_categorical_accuracy: 0.9342 - val_loss: 0.3376 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9749 - val_macro_f1: 0.8824 - seed: 12082.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.0899 - sparse_categorical_accuracy: 0.9716 - val_loss: 0.4472 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9770 - val_macro_f1: 0.8901 - seed: 12082.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.0936 - sparse_categorical_accuracy: 0.9626 - val_loss: 0.4381 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9825 - val_macro_f1: 0.8690 - seed: 12082.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 638ms/step - loss: 0.6197 - sparse_categorical_accuracy: 0.6353 - val_loss: 0.4226 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.8894 - val_macro_f1: 0.8804 - seed: 81996.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.3496 - sparse_categorical_accuracy: 0.8625 - val_loss: 0.3715 - val_sparse_categorical_accuracy: 0.8182 - train_macro_f1: 0.9595 - val_macro_f1: 0.8506 - seed: 81996.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1987 - sparse_categorical_accuracy: 0.9283 - val_loss: 0.4140 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9712 - val_macro_f1: 0.8862 - seed: 81996.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.0976 - sparse_categorical_accuracy: 0.9731 - val_loss: 0.3927 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9890 - val_macro_f1: 0.8852 - seed: 81996.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.0775 - sparse_categorical_accuracy: 0.9791 - val_loss: 0.4112 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9889 - val_macro_f1: 0.8727 - seed: 81996.0000 - batch_size: 32.0000 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 629ms/step - loss: 0.6584 - sparse_categorical_accuracy: 0.6129 - val_loss: 0.5761 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 21916.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.3937 - sparse_categorical_accuracy: 0.8251 - val_loss: 0.3993 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9288 - val_macro_f1: 0.8659 - seed: 21916.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 378ms/step - loss: 0.2223 - sparse_categorical_accuracy: 0.9208 - val_loss: 0.3846 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9605 - val_macro_f1: 0.8780 - seed: 21916.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 379ms/step - loss: 0.1278 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.3740 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9778 - val_macro_f1: 0.9061 - seed: 21916.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1240 - sparse_categorical_accuracy: 0.9522 - val_loss: 0.4194 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9749 - val_macro_f1: 0.8606 - seed: 21916.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 28s 628ms/step - loss: 0.6680 - sparse_categorical_accuracy: 0.5710 - val_loss: 0.6102 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 25412.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.4665 - sparse_categorical_accuracy: 0.7414 - val_loss: 0.3894 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9172 - val_macro_f1: 0.8571 - seed: 25412.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.2398 - sparse_categorical_accuracy: 0.9238 - val_loss: 0.3601 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9459 - val_macro_f1: 0.8571 - seed: 25412.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1405 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.3645 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9749 - val_macro_f1: 0.9029 - seed: 25412.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1383 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.4209 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9618 - val_macro_f1: 0.8727 - seed: 25412.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 28s 629ms/step - loss: 0.6682 - sparse_categorical_accuracy: 0.5949 - val_loss: 0.6083 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 56281.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.4694 - sparse_categorical_accuracy: 0.7354 - val_loss: 0.3394 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9243 - val_macro_f1: 0.8795 - seed: 56281.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.2239 - sparse_categorical_accuracy: 0.9103 - val_loss: 0.3565 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9555 - val_macro_f1: 0.8727 - seed: 56281.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.1386 - sparse_categorical_accuracy: 0.9611 - val_loss: 0.3384 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9750 - val_macro_f1: 0.9029 - seed: 56281.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1299 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.3974 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9632 - val_macro_f1: 0.8795 - seed: 56281.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 28s 626ms/step - loss: 0.6622 - sparse_categorical_accuracy: 0.6069 - val_loss: 0.6042 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 61712.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.4862 - sparse_categorical_accuracy: 0.7025 - val_loss: 0.3363 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9333 - val_macro_f1: 0.8914 - seed: 61712.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.2311 - sparse_categorical_accuracy: 0.9163 - val_loss: 0.3223 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9572 - val_macro_f1: 0.9017 - seed: 61712.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1419 - sparse_categorical_accuracy: 0.9522 - val_loss: 0.3397 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9802 - val_macro_f1: 0.9040 - seed: 61712.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1113 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.3672 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9710 - val_macro_f1: 0.8876 - seed: 61712.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 626ms/step - loss: 0.6597 - sparse_categorical_accuracy: 0.6009 - val_loss: 0.5558 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 30488.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.4168 - sparse_categorical_accuracy: 0.7907 - val_loss: 0.3153 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9462 - val_macro_f1: 0.8939 - seed: 30488.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1993 - sparse_categorical_accuracy: 0.9297 - val_loss: 0.3697 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9406 - val_macro_f1: 0.8834 - seed: 30488.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1552 - sparse_categorical_accuracy: 0.9447 - val_loss: 0.3731 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9687 - val_macro_f1: 0.9091 - seed: 30488.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 377ms/step - loss: 0.1287 - sparse_categorical_accuracy: 0.9567 - val_loss: 0.2881 - val_sparse_categorical_accuracy: 0.9021 - train_macro_f1: 0.9737 - val_macro_f1: 0.9186 - seed: 30488.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 28s 630ms/step - loss: 0.6653 - sparse_categorical_accuracy: 0.5919 - val_loss: 0.6174 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 28215.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.5132 - sparse_categorical_accuracy: 0.7160 - val_loss: 0.3622 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9278 - val_macro_f1: 0.9011 - seed: 28215.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 378ms/step - loss: 0.2684 - sparse_categorical_accuracy: 0.8999 - val_loss: 0.3425 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9517 - val_macro_f1: 0.8851 - seed: 28215.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.1587 - sparse_categorical_accuracy: 0.9507 - val_loss: 0.3502 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9679 - val_macro_f1: 0.9061 - seed: 28215.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.1437 - sparse_categorical_accuracy: 0.9507 - val_loss: 0.3651 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9634 - val_macro_f1: 0.8743 - seed: 28215.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 28s 627ms/step - loss: 0.6574 - sparse_categorical_accuracy: 0.6084 - val_loss: 0.5769 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 78867.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.4363 - sparse_categorical_accuracy: 0.7803 - val_loss: 0.3213 - val_sparse_categorical_accuracy: 0.8881 - train_macro_f1: 0.9265 - val_macro_f1: 0.9101 - seed: 78867.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.2246 - sparse_categorical_accuracy: 0.9148 - val_loss: 0.3429 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9562 - val_macro_f1: 0.8772 - seed: 78867.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1380 - sparse_categorical_accuracy: 0.9611 - val_loss: 0.3746 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9741 - val_macro_f1: 0.8939 - seed: 78867.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1278 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.3885 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9711 - val_macro_f1: 0.8941 - seed: 78867.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 640ms/step - loss: 0.6803 - sparse_categorical_accuracy: 0.5785 - val_loss: 0.6151 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 87843.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.4870 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.3491 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9366 - val_macro_f1: 0.8901 - seed: 87843.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.2442 - sparse_categorical_accuracy: 0.9148 - val_loss: 0.2986 - val_sparse_categorical_accuracy: 0.8881 - train_macro_f1: 0.9593 - val_macro_f1: 0.9121 - seed: 87843.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1661 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.3272 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9731 - val_macro_f1: 0.9032 - seed: 87843.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.1286 - sparse_categorical_accuracy: 0.9522 - val_loss: 0.3276 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9697 - val_macro_f1: 0.8795 - seed: 87843.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 641ms/step - loss: 0.6441 - sparse_categorical_accuracy: 0.6143 - val_loss: 0.5109 - val_sparse_categorical_accuracy: 0.7273 - train_macro_f1: 0.8250 - val_macro_f1: 0.8169 - seed: 67918.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.3654 - sparse_categorical_accuracy: 0.8460 - val_loss: 0.3264 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9466 - val_macro_f1: 0.8889 - seed: 67918.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 377ms/step - loss: 0.1919 - sparse_categorical_accuracy: 0.9297 - val_loss: 0.3761 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9486 - val_macro_f1: 0.8642 - seed: 67918.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1311 - sparse_categorical_accuracy: 0.9567 - val_loss: 0.3577 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9877 - val_macro_f1: 0.8901 - seed: 67918.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.1060 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.3830 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9685 - val_macro_f1: 0.8589 - seed: 67918.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 28s 628ms/step - loss: 0.6718 - sparse_categorical_accuracy: 0.5620 - val_loss: 0.5983 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 93327.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.4502 - sparse_categorical_accuracy: 0.7668 - val_loss: 0.3392 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9296 - val_macro_f1: 0.8837 - seed: 93327.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.2201 - sparse_categorical_accuracy: 0.9178 - val_loss: 0.3677 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9439 - val_macro_f1: 0.8606 - seed: 93327.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.1449 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.4120 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9745 - val_macro_f1: 0.8995 - seed: 93327.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.1301 - sparse_categorical_accuracy: 0.9567 - val_loss: 0.3623 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9698 - val_macro_f1: 0.8675 - seed: 93327.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 628ms/step - loss: 0.6612 - sparse_categorical_accuracy: 0.6099 - val_loss: 0.5856 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 95420.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.4441 - sparse_categorical_accuracy: 0.7519 - val_loss: 0.3276 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9272 - val_macro_f1: 0.8889 - seed: 95420.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 379ms/step - loss: 0.2514 - sparse_categorical_accuracy: 0.9043 - val_loss: 0.3634 - val_sparse_categorical_accuracy: 0.8322 - train_macro_f1: 0.9512 - val_macro_f1: 0.8519 - seed: 95420.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.1476 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.3666 - val_sparse_categorical_accuracy: 0.8741 - train_macro_f1: 0.9743 - val_macro_f1: 0.9032 - seed: 95420.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.1311 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.3702 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9645 - val_macro_f1: 0.8606 - seed: 95420.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 28s 627ms/step - loss: 0.6515 - sparse_categorical_accuracy: 0.6039 - val_loss: 0.5383 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 11905.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.3834 - sparse_categorical_accuracy: 0.8266 - val_loss: 0.3636 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9146 - val_macro_f1: 0.8659 - seed: 11905.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.2069 - sparse_categorical_accuracy: 0.9253 - val_loss: 0.3772 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9637 - val_macro_f1: 0.8837 - seed: 11905.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1300 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.4079 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9768 - val_macro_f1: 0.9071 - seed: 11905.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1337 - sparse_categorical_accuracy: 0.9522 - val_loss: 0.4436 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9566 - val_macro_f1: 0.8571 - seed: 11905.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 641ms/step - loss: 0.6696 - sparse_categorical_accuracy: 0.5874 - val_loss: 0.6272 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 86349.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.4691 - sparse_categorical_accuracy: 0.7534 - val_loss: 0.3479 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9256 - val_macro_f1: 0.8837 - seed: 86349.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.2239 - sparse_categorical_accuracy: 0.9163 - val_loss: 0.3235 - val_sparse_categorical_accuracy: 0.8601 - train_macro_f1: 0.9662 - val_macro_f1: 0.8864 - seed: 86349.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.1475 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.3641 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9801 - val_macro_f1: 0.8962 - seed: 86349.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1332 - sparse_categorical_accuracy: 0.9537 - val_loss: 0.3432 - val_sparse_categorical_accuracy: 0.8811 - train_macro_f1: 0.9618 - val_macro_f1: 0.8970 - seed: 86349.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 631ms/step - loss: 0.6523 - sparse_categorical_accuracy: 0.5979 - val_loss: 0.5682 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 12082.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 374ms/step - loss: 0.4625 - sparse_categorical_accuracy: 0.7474 - val_loss: 0.3738 - val_sparse_categorical_accuracy: 0.8671 - train_macro_f1: 0.9391 - val_macro_f1: 0.8889 - seed: 12082.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 8s 376ms/step - loss: 0.2278 - sparse_categorical_accuracy: 0.9238 - val_loss: 0.4106 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9632 - val_macro_f1: 0.8675 - seed: 12082.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1595 - sparse_categorical_accuracy: 0.9462 - val_loss: 0.4412 - val_sparse_categorical_accuracy: 0.8531 - train_macro_f1: 0.9793 - val_macro_f1: 0.8889 - seed: 12082.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.1127 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.4172 - val_sparse_categorical_accuracy: 0.8462 - train_macro_f1: 0.9710 - val_macro_f1: 0.8659 - seed: 12082.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 29s 628ms/step - loss: 0.6508 - sparse_categorical_accuracy: 0.6143 - val_loss: 0.5618 - val_sparse_categorical_accuracy: 0.6154 - train_macro_f1: 0.7565 - val_macro_f1: 0.7619 - seed: 81996.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 8s 375ms/step - loss: 0.4159 - sparse_categorical_accuracy: 0.7967 - val_loss: 0.3560 - val_sparse_categorical_accuracy: 0.8392 - train_macro_f1: 0.9412 - val_macro_f1: 0.8639 - seed: 81996.0000 - batch_size: 32.0000 - learning_rate: 2.0000e-05\n",
            "Epoch 3/5\n",
            " 1/21 [>.............................] - ETA: 5s - loss: 0.2825 - sparse_categorical_accuracy: 0.8750"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cp -av '/content/frnfr' '/content/drive/MyDrive/Thesis/logs/'"
      ],
      "metadata": {
        "id": "nFPdmaL29VYS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}